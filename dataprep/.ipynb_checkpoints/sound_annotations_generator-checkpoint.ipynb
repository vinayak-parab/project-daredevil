{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import torchvision\n",
    "import datetime\n",
    "from subprocess import Popen, PIPE\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo : Generalise a bit better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/work/oarongve/data/sound_dataset/SoccerNet-code/data/'\n",
    "train_file = root_dir+\"listgame_Train_300.npy\"\n",
    "valid_file = root_dir+\"listgame_Valid_100.npy\"\n",
    "test_file = root_dir+\"listgame_Test_100.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/hdd/SoccerNet-code/data/listgame_Train_300.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-45495b6af6b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnpy_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/hdd/SoccerNet-code/data/listgame_Train_300.npy'"
     ]
    }
   ],
   "source": [
    "train_dict = dict()\n",
    "\n",
    "\n",
    "npy_file = np.load(train_file)\n",
    "\n",
    "train_d = []\n",
    "\n",
    "count_train = 0\n",
    "for e in npy_file:\n",
    "    count_train += 1\n",
    "    f = open(root_dir+e+'/langlabel.json', \"r\")\n",
    "    d = eval(f.read())\n",
    "    train_d.append(d)\n",
    "    train_dict[e] = d['lang']\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dict = dict()\n",
    "\n",
    "npy_file = np.load(valid_file)\n",
    "\n",
    "valid_d = []\n",
    "\n",
    "count_valid = 0\n",
    "for e in npy_file:\n",
    "    count_valid += 1\n",
    "    f = open(root_dir+e+'/langlabel.json', \"r\")\n",
    "    d = eval(f.read())\n",
    "    valid_dict[e] = d['lang']\n",
    "    valid_d.append(d)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = dict()\n",
    "\n",
    "count_test = 0\n",
    "\n",
    "test_d = []\n",
    "\n",
    "npy_file = np.load(test_file)\n",
    "for e in npy_file:\n",
    "    count_test += 1\n",
    "    f = open(root_dir+e+'/langlabel.json', \"r\")\n",
    "    d = eval(f.read())\n",
    "    test_d.append(d)\n",
    "    test_dict[e] = d['lang']\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(count_train)\n",
    "print(count_valid)\n",
    "print(count_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save dict with langlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_lang_dict.json','w') as fp:\n",
    "        json.dump(train_dict,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('valid_lang_dict.json','w') as fp:\n",
    "        json.dump(valid_dict,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_lang_dict.json','w') as fp:\n",
    "        json.dump(test_dict,fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify integrity of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_lang_dict.json','r') as fp:\n",
    "        train_lang_load = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('valid_lang_dict.json','r') as fp:\n",
    "        valid_lang_load = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_lang_dict.json','r') as fp:\n",
    "        test_lang_load = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dict == test_lang_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read dict and write labels to folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_lang_label(root_dir,soccer_game_path, lang):\n",
    "    \"\"\" writes a file 'lang_label.json' that contains information of language used in soccer matches\n",
    "    \"\"\"\n",
    "    lang_label = {'lang': lang}\n",
    "    with open(root_dir+soccer_game_path+'lang_label.json','w') as fp:\n",
    "        json.dump(soundlabel,fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-daredevil",
   "language": "python",
   "name": "project-daredevil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
