{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import torchvision\n",
    "import datetime\n",
    "from subprocess import Popen, PIPE\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo : Generalise a bit better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/hdd/sound_sn/SoccerNet-code/data/\"\n",
    "train_file = \"/hdd/SoccerNet-code/data/listgame_Train_300.npy\"\n",
    "valid_file = \"/hdd/SoccerNet-code/data/listgame_Valid_100.npy\"\n",
    "test_file = \"/hdd/SoccerNet-code/data/listgame_Test_100.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = dict()\n",
    "\n",
    "\n",
    "npy_file = np.load(train_file)\n",
    "\n",
    "train_d = []\n",
    "\n",
    "count_train = 0\n",
    "for e in npy_file:\n",
    "    count_train += 1\n",
    "    f = open(root_dir+e+'/langlabel.json', \"r\")\n",
    "    d = eval(f.read())\n",
    "    train_d.append(d)\n",
    "    train_dict[e] = d['lang']\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dict = dict()\n",
    "\n",
    "npy_file = np.load(valid_file)\n",
    "\n",
    "valid_d = []\n",
    "\n",
    "count_valid = 0\n",
    "for e in npy_file:\n",
    "    count_valid += 1\n",
    "    f = open(root_dir+e+'/langlabel.json', \"r\")\n",
    "    d = eval(f.read())\n",
    "    valid_dict[e] = d['lang']\n",
    "    valid_d.append(d)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = dict()\n",
    "\n",
    "count_test = 0\n",
    "\n",
    "test_d = []\n",
    "\n",
    "npy_file = np.load(test_file)\n",
    "for e in npy_file:\n",
    "    count_test += 1\n",
    "    f = open(root_dir+e+'/langlabel.json', \"r\")\n",
    "    d = eval(f.read())\n",
    "    test_d.append(d)\n",
    "    test_dict[e] = d['lang']\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(count_train)\n",
    "print(count_valid)\n",
    "print(count_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save dict with langlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_lang_dict.json','w') as fp:\n",
    "        json.dump(train_dict,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('valid_lang_dict.json','w') as fp:\n",
    "        json.dump(valid_dict,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_lang_dict.json','w') as fp:\n",
    "        json.dump(test_dict,fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify integrity of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_lang_dict.json','r') as fp:\n",
    "        train_lang_load = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('valid_lang_dict.json','r') as fp:\n",
    "        valid_lang_load = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_lang_dict.json','r') as fp:\n",
    "        test_lang_load = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dict == test_lang_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read dict and write labels to folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_lang_label(root_dir,soccer_game_path, lang):\n",
    "    \"\"\" writes a file 'lang_label.json' that contains information of language used in soccer matches\n",
    "    \"\"\"\n",
    "    lang_label = {'lang': lang}\n",
    "    with open(root_dir+soccer_game_path+'lang_label.json','w') as fp:\n",
    "        json.dump(soundlabel,fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-daredevil",
   "language": "python",
   "name": "project-daredevil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
