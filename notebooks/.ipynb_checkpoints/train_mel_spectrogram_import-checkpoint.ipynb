{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchaudio\n",
    "import time\n",
    "# to fix relative import problem\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir   = \"/work/oarongve/data/sound_dataset/SoccerNet-code/data/\"\n",
    "train_file = root_dir+\"listgame_Train_300.npy\"\n",
    "valid_file = root_dir+\"listgame_Valid_100.npy\"\n",
    "test_file  = root_dir+\"listgame_Test_100.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov  4 00:41:02 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.165.02   Driver Version: 418.165.02   CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM3...  On   | 00000000:59:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    51W / 350W |      0MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Test loading of some samples from train_samples.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class soccernet_ms_npy_audio_only(Dataset):\n",
    "    \"\"\"Soccernet Dataset\"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self,npy_file,\n",
    "                 root_dir,\n",
    "                 transform=None,\n",
    "                 train=True):\n",
    "    \n",
    "        self.samples = np.load(root_dir+npy_file,allow_pickle=True)        # GENERALIZE\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        \"\"\"Returns a sample containing video path, clip and label\"\"\"\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx.tolist()\n",
    "        \n",
    "        if self.train:\n",
    "            if idx in [2209,2210,2212,2213,2215,2217,2222]: # ultradirty hack - fix later\n",
    "                idx = 0\n",
    "        \n",
    "        path = str(self.samples[idx]['audiopath'][:-11]+str(idx)+\"_ms.npy\")\n",
    "        ms = np.load(path)\n",
    "        ms = ms-np.min(ms) / (np.max(ms)-np.min(ms))\n",
    "        label = self.samples[idx]['label']\n",
    "        info = self.samples[idx]['annotation']\n",
    "        idx_old = self.samples[idx]['idx']\n",
    "        \n",
    "        sample = {'path': path,\n",
    "                  'ms':ms,'idx': idx_old,\n",
    "                  'label':label, 'info':info}\n",
    "        \n",
    "        return sample\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import torchvision\n",
    "import datetime\n",
    "from subprocess import Popen, PIPE\n",
    "import re\n",
    "\n",
    "class SoccerNetDataset(Dataset):\n",
    "    \"\"\"Soccernet Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self,npy_file,\n",
    "                 npy_file_audio,\n",
    "                 root_dir,nframes=1,\n",
    "                 stride_frames=1,\n",
    "                 frame_center='center',\n",
    "                 transform=None,\n",
    "                 train=False,\n",
    "                 tshift={'active':False,\n",
    "                         'mu':0,'sigma':(0.4/3), \n",
    "                         'interval':[-0.45,0.45],\n",
    "                         'mode': 'uniform'}):\n",
    "        self.npy_file = np.load(npy_file)\n",
    "        self.audio_samples = np.load(root_dir+npy_file_audio,allow_pickle=True)\n",
    "        self.samples = list() # maybe change structure later depending on efficiency        \n",
    "        self.tshift = tshift\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.frame_center = frame_center\n",
    "        self.nframes = nframes\n",
    "        self.stride_frames = stride_frames\n",
    "        self.train = train\n",
    "        # For each path in npy_file, get all annotations\n",
    "\n",
    "\n",
    "        for e in self.npy_file:\n",
    "            path, annotations = self.get_annotations(e)\n",
    "\n",
    "            duration1 = self.getVideoLength(self.root_dir + e + \"/1.mkv\")\n",
    "            duration2 = self.getVideoLength(self.root_dir + e + \"/2.mkv\")\n",
    "            #print(f\"duration1 : {duration1}, duration2: {duration2}\")\n",
    "            for annotation in annotations:\n",
    "                # Check that annotations hold correct labels\n",
    "                        if (\"card\" in annotation[\"label\"]) or (\"subs\" in annotation[\"label\"]) or (\"soccer\" in annotation[\"label\"]):\n",
    "                            annotation[\"duration1\"] = duration1\n",
    "                            annotation[\"duration2\"] = duration2\n",
    "                            self.samples.append([path,annotation,\"soccernet\"])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def getVideoLength(self,video_file):\n",
    "        res = Popen(['ffmpeg', '-i', video_file, '-hide_banner'],stdout=PIPE,stderr=PIPE)\n",
    "        none,meta = res.communicate()\n",
    "        meta_out = meta.decode()\n",
    "        #---| Take out info\n",
    "        duration = re.search(r'Duration:.*', meta_out)\n",
    "        return duration.group()[:21]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        \"\"\"Returns a sample containing video path, clip and label\"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx.tolist()\n",
    "        \n",
    "        if self.train:\n",
    "            if idx in [2209,2210,2212,2213,2215,2217,2222]: # ultradirty hack - fix later\n",
    "                idx = 0\n",
    "        \n",
    "        if self.train:\n",
    "            if idx in [2209,2210,2212,2213,2215,2217,2222]: # ultradirty hack - fix later\n",
    "                idx = 0\n",
    "        \n",
    "        path = str(self.audio_samples[idx]['audiopath'][:-11]+str(idx)+\"_ms.npy\")\n",
    "        ms = np.load(path)\n",
    "        ms = ms-np.min(ms) / (np.max(ms)-np.min(ms))\n",
    "        label = self.samples[idx]['label']\n",
    "        info = self.samples[idx]['annotation']\n",
    "        idx_old = self.samples[idx]['idx']\n",
    "        \n",
    "        audio_sample = {'path': path,\n",
    "                  'ms':ms,'idx': idx_old,\n",
    "                  'label':label, 'info':info}\n",
    "        \n",
    "        \n",
    "        # get annotations\n",
    "        time_half = int(self.samples[idx][1][\"gameTime\"][0])\n",
    "        time_minute = int(self.samples[idx][1][\"gameTime\"][-5:-3])\n",
    "        time_second = int(self.samples[idx][1][\"gameTime\"][-2:])\n",
    "        annotation = self.samples[idx][1]\n",
    "        source = self.samples[idx][2]\n",
    "        \n",
    "\n",
    "\n",
    "        # Get label\n",
    "        if (\"card\" in annotation[\"label\"]): label = 0\n",
    "        elif (\"subs\" in annotation[\"label\"]): label = 1\n",
    "        elif (\"soccer\" in annotation[\"label\"]): label = 2\n",
    "        elif (\"background\" in annotation[\"label\"]): label = 3\n",
    "        else: \n",
    "            print(\"Warning, label not compatible with set\")\n",
    "            return\n",
    "            \n",
    "        # Get videopath\n",
    "        if source == 'soccernet':\n",
    "            vidpath = os.path.join(self.root_dir,\n",
    "                                str(self.samples[idx][0]),\n",
    "                                    str(time_half)+\".mkv\")\n",
    "        else:\n",
    "            vidpath = str(self.samples[idx][0])\n",
    "        \n",
    "        \n",
    "        # Get video frames \n",
    "        \n",
    "        # get start in second, use labeled time as center TODO: fix centerframe as keyframe and stride\n",
    "        fps = 25.0 # assume fps = 25 for now, should be so\n",
    "        start_sec = time_minute*60 + time_second\n",
    "        end_sec = start_sec\n",
    "\n",
    "        if self.nframes == 1:\n",
    "            end_sec = start_sec\n",
    "        \n",
    "        if start_sec == 0:\n",
    "            end_sec += (1/fps) # possibly unstable solution\n",
    "            \n",
    "        \n",
    "        if self.frame_center == 'center' and self.nframes > 1:\n",
    "            \n",
    "            end_sec = end_sec + (self.nframes/fps) # might need to subtract 1/fps\n",
    "            # Shift backwards to center around time but check that time > 0\n",
    "            diff = (end_sec - start_sec) / 2 # TODO : Might result in bad precision\n",
    "            temp_start_sec = start_sec - diff\n",
    "            temp_end_sec = end_sec - diff\n",
    "            \n",
    "            # Only change as long as the shift operation doesnt shift out of bounds \n",
    "            if temp_start_sec >= 0:\n",
    "                start_sec = temp_start_sec\n",
    "                end_sec = temp_end_sec\n",
    "                \n",
    "            # TODO : Find new samplesize if self.stride_frames > 1\n",
    "            # if self.stride_frames > 1:\n",
    "            # For now, this is an operation for another place\n",
    "                \n",
    "        elif self.frame_center == 'back' and self.nframes > 1:\n",
    "            print(\"This option should NOT be used during inference, please use 'center' instead\")\n",
    "            end_sec = end_sec + (self.nframes/fps) # might need to subtract 1/fps\n",
    "        elif self.frame_center == 'front' and self.nframes > 1:\n",
    "            #print(\"This option should NOT be used during inference, please use 'center' instead\")\n",
    "            \n",
    "            end_sec = end_sec + (self.nframes/fps) # might need to subtract 1/fps\n",
    "            \n",
    "            # Shift forward such that the last frame is at annotated time t around time but check that time > 0\n",
    "            diff = (end_sec - start_sec) # TODO : Might result in bad precision\n",
    "            temp_start_sec = start_sec - diff\n",
    "            temp_end_sec = end_sec - diff\n",
    "            \n",
    "            # Only change as long as the shift operation doesnt shift out of bounds \n",
    "            if temp_start_sec >= 0:\n",
    "                start_sec = temp_start_sec\n",
    "                end_sec = temp_end_sec\n",
    "\n",
    "        \n",
    "        # Temporal translation transform\n",
    "        \n",
    "        if self.tshift['active'] and self.frame_center == 'center' and source == 'soccernet':\n",
    "            t0 = self.tshift['interval'][0]\n",
    "            t = self.tshift['interval'][1]\n",
    "            \n",
    "            if self.tshift['mode'] == 'uniform':    \n",
    "                delta = np.floor(np.random.uniform(t0,t) * self.nframes)\n",
    "            elif self.tshift['mode'] == 'normal':\n",
    "                mu = self.tshift['mu']\n",
    "                sigma = self.tshift['sigma']\n",
    "                temporal_window_size = self.nframes / 25.0\n",
    "                delta = np.random.normal(mu,sigma)\n",
    "                if delta < t0:\n",
    "                    delta = t0\n",
    "                elif delta > t:\n",
    "                    delta = t\n",
    "                delta = delta * temporal_window_size\n",
    "            else: return \"Please choose uniform or normal distribution\"\n",
    "            \n",
    "            # change delta from frames to seconds with correct stepsize\n",
    "            shifted_start = start_sec+delta\n",
    "            shifted_end = end_sec+delta\n",
    "            # Verify that shifted window stays inside \n",
    "            # get duration of video\n",
    "            if time_half == 1:\n",
    "                video_length = self.samples[idx][1][\"duration1\"]\n",
    "            elif time_half == 2:\n",
    "                video_length = self.samples[idx][1][\"duration2\"]\n",
    "\n",
    "            video_length_min = video_length[-8:-6]\n",
    "            video_length_sec = video_length[-5:-3]\n",
    "            total_sec = int(video_length_min)*60 + int(video_length_sec)\n",
    "            \n",
    "            if shifted_start < 0 or shifted_end > total_sec:\n",
    "                shifted_start = start_sec\n",
    "                shifted_end = end_sec\n",
    "            \n",
    "            start_sec = shifted_start\n",
    "            end_sec = shifted_end\n",
    "\n",
    "        # Buffer to endsec incase of bad load\n",
    "        end_sec = end_sec + 0.9 # loads more frames than needed, then reduced later\n",
    "        clip,_,info = torchvision.io.read_video(vidpath, start_pts=start_sec, end_pts=end_sec, pts_unit='sec')\n",
    "        \n",
    "        # TODO : This should be tested\n",
    "        clip = clip[:self.nframes,:,:,:]\n",
    "        \n",
    "\n",
    "        one_hot_labels = np.zeros(3)\n",
    "        one_hot_labels[label] = 1\n",
    "\n",
    "        csize = clip.size()\n",
    "        abnormal_count = 0\n",
    "        bad_count = 0   \n",
    "        abnormal_2_count = 0\n",
    "        # At this point clip is [T x H x W x C]\n",
    "        if clip.size()[3] != 3 or clip.size()[0] != self.nframes or clip.size()[1] != 224 or clip.size()[2] != 398:\n",
    "            abnormal_count += 1\n",
    "            if clip.size()[1] != 224 or clip.size()[2] != 398 or clip.size()[0] / self.nframes < 0.6:\n",
    "                clip = torch.zeros([self.nframes,224,398,3]).byte()\n",
    "                bad_count += 1\n",
    "            elif clip.size()[1] == 224 and clip.size()[2] == 398 and clip.size()[0] / self.nframes > 0.6:\n",
    "                a = clip.size()[0]\n",
    "                b = self.nframes - a\n",
    "                last_f = clip[(a-1):,:,:,:]\n",
    "                dup = last_f.repeat(b,1,1,1)\n",
    "                clip = torch.cat((clip,dup)).byte()\n",
    "                abnormal_2_count += 1\n",
    "\n",
    "        \n",
    "\n",
    "        sample = {'vidpath': vidpath,'clip': clip, 'annotation':annotation,'label':one_hot_labels,'idx':idx,\n",
    "                 'csize':csize, 'source': source, 'audio_sample': audio_sample}\n",
    "        \n",
    "\n",
    "        if self.transform:\n",
    "            sample['clip'] = self.transform(sample['clip'])\n",
    "        return sample\n",
    "            \n",
    "    def get_annotations(self,path):\n",
    "        \"\"\" Reads json files and returns \"\"\"\n",
    "        with open(self.root_dir+path+\"/Labels.json\") as jsonfile:\n",
    "            json_label = json.load(jsonfile)\n",
    "        \n",
    "        labels = [e for e in json_label['annotations']]\n",
    "        \n",
    "        return path,labels\n",
    "    def get_keyframe(self,idx):\n",
    "        if self.frame_center == 'back': return self.__getitem__(idx)['clip'][0,:,:,:]\n",
    "        elif self.frame_center == 'center': return self.__getitem__(idx)['clip'][self.nframes//2,:,:,:]\n",
    "        elif self.frame_center == 'front': return self.__getitem__(idx)['clip'][self.nframes-1,:,:,:]\n",
    "    def describe(self):\n",
    "        card = 0\n",
    "        subs = 0\n",
    "        goal = 0\n",
    "        background = 0\n",
    "\n",
    "        for sample in self.samples:\n",
    "            annotation = sample[1]\n",
    "        # Get label\n",
    "            if (\"card\" in annotation[\"label\"]): card += 1\n",
    "            elif (\"subs\" in annotation[\"label\"]): subs +=1\n",
    "            elif (\"soccer\" in annotation[\"label\"]): goal += 1\n",
    "            elif (\"background\" in annotation[\"label\"]): background += 1\n",
    "\n",
    "        print(\"Description of dataset\\n\\n\")\n",
    "        print(\"\\n ********* Classes *********\")\n",
    "        print(\"\\n card = 0\\n subs = 1\\n goals = 2\\n background = 3\")\n",
    "\n",
    "        print(\"\\n ********* Distribution and count *********\")\n",
    "        print(f\"\\n N card: {card} \\n N subs: {subs} \\n N goal: {goal} \\n N background: {background} \\n \\n Total : {card+subs+goal+background}\")\n",
    "        \n",
    "        print(\"\\n\\n ********* Configuration *********\")\n",
    "        print(f\"\\n npy_file: {self.npy_file} \\n tshift: {self.tshift} \\n root_dir: {self.root_dir} \\n transform: {self.transform} \\n frame_center: {self.frame_center} \\n nframes: {self.nframes} \\n stride_frames: {self.stride_frames} \\n background: {self.background}\")\n",
    "        print(\"\\n\\n ********* End of description *********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Note: Can also see warning once\n",
    "# warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 12,\n",
    "         'shuffle': True,\n",
    "         'num_workers':6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_npy = soccernet_ms_npy_audio_only(root_dir=root_dir,npy_file=\"train_samples.npy\")\n",
    "#X_valid_npy = soccernet_ms_npy_DS(root_dir=root_dir,npy_file=\"valid_samples.npy\")\n",
    "X_test_npy = soccernet_ms_npy_audio_only(root_dir=root_dir,npy_file=\"test_samples.npy\")\n",
    "\n",
    "params = {'batch_size': 12,\n",
    "         'shuffle': True,\n",
    "         'num_workers':6}\n",
    "trainloader = DataLoader(X_train_npy,**params)\n",
    "testloader = DataLoader(X_test_npy,**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(X_train_npy,**params)\n",
    "testloader = DataLoader(X_test_npy,**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.pool = nn.MaxPool2d(4, 4)\n",
    "        self.fc1 = nn.Linear(2208, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = x.view(-1, 2208)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/simple_net3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=2208, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.025, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov  4 00:41:19 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.165.02   Driver Version: 418.165.02   CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM3...  On   | 00000000:59:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    67W / 350W |   1406MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     76556      C   .../project-daredevil-8eBKzQn6/bin/python3  1393MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.241\n",
      "[1,     6] loss: 1.153\n",
      "[1,    11] loss: 1.107\n",
      "[1,    16] loss: 0.992\n",
      "[1,    21] loss: 1.034\n",
      "[1,    26] loss: 0.907\n",
      "[1,    31] loss: 0.669\n",
      "[1,    36] loss: 1.124\n",
      "[1,    41] loss: 0.953\n",
      "[1,    46] loss: 0.691\n",
      "[1,    51] loss: 0.742\n",
      "[1,    56] loss: 0.929\n",
      "[1,    61] loss: 0.679\n",
      "[1,    66] loss: 0.686\n",
      "[1,    71] loss: 0.598\n",
      "[1,    76] loss: 0.801\n",
      "[1,    81] loss: 0.734\n",
      "[1,    86] loss: 0.700\n",
      "[1,    91] loss: 0.857\n",
      "[1,    96] loss: 0.695\n",
      "[1,   101] loss: 0.875\n",
      "[1,   106] loss: 0.882\n",
      "[1,   111] loss: 0.905\n",
      "[1,   116] loss: 0.840\n",
      "[1,   121] loss: 0.630\n",
      "[1,   126] loss: 0.844\n",
      "[1,   131] loss: 0.948\n",
      "[1,   136] loss: 0.982\n",
      "[1,   141] loss: 0.891\n",
      "[1,   146] loss: 0.887\n",
      "[1,   151] loss: 0.698\n",
      "[1,   156] loss: 0.683\n",
      "[1,   161] loss: 0.725\n",
      "[1,   166] loss: 0.776\n",
      "[1,   171] loss: 0.837\n",
      "[1,   176] loss: 0.680\n",
      "[1,   181] loss: 0.863\n",
      "[1,   186] loss: 0.732\n",
      "[1,   191] loss: 0.649\n",
      "[1,   196] loss: 0.561\n",
      "[1,   201] loss: 0.987\n",
      "[1,   206] loss: 0.706\n",
      "[1,   211] loss: 0.728\n",
      "[1,   216] loss: 0.613\n",
      "[1,   221] loss: 0.617\n",
      "[1,   226] loss: 0.542\n",
      "[1,   231] loss: 0.520\n",
      "[1,   236] loss: 0.573\n",
      "[1,   241] loss: 0.635\n",
      "[1,   246] loss: 0.622\n",
      "[1,   251] loss: 0.832\n",
      "[1,   256] loss: 0.772\n",
      "[1,   261] loss: 0.630\n",
      "[1,   266] loss: 0.467\n",
      "[1,   271] loss: 0.562\n",
      "[1,   276] loss: 0.758\n",
      "[1,   281] loss: 0.633\n",
      "[1,   286] loss: 0.679\n",
      "[1,   291] loss: 0.707\n",
      "[1,   296] loss: 0.501\n",
      "[1,   301] loss: 0.709\n",
      "[1,   306] loss: 0.833\n",
      "[1,   311] loss: 0.623\n",
      "[1,   316] loss: 0.637\n",
      "[1,   321] loss: 0.628\n",
      "[1,   326] loss: 0.420\n",
      "[1,   331] loss: 0.771\n",
      "Epoch : 0, Accuracy : 0.7466862797737122\n",
      "[2,     1] loss: 0.097\n",
      "[2,     6] loss: 0.666\n",
      "[2,    11] loss: 0.721\n",
      "[2,    16] loss: 0.564\n",
      "[2,    21] loss: 0.535\n",
      "[2,    26] loss: 0.837\n",
      "[2,    31] loss: 0.782\n",
      "[2,    36] loss: 0.628\n",
      "[2,    41] loss: 0.605\n",
      "[2,    46] loss: 0.612\n",
      "[2,    51] loss: 0.614\n",
      "[2,    56] loss: 0.551\n",
      "[2,    61] loss: 0.607\n",
      "[2,    66] loss: 0.616\n",
      "[2,    71] loss: 0.644\n",
      "[2,    76] loss: 0.614\n",
      "[2,    81] loss: 0.528\n",
      "[2,    86] loss: 0.782\n",
      "[2,    91] loss: 0.550\n",
      "[2,    96] loss: 0.767\n",
      "[2,   101] loss: 0.384\n",
      "[2,   106] loss: 0.526\n",
      "[2,   111] loss: 0.546\n",
      "[2,   116] loss: 0.502\n",
      "[2,   121] loss: 0.595\n",
      "[2,   126] loss: 0.645\n",
      "[2,   131] loss: 0.559\n",
      "[2,   136] loss: 0.404\n",
      "[2,   141] loss: 0.600\n",
      "[2,   146] loss: 0.434\n",
      "[2,   151] loss: 0.595\n",
      "[2,   156] loss: 0.447\n",
      "[2,   161] loss: 0.721\n",
      "[2,   166] loss: 0.784\n",
      "[2,   171] loss: 0.487\n",
      "[2,   176] loss: 0.509\n",
      "[2,   181] loss: 0.740\n",
      "[2,   186] loss: 0.776\n",
      "[2,   191] loss: 0.554\n",
      "[2,   196] loss: 0.462\n",
      "[2,   201] loss: 0.610\n",
      "[2,   206] loss: 0.445\n",
      "[2,   211] loss: 0.526\n",
      "[2,   216] loss: 0.613\n",
      "[2,   221] loss: 0.430\n",
      "[2,   226] loss: 0.512\n",
      "[2,   231] loss: 0.549\n",
      "[2,   236] loss: 0.470\n",
      "[2,   241] loss: 0.539\n",
      "[2,   246] loss: 0.594\n",
      "[2,   251] loss: 0.597\n",
      "[2,   256] loss: 0.561\n",
      "[2,   261] loss: 0.560\n",
      "[2,   266] loss: 0.641\n",
      "[2,   271] loss: 0.700\n",
      "[2,   276] loss: 0.498\n",
      "[2,   281] loss: 0.515\n",
      "[2,   286] loss: 0.586\n",
      "[2,   291] loss: 0.315\n",
      "[2,   296] loss: 0.457\n",
      "[2,   301] loss: 0.757\n",
      "[2,   306] loss: 0.759\n",
      "[2,   311] loss: 0.670\n",
      "[2,   316] loss: 0.603\n",
      "[2,   321] loss: 0.582\n",
      "[2,   326] loss: 0.603\n",
      "[2,   331] loss: 0.613\n",
      "Epoch : 1, Accuracy : 0.7650957107543945\n",
      "[3,     1] loss: 0.069\n",
      "[3,     6] loss: 0.589\n",
      "[3,    11] loss: 0.481\n",
      "[3,    16] loss: 0.483\n",
      "[3,    21] loss: 0.664\n",
      "[3,    26] loss: 0.454\n",
      "[3,    31] loss: 0.445\n",
      "[3,    36] loss: 0.440\n",
      "[3,    41] loss: 0.521\n",
      "[3,    46] loss: 0.471\n",
      "[3,    51] loss: 0.536\n",
      "[3,    56] loss: 0.486\n",
      "[3,    61] loss: 0.547\n",
      "[3,    66] loss: 0.583\n",
      "[3,    71] loss: 0.521\n",
      "[3,    76] loss: 0.549\n",
      "[3,    81] loss: 0.515\n",
      "[3,    86] loss: 0.453\n",
      "[3,    91] loss: 0.648\n",
      "[3,    96] loss: 0.437\n",
      "[3,   101] loss: 0.449\n",
      "[3,   106] loss: 0.414\n",
      "[3,   111] loss: 0.404\n",
      "[3,   116] loss: 0.494\n",
      "[3,   121] loss: 0.464\n",
      "[3,   126] loss: 0.701\n",
      "[3,   131] loss: 0.550\n",
      "[3,   136] loss: 0.450\n",
      "[3,   141] loss: 0.450\n",
      "[3,   146] loss: 0.343\n",
      "[3,   151] loss: 0.551\n",
      "[3,   156] loss: 0.483\n",
      "[3,   161] loss: 0.542\n",
      "[3,   166] loss: 0.572\n",
      "[3,   171] loss: 0.535\n",
      "[3,   176] loss: 0.460\n",
      "[3,   181] loss: 0.543\n",
      "[3,   186] loss: 0.463\n",
      "[3,   191] loss: 0.536\n",
      "[3,   196] loss: 0.557\n",
      "[3,   201] loss: 0.372\n",
      "[3,   206] loss: 0.550\n",
      "[3,   211] loss: 0.594\n",
      "[3,   216] loss: 0.628\n",
      "[3,   221] loss: 0.407\n",
      "[3,   226] loss: 0.469\n",
      "[3,   231] loss: 0.387\n",
      "[3,   236] loss: 0.526\n",
      "[3,   241] loss: 0.540\n",
      "[3,   246] loss: 0.506\n",
      "[3,   251] loss: 0.451\n",
      "[3,   256] loss: 0.615\n",
      "[3,   261] loss: 0.521\n",
      "[3,   266] loss: 0.554\n",
      "[3,   271] loss: 0.386\n",
      "[3,   276] loss: 0.451\n",
      "[3,   281] loss: 0.411\n",
      "[3,   286] loss: 0.301\n",
      "[3,   291] loss: 0.460\n",
      "[3,   296] loss: 0.513\n",
      "[3,   301] loss: 0.357\n",
      "[3,   306] loss: 0.622\n",
      "[3,   311] loss: 0.305\n",
      "[3,   316] loss: 0.824\n",
      "[3,   321] loss: 0.372\n",
      "[3,   326] loss: 0.403\n",
      "[3,   331] loss: 0.679\n",
      "Epoch : 2, Accuracy : 0.7857142686843872\n",
      "[4,     1] loss: 0.091\n",
      "[4,     6] loss: 0.440\n",
      "[4,    11] loss: 0.608\n",
      "[4,    16] loss: 0.533\n",
      "[4,    21] loss: 0.503\n",
      "[4,    26] loss: 0.528\n",
      "[4,    31] loss: 0.592\n",
      "[4,    36] loss: 0.519\n",
      "[4,    41] loss: 0.533\n",
      "[4,    46] loss: 0.379\n",
      "[4,    51] loss: 0.654\n",
      "[4,    56] loss: 0.427\n",
      "[4,    61] loss: 0.467\n",
      "[4,    66] loss: 0.425\n",
      "[4,    71] loss: 0.380\n",
      "[4,    76] loss: 0.564\n",
      "[4,    81] loss: 0.533\n",
      "[4,    86] loss: 0.606\n",
      "[4,    91] loss: 0.695\n",
      "[4,    96] loss: 0.457\n",
      "[4,   101] loss: 0.455\n",
      "[4,   106] loss: 0.445\n",
      "[4,   111] loss: 0.497\n",
      "[4,   116] loss: 0.548\n",
      "[4,   121] loss: 0.456\n",
      "[4,   126] loss: 0.559\n",
      "[4,   131] loss: 0.441\n",
      "[4,   136] loss: 0.433\n",
      "[4,   141] loss: 0.312\n",
      "[4,   146] loss: 0.480\n",
      "[4,   151] loss: 0.516\n",
      "[4,   156] loss: 0.386\n",
      "[4,   161] loss: 0.509\n",
      "[4,   166] loss: 0.471\n",
      "[4,   171] loss: 0.407\n",
      "[4,   176] loss: 0.409\n",
      "[4,   181] loss: 0.418\n",
      "[4,   186] loss: 0.526\n",
      "[4,   191] loss: 0.284\n",
      "[4,   196] loss: 0.513\n",
      "[4,   201] loss: 0.320\n",
      "[4,   206] loss: 0.997\n",
      "[4,   211] loss: 0.482\n",
      "[4,   216] loss: 0.419\n",
      "[4,   221] loss: 0.611\n",
      "[4,   226] loss: 0.510\n",
      "[4,   231] loss: 0.278\n",
      "[4,   236] loss: 0.534\n",
      "[4,   241] loss: 0.410\n",
      "[4,   246] loss: 0.519\n",
      "[4,   251] loss: 0.310\n",
      "[4,   256] loss: 0.518\n",
      "[4,   261] loss: 0.471\n",
      "[4,   266] loss: 0.332\n",
      "[4,   271] loss: 0.408\n",
      "[4,   276] loss: 0.231\n",
      "[4,   281] loss: 0.468\n",
      "[4,   286] loss: 0.337\n",
      "[4,   291] loss: 0.353\n",
      "[4,   296] loss: 0.395\n",
      "[4,   301] loss: 0.650\n",
      "[4,   306] loss: 0.456\n",
      "[4,   311] loss: 0.585\n",
      "[4,   316] loss: 0.783\n",
      "[4,   321] loss: 0.550\n",
      "[4,   326] loss: 0.545\n",
      "[4,   331] loss: 0.496\n",
      "Epoch : 3, Accuracy : 0.8033873438835144\n",
      "[5,     1] loss: 0.109\n",
      "[5,     6] loss: 0.466\n",
      "[5,    11] loss: 0.501\n",
      "[5,    16] loss: 0.451\n",
      "[5,    21] loss: 0.495\n",
      "[5,    26] loss: 0.410\n",
      "[5,    31] loss: 0.422\n",
      "[5,    36] loss: 0.565\n",
      "[5,    41] loss: 0.581\n",
      "[5,    46] loss: 0.503\n",
      "[5,    51] loss: 0.381\n",
      "[5,    56] loss: 0.524\n",
      "[5,    61] loss: 0.379\n",
      "[5,    66] loss: 0.435\n",
      "[5,    71] loss: 0.370\n",
      "[5,    76] loss: 0.429\n",
      "[5,    81] loss: 0.301\n",
      "[5,    86] loss: 0.338\n",
      "[5,    91] loss: 0.544\n",
      "[5,    96] loss: 0.300\n",
      "[5,   101] loss: 0.533\n",
      "[5,   106] loss: 0.438\n",
      "[5,   111] loss: 0.477\n",
      "[5,   116] loss: 0.526\n",
      "[5,   121] loss: 0.448\n",
      "[5,   126] loss: 0.400\n",
      "[5,   131] loss: 0.470\n",
      "[5,   136] loss: 0.554\n",
      "[5,   141] loss: 0.569\n",
      "[5,   146] loss: 0.348\n",
      "[5,   151] loss: 0.363\n",
      "[5,   156] loss: 0.576\n",
      "[5,   161] loss: 0.448\n",
      "[5,   166] loss: 0.541\n",
      "[5,   171] loss: 0.381\n",
      "[5,   176] loss: 0.339\n",
      "[5,   181] loss: 0.345\n",
      "[5,   186] loss: 0.679\n",
      "[5,   191] loss: 0.417\n",
      "[5,   196] loss: 0.323\n",
      "[5,   201] loss: 0.416\n",
      "[5,   206] loss: 0.359\n",
      "[5,   211] loss: 0.592\n",
      "[5,   216] loss: 0.475\n",
      "[5,   221] loss: 0.358\n",
      "[5,   226] loss: 0.522\n",
      "[5,   231] loss: 0.376\n",
      "[5,   236] loss: 0.474\n",
      "[5,   241] loss: 0.410\n",
      "[5,   246] loss: 0.506\n",
      "[5,   251] loss: 0.360\n",
      "[5,   256] loss: 0.430\n",
      "[5,   261] loss: 0.470\n",
      "[5,   266] loss: 0.391\n",
      "[5,   271] loss: 0.429\n",
      "[5,   276] loss: 0.590\n",
      "[5,   281] loss: 0.388\n",
      "[5,   286] loss: 0.498\n",
      "[5,   291] loss: 0.326\n",
      "[5,   296] loss: 0.292\n",
      "[5,   301] loss: 0.427\n",
      "[5,   306] loss: 0.604\n",
      "[5,   311] loss: 0.446\n",
      "[5,   316] loss: 0.538\n",
      "[5,   321] loss: 0.450\n",
      "[5,   326] loss: 0.542\n",
      "[5,   331] loss: 0.315\n",
      "Epoch : 4, Accuracy : 0.784977912902832\n",
      "[6,     1] loss: 0.058\n",
      "[6,     6] loss: 0.528\n",
      "[6,    11] loss: 0.317\n",
      "[6,    16] loss: 0.326\n",
      "[6,    21] loss: 0.313\n",
      "[6,    26] loss: 0.256\n",
      "[6,    31] loss: 0.395\n",
      "[6,    36] loss: 0.443\n",
      "[6,    41] loss: 0.508\n",
      "[6,    46] loss: 0.339\n",
      "[6,    51] loss: 0.403\n",
      "[6,    56] loss: 0.314\n",
      "[6,    61] loss: 0.338\n",
      "[6,    66] loss: 0.438\n",
      "[6,    71] loss: 0.273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,    76] loss: 0.498\n",
      "[6,    81] loss: 0.497\n",
      "[6,    86] loss: 0.471\n",
      "[6,    91] loss: 0.474\n",
      "[6,    96] loss: 0.504\n",
      "[6,   101] loss: 0.554\n",
      "[6,   106] loss: 0.363\n",
      "[6,   111] loss: 0.357\n",
      "[6,   116] loss: 0.375\n",
      "[6,   121] loss: 0.312\n",
      "[6,   126] loss: 0.354\n",
      "[6,   131] loss: 0.396\n",
      "[6,   136] loss: 0.256\n",
      "[6,   141] loss: 0.417\n",
      "[6,   146] loss: 0.420\n",
      "[6,   151] loss: 0.319\n",
      "[6,   156] loss: 0.297\n",
      "[6,   161] loss: 0.299\n",
      "[6,   166] loss: 0.455\n",
      "[6,   171] loss: 0.278\n",
      "[6,   176] loss: 0.424\n",
      "[6,   181] loss: 0.291\n",
      "[6,   186] loss: 0.576\n",
      "[6,   191] loss: 0.466\n",
      "[6,   196] loss: 0.355\n",
      "[6,   201] loss: 0.583\n",
      "[6,   206] loss: 0.418\n",
      "[6,   211] loss: 0.365\n",
      "[6,   216] loss: 0.482\n",
      "[6,   221] loss: 0.276\n",
      "[6,   226] loss: 0.477\n",
      "[6,   231] loss: 0.479\n",
      "[6,   236] loss: 0.328\n",
      "[6,   241] loss: 0.485\n",
      "[6,   246] loss: 0.347\n",
      "[6,   251] loss: 0.424\n",
      "[6,   256] loss: 0.377\n",
      "[6,   261] loss: 0.301\n",
      "[6,   266] loss: 0.499\n",
      "[6,   271] loss: 0.323\n",
      "[6,   276] loss: 0.561\n",
      "[6,   281] loss: 0.337\n",
      "[6,   286] loss: 0.559\n",
      "[6,   291] loss: 0.301\n",
      "[6,   296] loss: 0.465\n",
      "[6,   301] loss: 0.560\n",
      "[6,   306] loss: 0.352\n",
      "[6,   311] loss: 0.494\n",
      "[6,   316] loss: 0.337\n",
      "[6,   321] loss: 0.222\n",
      "[6,   326] loss: 0.430\n",
      "[6,   331] loss: 0.403\n",
      "Epoch : 5, Accuracy : 0.8262150287628174\n",
      "[7,     1] loss: 0.053\n",
      "[7,     6] loss: 0.361\n",
      "[7,    11] loss: 0.380\n",
      "[7,    16] loss: 0.549\n",
      "[7,    21] loss: 0.307\n",
      "[7,    26] loss: 0.306\n",
      "[7,    31] loss: 0.518\n",
      "[7,    36] loss: 0.265\n",
      "[7,    41] loss: 0.238\n",
      "[7,    46] loss: 0.260\n",
      "[7,    51] loss: 0.226\n",
      "[7,    56] loss: 0.692\n",
      "[7,    61] loss: 0.266\n",
      "[7,    66] loss: 0.287\n",
      "[7,    71] loss: 0.381\n",
      "[7,    76] loss: 0.303\n",
      "[7,    81] loss: 0.413\n",
      "[7,    86] loss: 0.365\n",
      "[7,    91] loss: 0.470\n",
      "[7,    96] loss: 0.377\n",
      "[7,   101] loss: 0.479\n",
      "[7,   106] loss: 0.370\n",
      "[7,   111] loss: 0.320\n",
      "[7,   116] loss: 0.328\n",
      "[7,   121] loss: 0.423\n",
      "[7,   126] loss: 0.332\n",
      "[7,   131] loss: 0.322\n",
      "[7,   136] loss: 0.236\n",
      "[7,   141] loss: 0.455\n",
      "[7,   146] loss: 0.320\n",
      "[7,   151] loss: 0.367\n",
      "[7,   156] loss: 0.253\n",
      "[7,   161] loss: 0.302\n",
      "[7,   166] loss: 0.352\n",
      "[7,   171] loss: 0.457\n",
      "[7,   176] loss: 0.352\n",
      "[7,   181] loss: 0.394\n",
      "[7,   186] loss: 0.389\n",
      "[7,   191] loss: 0.343\n",
      "[7,   196] loss: 0.440\n",
      "[7,   201] loss: 0.429\n",
      "[7,   206] loss: 0.245\n",
      "[7,   211] loss: 0.556\n",
      "[7,   216] loss: 0.199\n",
      "[7,   221] loss: 0.309\n",
      "[7,   226] loss: 0.735\n",
      "[7,   231] loss: 0.347\n",
      "[7,   236] loss: 0.296\n",
      "[7,   241] loss: 0.402\n",
      "[7,   246] loss: 0.300\n",
      "[7,   251] loss: 0.412\n",
      "[7,   256] loss: 0.391\n",
      "[7,   261] loss: 0.224\n",
      "[7,   266] loss: 0.212\n",
      "[7,   271] loss: 0.322\n",
      "[7,   276] loss: 0.395\n",
      "[7,   281] loss: 0.509\n",
      "[7,   286] loss: 0.309\n",
      "[7,   291] loss: 0.326\n",
      "[7,   296] loss: 0.429\n",
      "[7,   301] loss: 0.352\n",
      "[7,   306] loss: 0.482\n",
      "[7,   311] loss: 0.336\n",
      "[7,   316] loss: 0.281\n",
      "[7,   321] loss: 0.343\n",
      "[7,   326] loss: 0.365\n",
      "[7,   331] loss: 0.388\n",
      "Epoch : 6, Accuracy : 0.8247422575950623\n",
      "[8,     1] loss: 0.125\n",
      "[8,     6] loss: 0.345\n",
      "[8,    11] loss: 0.310\n",
      "[8,    16] loss: 0.324\n",
      "[8,    21] loss: 0.351\n",
      "[8,    26] loss: 0.286\n",
      "[8,    31] loss: 0.308\n",
      "[8,    36] loss: 0.291\n",
      "[8,    41] loss: 0.547\n",
      "[8,    46] loss: 0.412\n",
      "[8,    51] loss: 0.536\n",
      "[8,    56] loss: 0.363\n",
      "[8,    61] loss: 0.454\n",
      "[8,    66] loss: 0.547\n",
      "[8,    71] loss: 0.746\n",
      "[8,    76] loss: 0.437\n",
      "[8,    81] loss: 0.349\n",
      "[8,    86] loss: 0.411\n",
      "[8,    91] loss: 0.264\n",
      "[8,    96] loss: 0.265\n",
      "[8,   101] loss: 0.500\n",
      "[8,   106] loss: 0.508\n",
      "[8,   111] loss: 0.288\n",
      "[8,   116] loss: 0.603\n",
      "[8,   121] loss: 0.311\n",
      "[8,   126] loss: 0.284\n",
      "[8,   131] loss: 0.479\n",
      "[8,   136] loss: 0.398\n",
      "[8,   141] loss: 0.536\n",
      "[8,   146] loss: 0.425\n",
      "[8,   151] loss: 0.449\n",
      "[8,   156] loss: 0.410\n",
      "[8,   161] loss: 0.331\n",
      "[8,   166] loss: 0.514\n",
      "[8,   171] loss: 0.415\n",
      "[8,   176] loss: 0.236\n",
      "[8,   181] loss: 0.592\n",
      "[8,   186] loss: 0.269\n",
      "[8,   191] loss: 0.269\n",
      "[8,   196] loss: 0.436\n",
      "[8,   201] loss: 0.326\n",
      "[8,   206] loss: 0.314\n",
      "[8,   211] loss: 0.297\n",
      "[8,   216] loss: 0.213\n",
      "[8,   221] loss: 0.345\n",
      "[8,   226] loss: 0.231\n",
      "[8,   231] loss: 0.410\n",
      "[8,   236] loss: 0.282\n",
      "[8,   241] loss: 0.344\n",
      "[8,   246] loss: 0.268\n",
      "[8,   251] loss: 0.562\n",
      "[8,   256] loss: 0.396\n",
      "[8,   261] loss: 0.408\n",
      "[8,   266] loss: 0.503\n",
      "[8,   271] loss: 0.389\n",
      "[8,   276] loss: 0.323\n",
      "[8,   281] loss: 0.281\n",
      "[8,   286] loss: 0.514\n",
      "[8,   291] loss: 0.331\n",
      "[8,   296] loss: 0.349\n",
      "[8,   301] loss: 0.214\n",
      "[8,   306] loss: 0.509\n",
      "[8,   311] loss: 0.319\n",
      "[8,   316] loss: 0.404\n",
      "[8,   321] loss: 0.349\n",
      "[8,   326] loss: 0.358\n",
      "[8,   331] loss: 0.363\n",
      "Epoch : 7, Accuracy : 0.8033873438835144\n",
      "[9,     1] loss: 0.069\n",
      "[9,     6] loss: 0.356\n",
      "[9,    11] loss: 0.526\n",
      "[9,    16] loss: 0.273\n",
      "[9,    21] loss: 0.507\n",
      "[9,    26] loss: 0.344\n",
      "[9,    31] loss: 0.248\n",
      "[9,    36] loss: 0.321\n",
      "[9,    41] loss: 0.253\n",
      "[9,    46] loss: 0.312\n",
      "[9,    51] loss: 0.345\n",
      "[9,    56] loss: 0.333\n",
      "[9,    61] loss: 0.285\n",
      "[9,    66] loss: 0.319\n",
      "[9,    71] loss: 0.253\n",
      "[9,    76] loss: 0.240\n",
      "[9,    81] loss: 0.443\n",
      "[9,    86] loss: 0.331\n",
      "[9,    91] loss: 0.312\n",
      "[9,    96] loss: 0.494\n",
      "[9,   101] loss: 0.484\n",
      "[9,   106] loss: 0.397\n",
      "[9,   111] loss: 0.281\n",
      "[9,   116] loss: 0.261\n",
      "[9,   121] loss: 0.303\n",
      "[9,   126] loss: 0.549\n",
      "[9,   131] loss: 0.378\n",
      "[9,   136] loss: 0.384\n",
      "[9,   141] loss: 0.238\n",
      "[9,   146] loss: 0.376\n",
      "[9,   151] loss: 0.342\n",
      "[9,   156] loss: 0.289\n",
      "[9,   161] loss: 0.248\n",
      "[9,   166] loss: 0.543\n",
      "[9,   171] loss: 0.343\n",
      "[9,   176] loss: 0.292\n",
      "[9,   181] loss: 0.403\n",
      "[9,   186] loss: 0.212\n",
      "[9,   191] loss: 0.235\n",
      "[9,   196] loss: 0.278\n",
      "[9,   201] loss: 0.422\n",
      "[9,   206] loss: 0.276\n",
      "[9,   211] loss: 0.343\n",
      "[9,   216] loss: 0.348\n",
      "[9,   221] loss: 0.523\n",
      "[9,   226] loss: 0.449\n",
      "[9,   231] loss: 0.433\n",
      "[9,   236] loss: 0.364\n",
      "[9,   241] loss: 0.291\n",
      "[9,   246] loss: 0.329\n",
      "[9,   251] loss: 0.290\n",
      "[9,   256] loss: 0.418\n",
      "[9,   261] loss: 0.275\n",
      "[9,   266] loss: 0.464\n",
      "[9,   271] loss: 0.333\n",
      "[9,   276] loss: 0.408\n",
      "[9,   281] loss: 0.414\n",
      "[9,   286] loss: 0.556\n",
      "[9,   291] loss: 0.260\n",
      "[9,   296] loss: 0.311\n",
      "[9,   301] loss: 0.252\n",
      "[9,   306] loss: 0.284\n",
      "[9,   311] loss: 0.304\n",
      "[9,   316] loss: 0.333\n",
      "[9,   321] loss: 0.531\n",
      "[9,   326] loss: 0.402\n",
      "[9,   331] loss: 0.474\n",
      "Epoch : 8, Accuracy : 0.8188512325286865\n",
      "[10,     1] loss: 0.109\n",
      "[10,     6] loss: 0.271\n",
      "[10,    11] loss: 0.347\n",
      "[10,    16] loss: 0.421\n",
      "[10,    21] loss: 0.270\n",
      "[10,    26] loss: 0.410\n",
      "[10,    31] loss: 0.305\n",
      "[10,    36] loss: 0.355\n",
      "[10,    41] loss: 0.232\n",
      "[10,    46] loss: 0.288\n",
      "[10,    51] loss: 0.390\n",
      "[10,    56] loss: 0.256\n",
      "[10,    61] loss: 0.242\n",
      "[10,    66] loss: 0.162\n",
      "[10,    71] loss: 0.102\n",
      "[10,    76] loss: 0.225\n",
      "[10,    81] loss: 0.386\n",
      "[10,    86] loss: 0.268\n",
      "[10,    91] loss: 0.635\n",
      "[10,    96] loss: 0.422\n",
      "[10,   101] loss: 0.373\n",
      "[10,   106] loss: 0.335\n",
      "[10,   111] loss: 0.343\n",
      "[10,   116] loss: 0.461\n",
      "[10,   121] loss: 0.348\n",
      "[10,   126] loss: 0.456\n",
      "[10,   131] loss: 0.438\n",
      "[10,   136] loss: 0.284\n",
      "[10,   141] loss: 0.467\n",
      "[10,   146] loss: 0.469\n",
      "[10,   151] loss: 0.278\n",
      "[10,   156] loss: 0.521\n",
      "[10,   161] loss: 0.191\n",
      "[10,   166] loss: 0.287\n",
      "[10,   171] loss: 0.274\n",
      "[10,   176] loss: 0.248\n",
      "[10,   181] loss: 0.546\n",
      "[10,   186] loss: 0.348\n",
      "[10,   191] loss: 0.293\n",
      "[10,   196] loss: 0.456\n",
      "[10,   201] loss: 0.382\n",
      "[10,   206] loss: 0.332\n",
      "[10,   211] loss: 0.242\n",
      "[10,   216] loss: 0.406\n",
      "[10,   221] loss: 0.542\n",
      "[10,   226] loss: 0.344\n",
      "[10,   231] loss: 0.330\n",
      "[10,   236] loss: 0.283\n",
      "[10,   241] loss: 0.310\n",
      "[10,   246] loss: 0.323\n",
      "[10,   251] loss: 0.285\n",
      "[10,   256] loss: 0.284\n",
      "[10,   261] loss: 0.362\n",
      "[10,   266] loss: 0.252\n",
      "[10,   271] loss: 0.399\n",
      "[10,   276] loss: 0.432\n",
      "[10,   281] loss: 0.322\n",
      "[10,   286] loss: 0.422\n",
      "[10,   291] loss: 0.293\n",
      "[10,   296] loss: 0.338\n",
      "[10,   301] loss: 0.634\n",
      "[10,   306] loss: 0.221\n",
      "[10,   311] loss: 0.394\n",
      "[10,   316] loss: 0.369\n",
      "[10,   321] loss: 0.252\n",
      "[10,   326] loss: 0.363\n",
      "[10,   331] loss: 0.343\n",
      "Epoch : 9, Accuracy : 0.822533130645752\n",
      "[11,     1] loss: 0.023\n",
      "[11,     6] loss: 0.395\n",
      "[11,    11] loss: 0.386\n",
      "[11,    16] loss: 0.319\n",
      "[11,    21] loss: 0.308\n",
      "[11,    26] loss: 0.347\n",
      "[11,    31] loss: 0.217\n",
      "[11,    36] loss: 0.497\n",
      "[11,    41] loss: 0.366\n",
      "[11,    46] loss: 0.402\n",
      "[11,    51] loss: 0.265\n",
      "[11,    56] loss: 0.292\n",
      "[11,    61] loss: 0.234\n",
      "[11,    66] loss: 0.255\n",
      "[11,    71] loss: 0.300\n",
      "[11,    76] loss: 0.373\n",
      "[11,    81] loss: 0.404\n",
      "[11,    86] loss: 0.364\n",
      "[11,    91] loss: 0.224\n",
      "[11,    96] loss: 0.181\n",
      "[11,   101] loss: 0.232\n",
      "[11,   106] loss: 0.219\n",
      "[11,   111] loss: 0.340\n",
      "[11,   116] loss: 0.330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11,   121] loss: 0.223\n",
      "[11,   126] loss: 0.252\n",
      "[11,   131] loss: 0.263\n",
      "[11,   136] loss: 0.299\n",
      "[11,   141] loss: 0.244\n",
      "[11,   146] loss: 0.205\n",
      "[11,   151] loss: 0.291\n",
      "[11,   156] loss: 0.354\n",
      "[11,   161] loss: 0.163\n",
      "[11,   166] loss: 0.261\n",
      "[11,   171] loss: 0.246\n",
      "[11,   176] loss: 0.333\n",
      "[11,   181] loss: 0.272\n",
      "[11,   186] loss: 0.400\n",
      "[11,   191] loss: 0.226\n",
      "[11,   196] loss: 0.275\n",
      "[11,   201] loss: 0.362\n",
      "[11,   206] loss: 0.367\n",
      "[11,   211] loss: 0.268\n",
      "[11,   216] loss: 0.323\n",
      "[11,   221] loss: 0.263\n",
      "[11,   226] loss: 0.290\n",
      "[11,   231] loss: 0.286\n",
      "[11,   236] loss: 0.294\n",
      "[11,   241] loss: 0.262\n",
      "[11,   246] loss: 0.430\n",
      "[11,   251] loss: 0.276\n",
      "[11,   256] loss: 0.168\n",
      "[11,   261] loss: 0.441\n",
      "[11,   266] loss: 0.147\n",
      "[11,   271] loss: 0.355\n",
      "[11,   276] loss: 0.298\n",
      "[11,   281] loss: 0.259\n",
      "[11,   286] loss: 0.354\n",
      "[11,   291] loss: 0.219\n",
      "[11,   296] loss: 0.163\n",
      "[11,   301] loss: 0.595\n",
      "[11,   306] loss: 0.296\n",
      "[11,   311] loss: 0.477\n",
      "[11,   316] loss: 0.413\n",
      "[11,   321] loss: 0.451\n",
      "[11,   326] loss: 0.222\n",
      "[11,   331] loss: 0.526\n",
      "Epoch : 10, Accuracy : 0.8262150287628174\n",
      "[12,     1] loss: 0.085\n",
      "[12,     6] loss: 0.282\n",
      "[12,    11] loss: 0.374\n",
      "[12,    16] loss: 0.324\n",
      "[12,    21] loss: 0.465\n",
      "[12,    26] loss: 0.153\n",
      "[12,    31] loss: 0.260\n",
      "[12,    36] loss: 0.184\n",
      "[12,    41] loss: 0.340\n",
      "[12,    46] loss: 0.342\n",
      "[12,    51] loss: 0.202\n",
      "[12,    56] loss: 0.319\n",
      "[12,    61] loss: 0.275\n",
      "[12,    66] loss: 0.170\n",
      "[12,    71] loss: 0.430\n",
      "[12,    76] loss: 0.185\n",
      "[12,    81] loss: 0.377\n",
      "[12,    86] loss: 0.563\n",
      "[12,    91] loss: 0.557\n",
      "[12,    96] loss: 0.339\n",
      "[12,   101] loss: 0.387\n",
      "[12,   106] loss: 0.464\n",
      "[12,   111] loss: 0.306\n",
      "[12,   116] loss: 0.248\n",
      "[12,   121] loss: 0.335\n",
      "[12,   126] loss: 0.418\n",
      "[12,   131] loss: 0.375\n",
      "[12,   136] loss: 0.222\n",
      "[12,   141] loss: 0.202\n",
      "[12,   146] loss: 0.183\n",
      "[12,   151] loss: 0.438\n",
      "[12,   156] loss: 0.668\n",
      "[12,   161] loss: 0.311\n",
      "[12,   166] loss: 0.403\n",
      "[12,   171] loss: 0.218\n",
      "[12,   176] loss: 0.160\n",
      "[12,   181] loss: 0.522\n",
      "[12,   186] loss: 0.295\n",
      "[12,   191] loss: 0.472\n",
      "[12,   196] loss: 0.368\n",
      "[12,   201] loss: 0.294\n",
      "[12,   206] loss: 0.356\n",
      "[12,   211] loss: 0.257\n",
      "[12,   216] loss: 0.334\n",
      "[12,   221] loss: 0.417\n",
      "[12,   226] loss: 0.445\n",
      "[12,   231] loss: 0.268\n",
      "[12,   236] loss: 0.198\n",
      "[12,   241] loss: 0.237\n",
      "[12,   246] loss: 0.173\n",
      "[12,   251] loss: 0.298\n",
      "[12,   256] loss: 0.375\n",
      "[12,   261] loss: 0.277\n",
      "[12,   266] loss: 0.304\n",
      "[12,   271] loss: 0.258\n",
      "[12,   276] loss: 0.297\n",
      "[12,   281] loss: 0.302\n",
      "[12,   286] loss: 0.587\n",
      "[12,   291] loss: 0.240\n",
      "[12,   296] loss: 0.398\n",
      "[12,   301] loss: 0.345\n",
      "[12,   306] loss: 0.321\n",
      "[12,   311] loss: 0.303\n",
      "[12,   316] loss: 0.245\n",
      "[12,   321] loss: 0.332\n",
      "[12,   326] loss: 0.262\n",
      "[12,   331] loss: 0.331\n",
      "Epoch : 11, Accuracy : 0.8195876479148865\n",
      "[13,     1] loss: 0.058\n",
      "[13,     6] loss: 0.310\n",
      "[13,    11] loss: 0.421\n",
      "[13,    16] loss: 0.387\n",
      "[13,    21] loss: 0.287\n",
      "[13,    26] loss: 0.306\n",
      "[13,    31] loss: 0.301\n",
      "[13,    36] loss: 0.257\n",
      "[13,    41] loss: 0.150\n",
      "[13,    46] loss: 0.101\n",
      "[13,    51] loss: 0.268\n",
      "[13,    56] loss: 0.485\n",
      "[13,    61] loss: 0.393\n",
      "[13,    66] loss: 0.305\n",
      "[13,    71] loss: 0.335\n",
      "[13,    76] loss: 0.278\n",
      "[13,    81] loss: 0.348\n",
      "[13,    86] loss: 0.243\n",
      "[13,    91] loss: 0.277\n",
      "[13,    96] loss: 0.254\n",
      "[13,   101] loss: 0.174\n",
      "[13,   106] loss: 0.157\n",
      "[13,   111] loss: 0.120\n",
      "[13,   116] loss: 0.160\n",
      "[13,   121] loss: 0.252\n",
      "[13,   126] loss: 0.237\n",
      "[13,   131] loss: 0.378\n",
      "[13,   136] loss: 0.253\n",
      "[13,   141] loss: 0.279\n",
      "[13,   146] loss: 0.262\n",
      "[13,   151] loss: 0.424\n",
      "[13,   156] loss: 0.422\n",
      "[13,   161] loss: 0.339\n",
      "[13,   166] loss: 0.257\n",
      "[13,   171] loss: 0.358\n",
      "[13,   176] loss: 0.484\n",
      "[13,   181] loss: 0.328\n",
      "[13,   186] loss: 0.327\n",
      "[13,   191] loss: 0.304\n",
      "[13,   196] loss: 0.266\n",
      "[13,   201] loss: 0.293\n",
      "[13,   206] loss: 0.401\n",
      "[13,   211] loss: 0.352\n",
      "[13,   216] loss: 0.431\n",
      "[13,   221] loss: 0.256\n",
      "[13,   226] loss: 0.286\n",
      "[13,   231] loss: 0.247\n",
      "[13,   236] loss: 0.356\n",
      "[13,   241] loss: 0.320\n",
      "[13,   246] loss: 0.351\n",
      "[13,   251] loss: 0.423\n",
      "[13,   256] loss: 0.375\n",
      "[13,   261] loss: 0.273\n",
      "[13,   266] loss: 0.716\n",
      "[13,   271] loss: 0.390\n",
      "[13,   276] loss: 0.399\n",
      "[13,   281] loss: 0.427\n",
      "[13,   286] loss: 0.223\n",
      "[13,   291] loss: 0.356\n",
      "[13,   296] loss: 0.342\n",
      "[13,   301] loss: 0.508\n",
      "[13,   306] loss: 0.306\n",
      "[13,   311] loss: 0.286\n",
      "[13,   316] loss: 0.252\n",
      "[13,   321] loss: 0.299\n",
      "[13,   326] loss: 0.213\n",
      "[13,   331] loss: 0.285\n",
      "Epoch : 12, Accuracy : 0.8188512325286865\n",
      "[14,     1] loss: 0.024\n",
      "[14,     6] loss: 0.122\n",
      "[14,    11] loss: 0.234\n",
      "[14,    16] loss: 0.323\n",
      "[14,    21] loss: 0.279\n",
      "[14,    26] loss: 0.255\n",
      "[14,    31] loss: 0.375\n",
      "[14,    36] loss: 0.154\n",
      "[14,    41] loss: 0.386\n",
      "[14,    46] loss: 0.154\n",
      "[14,    51] loss: 0.253\n",
      "[14,    56] loss: 0.298\n",
      "[14,    61] loss: 0.351\n",
      "[14,    66] loss: 0.198\n",
      "[14,    71] loss: 0.242\n",
      "[14,    76] loss: 0.205\n",
      "[14,    81] loss: 0.334\n",
      "[14,    86] loss: 0.190\n",
      "[14,    91] loss: 0.275\n",
      "[14,    96] loss: 0.406\n",
      "[14,   101] loss: 0.328\n",
      "[14,   106] loss: 0.371\n",
      "[14,   111] loss: 0.177\n",
      "[14,   116] loss: 0.260\n",
      "[14,   121] loss: 0.221\n",
      "[14,   126] loss: 0.213\n",
      "[14,   131] loss: 0.273\n",
      "[14,   136] loss: 0.221\n",
      "[14,   141] loss: 0.194\n",
      "[14,   146] loss: 0.169\n",
      "[14,   151] loss: 0.140\n",
      "[14,   156] loss: 0.212\n",
      "[14,   161] loss: 0.226\n",
      "[14,   166] loss: 0.227\n",
      "[14,   171] loss: 0.221\n",
      "[14,   176] loss: 0.207\n",
      "[14,   181] loss: 0.264\n",
      "[14,   186] loss: 0.158\n",
      "[14,   191] loss: 0.424\n",
      "[14,   196] loss: 0.303\n",
      "[14,   201] loss: 0.367\n",
      "[14,   206] loss: 0.317\n",
      "[14,   211] loss: 0.238\n",
      "[14,   216] loss: 0.380\n",
      "[14,   221] loss: 0.176\n",
      "[14,   226] loss: 0.215\n",
      "[14,   231] loss: 0.233\n",
      "[14,   236] loss: 0.357\n",
      "[14,   241] loss: 0.243\n",
      "[14,   246] loss: 0.329\n",
      "[14,   251] loss: 0.212\n",
      "[14,   256] loss: 0.287\n",
      "[14,   261] loss: 0.205\n",
      "[14,   266] loss: 0.385\n",
      "[14,   271] loss: 0.287\n",
      "[14,   276] loss: 0.365\n",
      "[14,   281] loss: 0.394\n",
      "[14,   286] loss: 0.221\n",
      "[14,   291] loss: 0.283\n",
      "[14,   296] loss: 0.160\n",
      "[14,   301] loss: 0.106\n",
      "[14,   306] loss: 0.337\n",
      "[14,   311] loss: 0.337\n",
      "[14,   316] loss: 0.229\n",
      "[14,   321] loss: 0.251\n",
      "[14,   326] loss: 0.346\n",
      "[14,   331] loss: 0.250\n",
      "Epoch : 13, Accuracy : 0.8262150287628174\n",
      "[15,     1] loss: 0.008\n",
      "[15,     6] loss: 0.142\n",
      "[15,    11] loss: 0.437\n",
      "[15,    16] loss: 0.194\n",
      "[15,    21] loss: 0.180\n",
      "[15,    26] loss: 0.238\n",
      "[15,    31] loss: 0.352\n",
      "[15,    36] loss: 0.360\n",
      "[15,    41] loss: 0.655\n",
      "[15,    46] loss: 0.255\n",
      "[15,    51] loss: 0.190\n",
      "[15,    56] loss: 0.510\n",
      "[15,    61] loss: 0.245\n",
      "[15,    66] loss: 0.377\n",
      "[15,    71] loss: 0.397\n",
      "[15,    76] loss: 0.390\n",
      "[15,    81] loss: 0.242\n",
      "[15,    86] loss: 0.216\n",
      "[15,    91] loss: 0.381\n",
      "[15,    96] loss: 0.197\n",
      "[15,   101] loss: 0.396\n",
      "[15,   106] loss: 0.271\n",
      "[15,   111] loss: 0.306\n",
      "[15,   116] loss: 0.467\n",
      "[15,   121] loss: 0.378\n",
      "[15,   126] loss: 0.220\n",
      "[15,   131] loss: 0.107\n",
      "[15,   136] loss: 0.363\n",
      "[15,   141] loss: 0.239\n",
      "[15,   146] loss: 0.331\n",
      "[15,   151] loss: 0.266\n",
      "[15,   156] loss: 0.289\n",
      "[15,   161] loss: 0.358\n",
      "[15,   166] loss: 0.232\n",
      "[15,   171] loss: 0.245\n",
      "[15,   176] loss: 0.189\n",
      "[15,   181] loss: 0.165\n",
      "[15,   186] loss: 0.211\n",
      "[15,   191] loss: 0.227\n",
      "[15,   196] loss: 0.133\n",
      "[15,   201] loss: 0.282\n",
      "[15,   206] loss: 0.160\n",
      "[15,   211] loss: 0.624\n",
      "[15,   216] loss: 0.179\n",
      "[15,   221] loss: 0.276\n",
      "[15,   226] loss: 0.379\n",
      "[15,   231] loss: 0.278\n",
      "[15,   236] loss: 0.132\n",
      "[15,   241] loss: 0.104\n",
      "[15,   246] loss: 0.302\n",
      "[15,   251] loss: 0.254\n",
      "[15,   256] loss: 0.231\n",
      "[15,   261] loss: 0.285\n",
      "[15,   266] loss: 0.320\n",
      "[15,   271] loss: 0.111\n",
      "[15,   276] loss: 0.233\n",
      "[15,   281] loss: 0.247\n",
      "[15,   286] loss: 0.338\n",
      "[15,   291] loss: 0.220\n",
      "[15,   296] loss: 0.188\n",
      "[15,   301] loss: 0.268\n",
      "[15,   306] loss: 0.196\n",
      "[15,   311] loss: 0.334\n",
      "[15,   316] loss: 0.225\n",
      "[15,   321] loss: 0.185\n",
      "[15,   326] loss: 0.289\n",
      "[15,   331] loss: 0.167\n",
      "Epoch : 14, Accuracy : 0.8372606635093689\n",
      "[16,     1] loss: 0.068\n",
      "[16,     6] loss: 0.211\n",
      "[16,    11] loss: 0.167\n",
      "[16,    16] loss: 0.230\n",
      "[16,    21] loss: 0.219\n",
      "[16,    26] loss: 0.324\n",
      "[16,    31] loss: 0.184\n",
      "[16,    36] loss: 0.177\n",
      "[16,    41] loss: 0.203\n",
      "[16,    46] loss: 0.173\n",
      "[16,    51] loss: 0.477\n",
      "[16,    56] loss: 0.279\n",
      "[16,    61] loss: 0.188\n",
      "[16,    66] loss: 0.285\n",
      "[16,    71] loss: 0.172\n",
      "[16,    76] loss: 0.242\n",
      "[16,    81] loss: 0.139\n",
      "[16,    86] loss: 0.239\n",
      "[16,    91] loss: 0.216\n",
      "[16,    96] loss: 0.122\n",
      "[16,   101] loss: 0.265\n",
      "[16,   106] loss: 0.122\n",
      "[16,   111] loss: 0.143\n",
      "[16,   116] loss: 0.165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16,   121] loss: 0.170\n",
      "[16,   126] loss: 0.171\n",
      "[16,   131] loss: 0.276\n",
      "[16,   136] loss: 0.231\n",
      "[16,   141] loss: 0.278\n",
      "[16,   146] loss: 0.095\n",
      "[16,   151] loss: 0.189\n",
      "[16,   156] loss: 0.249\n",
      "[16,   161] loss: 0.181\n",
      "[16,   166] loss: 0.181\n",
      "[16,   171] loss: 0.265\n",
      "[16,   176] loss: 0.205\n",
      "[16,   181] loss: 0.132\n",
      "[16,   186] loss: 0.318\n",
      "[16,   191] loss: 0.204\n",
      "[16,   196] loss: 0.224\n",
      "[16,   201] loss: 0.298\n",
      "[16,   206] loss: 0.198\n",
      "[16,   211] loss: 0.315\n",
      "[16,   216] loss: 0.351\n",
      "[16,   221] loss: 0.199\n",
      "[16,   226] loss: 0.218\n",
      "[16,   231] loss: 0.272\n",
      "[16,   236] loss: 0.301\n",
      "[16,   241] loss: 0.143\n",
      "[16,   246] loss: 0.133\n",
      "[16,   251] loss: 0.289\n",
      "[16,   256] loss: 0.227\n",
      "[16,   261] loss: 0.232\n",
      "[16,   266] loss: 0.260\n",
      "[16,   271] loss: 0.208\n",
      "[16,   276] loss: 0.254\n",
      "[16,   281] loss: 0.278\n",
      "[16,   286] loss: 0.271\n",
      "[16,   291] loss: 0.483\n",
      "[16,   296] loss: 0.227\n",
      "[16,   301] loss: 0.337\n",
      "[16,   306] loss: 0.238\n",
      "[16,   311] loss: 0.383\n",
      "[16,   316] loss: 0.216\n",
      "[16,   321] loss: 0.189\n",
      "[16,   326] loss: 0.112\n",
      "[16,   331] loss: 0.228\n",
      "Epoch : 15, Accuracy : 0.8298969268798828\n",
      "[17,     1] loss: 0.080\n",
      "[17,     6] loss: 0.285\n",
      "[17,    11] loss: 0.152\n",
      "[17,    16] loss: 0.677\n",
      "[17,    21] loss: 0.169\n",
      "[17,    26] loss: 0.235\n",
      "[17,    31] loss: 0.255\n",
      "[17,    36] loss: 0.205\n",
      "[17,    41] loss: 0.258\n",
      "[17,    46] loss: 0.171\n",
      "[17,    51] loss: 0.247\n",
      "[17,    56] loss: 0.275\n",
      "[17,    61] loss: 0.366\n",
      "[17,    66] loss: 0.270\n",
      "[17,    71] loss: 0.240\n",
      "[17,    76] loss: 0.242\n",
      "[17,    81] loss: 0.246\n",
      "[17,    86] loss: 0.321\n",
      "[17,    91] loss: 0.212\n",
      "[17,    96] loss: 0.159\n",
      "[17,   101] loss: 0.328\n",
      "[17,   106] loss: 0.245\n",
      "[17,   111] loss: 0.295\n",
      "[17,   116] loss: 0.407\n",
      "[17,   121] loss: 0.357\n",
      "[17,   126] loss: 0.236\n",
      "[17,   131] loss: 0.214\n",
      "[17,   136] loss: 0.284\n",
      "[17,   141] loss: 0.236\n",
      "[17,   146] loss: 0.194\n",
      "[17,   151] loss: 0.075\n",
      "[17,   156] loss: 0.206\n",
      "[17,   161] loss: 0.239\n",
      "[17,   166] loss: 0.399\n",
      "[17,   171] loss: 0.270\n",
      "[17,   176] loss: 0.217\n",
      "[17,   181] loss: 0.268\n",
      "[17,   186] loss: 0.407\n",
      "[17,   191] loss: 0.283\n",
      "[17,   196] loss: 0.247\n",
      "[17,   201] loss: 0.256\n",
      "[17,   206] loss: 0.307\n",
      "[17,   211] loss: 0.282\n",
      "[17,   216] loss: 0.297\n",
      "[17,   221] loss: 0.181\n",
      "[17,   226] loss: 0.110\n",
      "[17,   231] loss: 0.306\n",
      "[17,   236] loss: 0.227\n",
      "[17,   241] loss: 0.201\n",
      "[17,   246] loss: 0.347\n",
      "[17,   251] loss: 0.282\n",
      "[17,   256] loss: 0.462\n",
      "[17,   261] loss: 0.268\n",
      "[17,   266] loss: 0.286\n",
      "[17,   271] loss: 0.213\n",
      "[17,   276] loss: 0.339\n",
      "[17,   281] loss: 0.237\n",
      "[17,   286] loss: 0.254\n",
      "[17,   291] loss: 0.172\n",
      "[17,   296] loss: 0.269\n",
      "[17,   301] loss: 0.195\n",
      "[17,   306] loss: 0.104\n",
      "[17,   311] loss: 0.254\n",
      "[17,   316] loss: 0.275\n",
      "[17,   321] loss: 0.303\n",
      "[17,   326] loss: 0.399\n",
      "[17,   331] loss: 0.179\n",
      "Epoch : 16, Accuracy : 0.8262150287628174\n",
      "[18,     1] loss: 0.041\n",
      "[18,     6] loss: 0.326\n",
      "[18,    11] loss: 0.281\n",
      "[18,    16] loss: 0.162\n",
      "[18,    21] loss: 0.144\n",
      "[18,    26] loss: 0.124\n",
      "[18,    31] loss: 0.124\n",
      "[18,    36] loss: 0.207\n",
      "[18,    41] loss: 0.153\n",
      "[18,    46] loss: 0.334\n",
      "[18,    51] loss: 0.168\n",
      "[18,    56] loss: 0.195\n",
      "[18,    61] loss: 0.154\n",
      "[18,    66] loss: 0.248\n",
      "[18,    71] loss: 0.283\n",
      "[18,    76] loss: 0.189\n",
      "[18,    81] loss: 0.234\n",
      "[18,    86] loss: 0.225\n",
      "[18,    91] loss: 0.177\n",
      "[18,    96] loss: 0.284\n",
      "[18,   101] loss: 0.275\n",
      "[18,   106] loss: 0.327\n",
      "[18,   111] loss: 0.183\n",
      "[18,   116] loss: 0.259\n",
      "[18,   121] loss: 0.205\n",
      "[18,   126] loss: 0.209\n",
      "[18,   131] loss: 0.304\n",
      "[18,   136] loss: 0.194\n",
      "[18,   141] loss: 0.212\n",
      "[18,   146] loss: 0.118\n",
      "[18,   151] loss: 0.177\n",
      "[18,   156] loss: 0.226\n",
      "[18,   161] loss: 0.205\n",
      "[18,   166] loss: 0.289\n",
      "[18,   171] loss: 0.158\n",
      "[18,   176] loss: 0.167\n",
      "[18,   181] loss: 0.296\n",
      "[18,   186] loss: 0.246\n",
      "[18,   191] loss: 0.187\n",
      "[18,   196] loss: 0.305\n",
      "[18,   201] loss: 0.282\n",
      "[18,   206] loss: 0.200\n",
      "[18,   211] loss: 0.182\n",
      "[18,   216] loss: 0.093\n",
      "[18,   221] loss: 0.106\n",
      "[18,   226] loss: 0.063\n",
      "[18,   231] loss: 0.202\n",
      "[18,   236] loss: 0.222\n",
      "[18,   241] loss: 0.080\n",
      "[18,   246] loss: 0.180\n",
      "[18,   251] loss: 0.221\n",
      "[18,   256] loss: 0.244\n",
      "[18,   261] loss: 0.085\n",
      "[18,   266] loss: 0.186\n",
      "[18,   271] loss: 0.320\n",
      "[18,   276] loss: 0.277\n",
      "[18,   281] loss: 0.398\n",
      "[18,   286] loss: 0.176\n",
      "[18,   291] loss: 0.300\n",
      "[18,   296] loss: 0.219\n",
      "[18,   301] loss: 0.141\n",
      "[18,   306] loss: 0.145\n",
      "[18,   311] loss: 0.210\n",
      "[18,   316] loss: 0.171\n",
      "[18,   321] loss: 0.197\n",
      "[18,   326] loss: 0.303\n",
      "[18,   331] loss: 0.135\n",
      "Epoch : 17, Accuracy : 0.8033873438835144\n",
      "[19,     1] loss: 0.024\n",
      "[19,     6] loss: 0.167\n",
      "[19,    11] loss: 0.104\n",
      "[19,    16] loss: 0.254\n",
      "[19,    21] loss: 0.300\n",
      "[19,    26] loss: 0.115\n",
      "[19,    31] loss: 0.122\n",
      "[19,    36] loss: 0.431\n",
      "[19,    41] loss: 0.356\n",
      "[19,    46] loss: 0.262\n",
      "[19,    51] loss: 0.503\n",
      "[19,    56] loss: 0.424\n",
      "[19,    61] loss: 0.237\n",
      "[19,    66] loss: 0.235\n",
      "[19,    71] loss: 0.243\n",
      "[19,    76] loss: 0.196\n",
      "[19,    81] loss: 0.296\n",
      "[19,    86] loss: 0.124\n",
      "[19,    91] loss: 0.113\n",
      "[19,    96] loss: 0.357\n",
      "[19,   101] loss: 0.158\n",
      "[19,   106] loss: 0.167\n",
      "[19,   111] loss: 0.251\n",
      "[19,   116] loss: 0.229\n",
      "[19,   121] loss: 0.210\n",
      "[19,   126] loss: 0.306\n",
      "[19,   131] loss: 0.237\n",
      "[19,   136] loss: 0.224\n",
      "[19,   141] loss: 0.262\n",
      "[19,   146] loss: 0.138\n",
      "[19,   151] loss: 0.230\n",
      "[19,   156] loss: 0.109\n",
      "[19,   161] loss: 0.114\n",
      "[19,   166] loss: 0.104\n",
      "[19,   171] loss: 0.096\n",
      "[19,   176] loss: 0.055\n",
      "[19,   181] loss: 0.052\n",
      "[19,   186] loss: 0.136\n",
      "[19,   191] loss: 0.300\n",
      "[19,   196] loss: 0.277\n",
      "[19,   201] loss: 0.220\n",
      "[19,   206] loss: 0.176\n",
      "[19,   211] loss: 0.188\n",
      "[19,   216] loss: 0.283\n",
      "[19,   221] loss: 0.253\n",
      "[19,   226] loss: 0.207\n",
      "[19,   231] loss: 0.304\n",
      "[19,   236] loss: 0.196\n",
      "[19,   241] loss: 0.356\n",
      "[19,   246] loss: 0.301\n",
      "[19,   251] loss: 0.139\n",
      "[19,   256] loss: 0.206\n",
      "[19,   261] loss: 0.142\n",
      "[19,   266] loss: 0.112\n",
      "[19,   271] loss: 0.358\n",
      "[19,   276] loss: 0.229\n",
      "[19,   281] loss: 0.080\n",
      "[19,   286] loss: 0.375\n",
      "[19,   291] loss: 0.143\n",
      "[19,   296] loss: 0.225\n",
      "[19,   301] loss: 0.441\n",
      "[19,   306] loss: 0.248\n",
      "[19,   311] loss: 0.247\n",
      "[19,   316] loss: 0.234\n",
      "[19,   321] loss: 0.253\n",
      "[19,   326] loss: 0.283\n",
      "[19,   331] loss: 0.247\n",
      "Epoch : 18, Accuracy : 0.8122238516807556\n",
      "[20,     1] loss: 0.017\n",
      "[20,     6] loss: 0.181\n",
      "[20,    11] loss: 0.201\n",
      "[20,    16] loss: 0.106\n",
      "[20,    21] loss: 0.129\n",
      "[20,    26] loss: 0.077\n",
      "[20,    31] loss: 0.061\n",
      "[20,    36] loss: 0.219\n",
      "[20,    41] loss: 0.085\n",
      "[20,    46] loss: 0.210\n",
      "[20,    51] loss: 0.210\n",
      "[20,    56] loss: 0.189\n",
      "[20,    61] loss: 0.133\n",
      "[20,    66] loss: 0.094\n",
      "[20,    71] loss: 0.163\n",
      "[20,    76] loss: 0.325\n",
      "[20,    81] loss: 0.073\n",
      "[20,    86] loss: 0.101\n",
      "[20,    91] loss: 0.343\n",
      "[20,    96] loss: 0.294\n",
      "[20,   101] loss: 0.197\n",
      "[20,   106] loss: 0.287\n",
      "[20,   111] loss: 0.173\n",
      "[20,   116] loss: 0.237\n",
      "[20,   121] loss: 0.132\n",
      "[20,   126] loss: 0.143\n",
      "[20,   131] loss: 0.127\n",
      "[20,   136] loss: 0.129\n",
      "[20,   141] loss: 0.135\n",
      "[20,   146] loss: 0.144\n",
      "[20,   151] loss: 0.056\n",
      "[20,   156] loss: 0.252\n",
      "[20,   161] loss: 0.105\n",
      "[20,   166] loss: 0.274\n",
      "[20,   171] loss: 0.133\n",
      "[20,   176] loss: 0.196\n",
      "[20,   181] loss: 0.085\n",
      "[20,   186] loss: 0.079\n",
      "[20,   191] loss: 0.058\n",
      "[20,   196] loss: 0.122\n",
      "[20,   201] loss: 0.265\n",
      "[20,   206] loss: 0.328\n",
      "[20,   211] loss: 0.344\n",
      "[20,   216] loss: 0.219\n",
      "[20,   221] loss: 0.309\n",
      "[20,   226] loss: 0.224\n",
      "[20,   231] loss: 0.130\n",
      "[20,   236] loss: 0.206\n",
      "[20,   241] loss: 0.322\n",
      "[20,   246] loss: 0.196\n",
      "[20,   251] loss: 0.115\n",
      "[20,   256] loss: 0.138\n",
      "[20,   261] loss: 0.088\n",
      "[20,   266] loss: 0.069\n",
      "[20,   271] loss: 0.300\n",
      "[20,   276] loss: 0.166\n",
      "[20,   281] loss: 0.128\n",
      "[20,   286] loss: 0.192\n",
      "[20,   291] loss: 0.132\n",
      "[20,   296] loss: 0.124\n",
      "[20,   301] loss: 0.221\n",
      "[20,   306] loss: 0.104\n",
      "[20,   311] loss: 0.135\n",
      "[20,   316] loss: 0.170\n",
      "[20,   321] loss: 0.228\n",
      "[20,   326] loss: 0.127\n",
      "[20,   331] loss: 0.184\n",
      "Epoch : 19, Accuracy : 0.8122238516807556\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dataloader or dataset faulty(returns batches of 0\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    net.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data['ms'].to(device),data['label'].to(device)\n",
    "\n",
    "        #print(inputs.size())\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 0:    # print every 2000 mini-batches\n",
    "            \n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 5,\n",
    "                            epoch * len(trainloader) + i)\n",
    "            \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 5))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # calculate accuracy\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        res = torch.zeros((3,3))\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data['ms'].to(device),data['label'].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "            \n",
    "            for p,gt in zip(preds,labels):\n",
    "                res[int(p),int(gt)] += 1\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        N_total = res.sum()\n",
    "        N_correct = res.diag().sum()\n",
    "        \n",
    "        acc = N_correct / N_total\n",
    "        \n",
    "        writer.add_scalar('training acc',\n",
    "                    acc,\n",
    "                    epoch)\n",
    "        print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10, Accuracy : 0.8122238516807556\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "        net.eval()\n",
    "        res = torch.zeros((3,3))\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data['ms'].to(device),data['label'].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = torch.softmax(net(inputs),dim=1)\n",
    "            \n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "            \n",
    "            for p,gt in zip(preds,labels):\n",
    "                res[int(p),int(gt)] += 1\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        N_total = res.sum()\n",
    "        N_correct = res.diag().sum()\n",
    "        \n",
    "        acc = N_correct / N_total\n",
    "        \n",
    "        writer.add_scalar('training acc',\n",
    "                    acc,\n",
    "                    epoch)\n",
    "        print(f\"Epoch : {epoch}, Accuracy : {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# densenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soccernet_ms_npy_audio_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_npy = soccernet_ms_npy_audio_only(root_dir=root_dir,npy_file=\"train_samples.npy\")\n",
    "#X_valid_npy = soccernet_ms_npy_DS(root_dir=root_dir,npy_file=\"valid_samples.npy\")\n",
    "X_test_npy = soccernet_ms_npy_audio_only(root_dir=root_dir,npy_file=\"test_samples.npy\")\n",
    "\n",
    "params = {'batch_size': 12,\n",
    "         'shuffle': True,\n",
    "         'num_workers':3}\n",
    "trainloader = DataLoader(X_train_npy,**params)\n",
    "testloader = DataLoader(X_test_npy,**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/dense_net_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = torchvision.models.densenet161(pretrained=True)\n",
    "densenet.features.conv0 = nn.Conv2d(1, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "densenet.classifier = nn.Linear(in_features=densenet.classifier.in_features, out_features=3,bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(densenet.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataloader or dataset faulty(returns batches of 0\n",
    "epochs = 15\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    densenet.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data['ms'].to(device),data['label'].to(device)\n",
    "\n",
    "        #print(inputs.size())\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = densenet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 0:    # print every 2000 mini-batches\n",
    "            \n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 20,\n",
    "                            epoch * len(trainloader) + i)\n",
    "            \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 20))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # calculate accuracy\n",
    "    with torch.no_grad():\n",
    "        densenet.eval()\n",
    "        res = torch.zeros((3,3))\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data['ms'].to(device),data['label'].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = densenet(inputs)\n",
    "            \n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "            \n",
    "            for p,gt in zip(preds,labels):\n",
    "                res[int(p),int(gt)] += 1\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        N_total = res.sum()\n",
    "        N_correct = res.diag().sum()\n",
    "        \n",
    "        acc = N_correct / N_total\n",
    "        \n",
    "        writer.add_scalar('training acc',\n",
    "                    acc,\n",
    "                    epoch)\n",
    "        print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "        densenet.train()\n",
    "        res = torch.zeros((3,3))\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data['ms'].to(device),data['label'].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = densenet(inputs)\n",
    "            \n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "            print(outputs)\n",
    "            for p,gt in zip(preds,labels):\n",
    "                res[int(p),int(gt)] += 1\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        N_total = res.sum()\n",
    "        N_correct = res.diag().sum()\n",
    "        \n",
    "        acc = N_correct / N_total\n",
    "        \n",
    "        writer.add_scalar('training acc',\n",
    "                    acc,\n",
    "                    epoch)\n",
    "        print(f\"Epoch : {epoch}, Accuracy : {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.diag().sum() / res.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save validation list for dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = soccernet_ms_npy_DS(root_dir=root_dir,npy_file=train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file=root_dir+\"valid_samples.npy\",arr=samples,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.load(root_dir+\"valid_samples.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save test list for dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = SoccerNetDataset(root_dir=root_dir,npy_file=test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = list()\n",
    "for e in X:\n",
    "    samples.append(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file=root_dir+\"test_samples.npy\",arr=samples,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.load(root_dir+\"test_samples.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.pool = nn.MaxPool2d(4, 4)\n",
    "        self.fc1 = nn.Linear(2208, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = x.view(-1, 2208)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Note: Can also see warning once\n",
    "# warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/mel_spec_experiment_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(labels == torch.argmax(outputs, dim=1)).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/mel_spec_experiment_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device)\n",
    "# Dataloader or dataset faulty(returns batches of 0\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    net.train()\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data['mel_spectogram'].to(device),data['label'].to(device)\n",
    "\n",
    "        #print(inputs.size())\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 0:    # print every 2000 mini-batches\n",
    "            \n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 5,\n",
    "                            epoch * len(dataloader) + i)\n",
    "            \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 5))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # calculate accuracy\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        res = torch.zeros((3,3))\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data['mel_spectogram'].to(device),data['label'].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "            \n",
    "            for p,gt in zip(preds,labels):\n",
    "                res[int(p),int(gt)] += 1\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        N_total = res.sum()\n",
    "        N_correct = res.diag().sum()\n",
    "        \n",
    "        acc = N_total / N_correct\n",
    "        \n",
    "        writer.add_scalar('training acc',\n",
    "                    acc,\n",
    "                    epoch)\n",
    "        print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate samples to look for cases where y, sr from librosa is inconsistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.fc1.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device)\n",
    "\n",
    "running_loss = 0.0\n",
    "for i, data in enumerate(dataloader, 0):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data['mel_spectogram'].unsqueeze(0).to(device),torch.argmax(data['one_hot_label']).to(device)\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    running_loss += loss.item()\n",
    "    if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "        print('[%d, %5d] loss: %.3f' %\n",
    "              (epoch + 1, i + 1, running_loss / 2000))\n",
    "        running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import torchvision\n",
    "import datetime\n",
    "from subprocess import Popen, PIPE\n",
    "import re\n",
    "\n",
    "class SoccerNetDataset(Dataset):\n",
    "    \"\"\"Soccernet Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self,npy_file,\n",
    "                 npy_file_audio,\n",
    "                 root_dir,nframes=1,\n",
    "                 stride_frames=1,\n",
    "                 frame_center='center',\n",
    "                 transform=None,\n",
    "                 train=False,\n",
    "                 tshift={'active':False,\n",
    "                         'mu':0,'sigma':(0.4/3), \n",
    "                         'interval':[-0.45,0.45],\n",
    "                         'mode': 'uniform'}):\n",
    "        self.npy_file = np.load(npy_file)\n",
    "        self.audio_samples = np.load(root_dir+npy_file_audio,allow_pickle=True)\n",
    "        self.samples = list() # maybe change structure later depending on efficiency        \n",
    "        self.tshift = tshift\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.frame_center = frame_center\n",
    "        self.nframes = nframes\n",
    "        self.stride_frames = stride_frames\n",
    "        self.train = train\n",
    "        # For each path in npy_file, get all annotations\n",
    "\n",
    "\n",
    "        for e in self.npy_file:\n",
    "            path, annotations = self.get_annotations(e)\n",
    "\n",
    "            duration1 = self.getVideoLength(self.root_dir + e + \"/1.mkv\")\n",
    "            duration2 = self.getVideoLength(self.root_dir + e + \"/2.mkv\")\n",
    "            #print(f\"duration1 : {duration1}, duration2: {duration2}\")\n",
    "            for annotation in annotations:\n",
    "                # Check that annotations hold correct labels\n",
    "                        if (\"card\" in annotation[\"label\"]) or (\"subs\" in annotation[\"label\"]) or (\"soccer\" in annotation[\"label\"]):\n",
    "                            annotation[\"duration1\"] = duration1\n",
    "                            annotation[\"duration2\"] = duration2\n",
    "                            self.samples.append([path,annotation,\"soccernet\"])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def getVideoLength(self,video_file):\n",
    "        res = Popen(['ffmpeg', '-i', video_file, '-hide_banner'],stdout=PIPE,stderr=PIPE)\n",
    "        none,meta = res.communicate()\n",
    "        meta_out = meta.decode()\n",
    "        #---| Take out info\n",
    "        duration = re.search(r'Duration:.*', meta_out)\n",
    "        return duration.group()[:21]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        \"\"\"Returns a sample containing video path, clip and label\"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx.tolist()\n",
    "        \n",
    "        if self.train:\n",
    "            if idx in [2209,2210,2212,2213,2215,2217,2222]: # ultradirty hack - fix later\n",
    "                idx = 0\n",
    "        \n",
    "        if self.train:\n",
    "            if idx in [2209,2210,2212,2213,2215,2217,2222]: # ultradirty hack - fix later\n",
    "                idx = 0\n",
    "        \n",
    "        path = str(self.audio_samples[idx]['audiopath'][:-11]+str(idx)+\"_ms.npy\")\n",
    "        ms = np.load(path)\n",
    "        ms = ms-np.min(ms) / (np.max(ms)-np.min(ms))\n",
    "        label = self.audio_samples[idx]['label']\n",
    "        info = self.audio_samples[idx]['annotation']\n",
    "        #print(info)\n",
    "        idx_old = self.audio_samples[idx]['idx']\n",
    "        \n",
    "        audio_sample = {'path': path,\n",
    "                  'ms':ms,'idx': idx_old,\n",
    "                  'label':label, 'info':info}\n",
    "        \n",
    "        \n",
    "        # get annotations\n",
    "        time_half = int(self.samples[idx][1][\"gameTime\"][0])\n",
    "        time_minute = int(self.samples[idx][1][\"gameTime\"][-5:-3])\n",
    "        time_second = int(self.samples[idx][1][\"gameTime\"][-2:])\n",
    "        annotation = self.samples[idx][1]\n",
    "        source = self.samples[idx][2]\n",
    "        \n",
    "\n",
    "\n",
    "        # Get label\n",
    "        if (\"card\" in annotation[\"label\"]): label = 0\n",
    "        elif (\"subs\" in annotation[\"label\"]): label = 1\n",
    "        elif (\"soccer\" in annotation[\"label\"]): label = 2\n",
    "        elif (\"background\" in annotation[\"label\"]): label = 3\n",
    "        else: \n",
    "            print(\"Warning, label not compatible with set\")\n",
    "            return\n",
    "            \n",
    "        # Get videopath\n",
    "        if source == 'soccernet':\n",
    "            vidpath = os.path.join(self.root_dir,\n",
    "                                str(self.samples[idx][0]),\n",
    "                                    str(time_half)+\".mkv\")\n",
    "        else:\n",
    "            vidpath = str(self.samples[idx][0])\n",
    "        \n",
    "        \n",
    "        # Get video frames \n",
    "        \n",
    "        # get start in second, use labeled time as center TODO: fix centerframe as keyframe and stride\n",
    "        fps = 25.0 # assume fps = 25 for now, should be so\n",
    "        start_sec = time_minute*60 + time_second\n",
    "        end_sec = start_sec\n",
    "\n",
    "        if self.nframes == 1:\n",
    "            end_sec = start_sec\n",
    "        \n",
    "        if start_sec == 0:\n",
    "            end_sec += (1/fps) # possibly unstable solution\n",
    "            \n",
    "        \n",
    "        if self.frame_center == 'center' and self.nframes > 1:\n",
    "            \n",
    "            end_sec = end_sec + (self.nframes/fps) # might need to subtract 1/fps\n",
    "            # Shift backwards to center around time but check that time > 0\n",
    "            diff = (end_sec - start_sec) / 2 # TODO : Might result in bad precision\n",
    "            temp_start_sec = start_sec - diff\n",
    "            temp_end_sec = end_sec - diff\n",
    "            \n",
    "            # Only change as long as the shift operation doesnt shift out of bounds \n",
    "            if temp_start_sec >= 0:\n",
    "                start_sec = temp_start_sec\n",
    "                end_sec = temp_end_sec\n",
    "                \n",
    "            # TODO : Find new samplesize if self.stride_frames > 1\n",
    "            # if self.stride_frames > 1:\n",
    "            # For now, this is an operation for another place\n",
    "                \n",
    "        elif self.frame_center == 'back' and self.nframes > 1:\n",
    "            print(\"This option should NOT be used during inference, please use 'center' instead\")\n",
    "            end_sec = end_sec + (self.nframes/fps) # might need to subtract 1/fps\n",
    "        elif self.frame_center == 'front' and self.nframes > 1:\n",
    "            #print(\"This option should NOT be used during inference, please use 'center' instead\")\n",
    "            \n",
    "            end_sec = end_sec + (self.nframes/fps) # might need to subtract 1/fps\n",
    "            \n",
    "            # Shift forward such that the last frame is at annotated time t around time but check that time > 0\n",
    "            diff = (end_sec - start_sec) # TODO : Might result in bad precision\n",
    "            temp_start_sec = start_sec - diff\n",
    "            temp_end_sec = end_sec - diff\n",
    "            \n",
    "            # Only change as long as the shift operation doesnt shift out of bounds \n",
    "            if temp_start_sec >= 0:\n",
    "                start_sec = temp_start_sec\n",
    "                end_sec = temp_end_sec\n",
    "\n",
    "        \n",
    "        # Temporal translation transform\n",
    "        \n",
    "        if self.tshift['active'] and self.frame_center == 'center' and source == 'soccernet':\n",
    "            t0 = self.tshift['interval'][0]\n",
    "            t = self.tshift['interval'][1]\n",
    "            \n",
    "            if self.tshift['mode'] == 'uniform':    \n",
    "                delta = np.floor(np.random.uniform(t0,t) * self.nframes)\n",
    "            elif self.tshift['mode'] == 'normal':\n",
    "                mu = self.tshift['mu']\n",
    "                sigma = self.tshift['sigma']\n",
    "                temporal_window_size = self.nframes / 25.0\n",
    "                delta = np.random.normal(mu,sigma)\n",
    "                if delta < t0:\n",
    "                    delta = t0\n",
    "                elif delta > t:\n",
    "                    delta = t\n",
    "                delta = delta * temporal_window_size\n",
    "            else: return \"Please choose uniform or normal distribution\"\n",
    "            \n",
    "            # change delta from frames to seconds with correct stepsize\n",
    "            shifted_start = start_sec+delta\n",
    "            shifted_end = end_sec+delta\n",
    "            # Verify that shifted window stays inside \n",
    "            # get duration of video\n",
    "            if time_half == 1:\n",
    "                video_length = self.samples[idx][1][\"duration1\"]\n",
    "            elif time_half == 2:\n",
    "                video_length = self.samples[idx][1][\"duration2\"]\n",
    "\n",
    "            video_length_min = video_length[-8:-6]\n",
    "            video_length_sec = video_length[-5:-3]\n",
    "            total_sec = int(video_length_min)*60 + int(video_length_sec)\n",
    "            \n",
    "            if shifted_start < 0 or shifted_end > total_sec:\n",
    "                shifted_start = start_sec\n",
    "                shifted_end = end_sec\n",
    "            \n",
    "            start_sec = shifted_start\n",
    "            end_sec = shifted_end\n",
    "\n",
    "        # Buffer to endsec incase of bad load\n",
    "        end_sec = end_sec + 0.9 # loads more frames than needed, then reduced later\n",
    "        clip,_,info = torchvision.io.read_video(vidpath, start_pts=start_sec, end_pts=end_sec, pts_unit='sec')\n",
    "        \n",
    "        # TODO : This should be tested\n",
    "        clip = clip[:self.nframes,:,:,:]\n",
    "        \n",
    "\n",
    "        one_hot_labels = np.zeros(3)\n",
    "        one_hot_labels[label] = 1\n",
    "\n",
    "        csize = clip.size()\n",
    "        abnormal_count = 0\n",
    "        bad_count = 0   \n",
    "        abnormal_2_count = 0\n",
    "        # At this point clip is [T x H x W x C]\n",
    "        if clip.size()[3] != 3 or clip.size()[0] != self.nframes or clip.size()[1] != 224 or clip.size()[2] != 398:\n",
    "            abnormal_count += 1\n",
    "            if clip.size()[1] != 224 or clip.size()[2] != 398 or clip.size()[0] / self.nframes < 0.6:\n",
    "                clip = torch.zeros([self.nframes,224,398,3]).byte()\n",
    "                bad_count += 1\n",
    "            elif clip.size()[1] == 224 and clip.size()[2] == 398 and clip.size()[0] / self.nframes > 0.6:\n",
    "                a = clip.size()[0]\n",
    "                b = self.nframes - a\n",
    "                last_f = clip[(a-1):,:,:,:]\n",
    "                dup = last_f.repeat(b,1,1,1)\n",
    "                clip = torch.cat((clip,dup)).byte()\n",
    "                abnormal_2_count += 1\n",
    "\n",
    "        \n",
    "\n",
    "        sample = {'vidpath': vidpath,'clip': clip, 'annotation':annotation,'label':one_hot_labels,'idx':idx,\n",
    "                 'csize':csize, 'source': source, 'audio_sample': audio_sample}\n",
    "        \n",
    "\n",
    "        if self.transform:\n",
    "            sample['clip'] = self.transform(sample['clip'])\n",
    "        return sample\n",
    "            \n",
    "    def get_annotations(self,path):\n",
    "        \"\"\" Reads json files and returns \"\"\"\n",
    "        with open(self.root_dir+path+\"/Labels.json\") as jsonfile:\n",
    "            json_label = json.load(jsonfile)\n",
    "        \n",
    "        labels = [e for e in json_label['annotations']]\n",
    "        \n",
    "        return path,labels\n",
    "    def get_keyframe(self,idx):\n",
    "        if self.frame_center == 'back': return self.__getitem__(idx)['clip'][0,:,:,:]\n",
    "        elif self.frame_center == 'center': return self.__getitem__(idx)['clip'][self.nframes//2,:,:,:]\n",
    "        elif self.frame_center == 'front': return self.__getitem__(idx)['clip'][self.nframes-1,:,:,:]\n",
    "    def describe(self):\n",
    "        card = 0\n",
    "        subs = 0\n",
    "        goal = 0\n",
    "        background = 0\n",
    "\n",
    "        for sample in self.samples:\n",
    "            annotation = sample[1]\n",
    "        # Get label\n",
    "            if (\"card\" in annotation[\"label\"]): card += 1\n",
    "            elif (\"subs\" in annotation[\"label\"]): subs +=1\n",
    "            elif (\"soccer\" in annotation[\"label\"]): goal += 1\n",
    "            elif (\"background\" in annotation[\"label\"]): background += 1\n",
    "\n",
    "        print(\"Description of dataset\\n\\n\")\n",
    "        print(\"\\n ********* Classes *********\")\n",
    "        print(\"\\n card = 0\\n subs = 1\\n goals = 2\\n background = 3\")\n",
    "\n",
    "        print(\"\\n ********* Distribution and count *********\")\n",
    "        print(f\"\\n N card: {card} \\n N subs: {subs} \\n N goal: {goal} \\n N background: {background} \\n \\n Total : {card+subs+goal+background}\")\n",
    "        \n",
    "        print(\"\\n\\n ********* Configuration *********\")\n",
    "        print(f\"\\n npy_file: {self.npy_file} \\n tshift: {self.tshift} \\n root_dir: {self.root_dir} \\n transform: {self.transform} \\n frame_center: {self.frame_center} \\n nframes: {self.nframes} \\n stride_frames: {self.stride_frames} \\n background: {self.background}\")\n",
    "        print(\"\\n\\n ********* End of description *********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1358"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(videods_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_file_train = \"/work/oarongve/data/listgame_Train_300.npy\"\n",
    "npy_file_test = \"/work/oarongve/data/listgame_Test_100.npy\"\n",
    "root_dir = \"/work/oarongve/data/sound_dataset/SoccerNet-code/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models.video as video_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = video_models.resnet.r3d_18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change last layer..\n",
    "\n",
    "model.fc = torch.nn.Linear(model.fc.in_features,3)\n",
    "\n",
    "# Change first input as well\n",
    "\n",
    "model.stem[0] = torch.nn.Conv3d(3,model.stem[0].out_channels,kernel_size=(1,7,7),stride=(10,2,2),padding=model.stem[0].padding,bias=model.stem[0].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-26-fa410f5b77da>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-fa410f5b77da>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    'shuffle': True,\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "params = {'batch_size': 12\n",
    "         'shuffle': True,\n",
    "         'num_workers':6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transforms\n",
    "class ReSize(object):\n",
    "    def __init__(self,output_size,interpolation='bilinear'):\n",
    "        self.output_size = output_size\n",
    "        self.interpolation = interpolation\n",
    "    \n",
    "    def __call__(self,clip):\n",
    "        c,t,h,w = clip.size()\n",
    "        return video_transform.F.resize(clip,self.output_size,interpolation_mode=self.interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms._transforms_video as video_transform\n",
    "std = (0.22803, 0.22145, 0.216989)\n",
    "mean = (0.43216, 0.394666, 0.37645)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "        [video_transform.ToTensorVideo(),\n",
    "         ReSize((112,112)),\n",
    "        video_transform.RandomHorizontalFlipVideo(0.5),\n",
    "        video_transform.NormalizeVideo(std,mean)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "videods = SoccerNetDataset(root_dir=root_dir,\n",
    "                           npy_file=npy_file_train,\n",
    "                           npy_file_audio='train_samples.npy',\n",
    "                           train=True,\n",
    "                            nframes=4*25, transform=transform)\n",
    "\n",
    "videods_test = SoccerNetDataset(root_dir=root_dir,\n",
    "                           npy_file=npy_file_train,\n",
    "                           npy_file_audio='test_samples.npy',\n",
    "                           train=True,\n",
    "                            nframes=4*25, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(videods,**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 12, 'shuffle': True, 'num_workers': 6}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov  4 15:06:09 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.165.02   Driver Version: 418.165.02   CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM3...  On   | 00000000:59:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    69W / 350W |   4964MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     76556      C   .../project-daredevil-8eBKzQn6/bin/python3  4951MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/video_only_prototypev4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.136\n",
      "[1,     6] loss: 0.608\n",
      "[1,    11] loss: 0.640\n",
      "[1,    16] loss: 0.668\n",
      "[1,    21] loss: 0.536\n",
      "[1,    26] loss: 0.563\n",
      "[1,    31] loss: 0.590\n",
      "[1,    36] loss: 0.516\n",
      "[1,    41] loss: 0.639\n",
      "[1,    46] loss: 0.620\n",
      "[1,    51] loss: 0.584\n",
      "[1,    56] loss: 0.566\n",
      "[1,    61] loss: 0.670\n",
      "[1,    66] loss: 0.661\n",
      "[1,    71] loss: 0.578\n",
      "[1,    76] loss: 0.544\n",
      "[1,    81] loss: 0.575\n",
      "[1,    86] loss: 0.480\n",
      "[1,    91] loss: 0.579\n",
      "[1,    96] loss: 0.601\n",
      "[1,   101] loss: 0.465\n",
      "[1,   106] loss: 0.576\n",
      "[1,   111] loss: 0.527\n",
      "[1,   116] loss: 0.620\n",
      "[1,   121] loss: 0.590\n",
      "[1,   126] loss: 0.547\n",
      "[1,   131] loss: 0.560\n",
      "[1,   136] loss: 0.486\n",
      "[1,   141] loss: 0.678\n",
      "[1,   146] loss: 0.553\n",
      "[1,   151] loss: 0.510\n",
      "[1,   156] loss: 0.553\n",
      "[1,   161] loss: 0.585\n",
      "[1,   166] loss: 0.563\n",
      "[1,   171] loss: 0.543\n",
      "[1,   176] loss: 0.587\n",
      "[1,   181] loss: 0.432\n",
      "[1,   186] loss: 0.490\n",
      "[1,   191] loss: 0.396\n",
      "[1,   196] loss: 0.493\n",
      "[1,   201] loss: 0.459\n",
      "[1,   206] loss: 0.618\n",
      "[1,   211] loss: 0.608\n",
      "[1,   216] loss: 0.466\n",
      "[1,   221] loss: 0.554\n",
      "Epoch : 0, Accuracy : 1.1860604286193848\n",
      "[2,     1] loss: 0.118\n",
      "[2,     6] loss: 0.515\n",
      "[2,    11] loss: 0.402\n",
      "[2,    16] loss: 0.409\n",
      "[2,    21] loss: 0.505\n",
      "[2,    26] loss: 0.512\n",
      "[2,    31] loss: 0.504\n",
      "[2,    36] loss: 0.521\n",
      "[2,    41] loss: 0.435\n",
      "[2,    46] loss: 0.466\n",
      "[2,    51] loss: 0.426\n",
      "[2,    56] loss: 0.550\n",
      "[2,    61] loss: 0.445\n",
      "[2,    66] loss: 0.409\n",
      "[2,    71] loss: 0.404\n",
      "[2,    76] loss: 0.452\n",
      "[2,    81] loss: 0.480\n",
      "[2,    86] loss: 0.592\n",
      "[2,    91] loss: 0.512\n",
      "[2,    96] loss: 0.456\n",
      "[2,   101] loss: 0.399\n",
      "[2,   106] loss: 0.379\n",
      "[2,   111] loss: 0.501\n",
      "[2,   116] loss: 0.407\n",
      "[2,   121] loss: 0.522\n",
      "[2,   126] loss: 0.393\n",
      "[2,   131] loss: 0.497\n",
      "[2,   136] loss: 0.465\n",
      "[2,   141] loss: 0.511\n",
      "[2,   146] loss: 0.342\n",
      "[2,   151] loss: 0.427\n",
      "[2,   156] loss: 0.520\n",
      "[2,   161] loss: 0.474\n",
      "[2,   166] loss: 0.493\n",
      "[2,   171] loss: 0.418\n",
      "[2,   176] loss: 0.461\n",
      "[2,   181] loss: 0.493\n",
      "[2,   186] loss: 0.441\n",
      "[2,   191] loss: 0.463\n",
      "[2,   196] loss: 0.534\n",
      "[2,   201] loss: 0.404\n",
      "[2,   206] loss: 0.333\n",
      "[2,   211] loss: 0.417\n",
      "[2,   216] loss: 0.458\n",
      "[2,   221] loss: 0.501\n",
      "Epoch : 1, Accuracy : 1.1556397676467896\n",
      "[3,     1] loss: 0.103\n",
      "[3,     6] loss: 0.471\n",
      "[3,    11] loss: 0.427\n",
      "[3,    16] loss: 0.433\n",
      "[3,    21] loss: 0.370\n",
      "[3,    26] loss: 0.381\n",
      "[3,    31] loss: 0.495\n",
      "[3,    36] loss: 0.430\n",
      "[3,    41] loss: 0.436\n",
      "[3,    46] loss: 0.332\n",
      "[3,    51] loss: 0.301\n",
      "[3,    56] loss: 0.404\n",
      "[3,    61] loss: 0.455\n",
      "[3,    66] loss: 0.427\n",
      "[3,    71] loss: 0.366\n",
      "[3,    76] loss: 0.373\n",
      "[3,    81] loss: 0.373\n",
      "[3,    86] loss: 0.404\n",
      "[3,    91] loss: 0.387\n",
      "[3,    96] loss: 0.373\n",
      "[3,   101] loss: 0.412\n",
      "[3,   106] loss: 0.481\n",
      "[3,   111] loss: 0.447\n",
      "[3,   116] loss: 0.416\n",
      "[3,   121] loss: 0.413\n",
      "[3,   126] loss: 0.369\n",
      "[3,   131] loss: 0.390\n",
      "[3,   136] loss: 0.322\n",
      "[3,   141] loss: 0.317\n",
      "[3,   146] loss: 0.415\n",
      "[3,   151] loss: 0.275\n",
      "[3,   156] loss: 0.411\n",
      "[3,   161] loss: 0.454\n",
      "[3,   166] loss: 0.409\n",
      "[3,   171] loss: 0.480\n",
      "[3,   176] loss: 0.360\n",
      "[3,   181] loss: 0.384\n",
      "[3,   186] loss: 0.285\n",
      "[3,   191] loss: 0.463\n",
      "[3,   196] loss: 0.336\n",
      "[3,   201] loss: 0.340\n",
      "[3,   206] loss: 0.369\n",
      "[3,   211] loss: 0.448\n",
      "[3,   216] loss: 0.529\n",
      "[3,   221] loss: 0.515\n",
      "Epoch : 2, Accuracy : 1.132857084274292\n",
      "[4,     1] loss: 0.076\n",
      "[4,     6] loss: 0.357\n",
      "[4,    11] loss: 0.413\n",
      "[4,    16] loss: 0.398\n",
      "[4,    21] loss: 0.272\n",
      "[4,    26] loss: 0.331\n",
      "[4,    31] loss: 0.346\n",
      "[4,    36] loss: 0.348\n",
      "[4,    41] loss: 0.405\n",
      "[4,    46] loss: 0.317\n",
      "[4,    51] loss: 0.278\n",
      "[4,    56] loss: 0.466\n",
      "[4,    61] loss: 0.439\n",
      "[4,    66] loss: 0.369\n",
      "[4,    71] loss: 0.339\n",
      "[4,    76] loss: 0.446\n",
      "[4,    81] loss: 0.389\n",
      "[4,    86] loss: 0.434\n",
      "[4,    91] loss: 0.404\n",
      "[4,    96] loss: 0.392\n",
      "[4,   101] loss: 0.406\n",
      "[4,   106] loss: 0.385\n",
      "[4,   111] loss: 0.324\n",
      "[4,   116] loss: 0.324\n",
      "[4,   121] loss: 0.352\n",
      "[4,   126] loss: 0.298\n",
      "[4,   131] loss: 0.393\n",
      "[4,   136] loss: 0.339\n",
      "[4,   141] loss: 0.423\n",
      "[4,   146] loss: 0.287\n",
      "[4,   151] loss: 0.351\n",
      "[4,   156] loss: 0.316\n",
      "[4,   161] loss: 0.401\n",
      "[4,   166] loss: 0.343\n",
      "[4,   171] loss: 0.368\n",
      "[4,   176] loss: 0.387\n",
      "[4,   181] loss: 0.316\n",
      "[4,   186] loss: 0.363\n",
      "[4,   191] loss: 0.327\n",
      "[4,   196] loss: 0.524\n",
      "[4,   201] loss: 0.377\n",
      "[4,   206] loss: 0.418\n",
      "[4,   211] loss: 0.363\n",
      "[4,   216] loss: 0.403\n",
      "[4,   221] loss: 0.459\n",
      "Epoch : 3, Accuracy : 1.115958333015442\n",
      "[5,     1] loss: 0.068\n",
      "[5,     6] loss: 0.296\n",
      "[5,    11] loss: 0.290\n",
      "[5,    16] loss: 0.393\n",
      "[5,    21] loss: 0.368\n",
      "[5,    26] loss: 0.337\n",
      "[5,    31] loss: 0.395\n",
      "[5,    36] loss: 0.291\n",
      "[5,    41] loss: 0.384\n",
      "[5,    46] loss: 0.408\n",
      "[5,    51] loss: 0.393\n",
      "[5,    56] loss: 0.321\n",
      "[5,    61] loss: 0.281\n",
      "[5,    66] loss: 0.438\n",
      "[5,    71] loss: 0.297\n",
      "[5,    76] loss: 0.366\n",
      "[5,    81] loss: 0.319\n",
      "[5,    86] loss: 0.266\n",
      "[5,    91] loss: 0.431\n",
      "[5,    96] loss: 0.347\n",
      "[5,   101] loss: 0.270\n",
      "[5,   106] loss: 0.356\n",
      "[5,   111] loss: 0.272\n",
      "[5,   116] loss: 0.404\n",
      "[5,   121] loss: 0.290\n",
      "[5,   126] loss: 0.333\n",
      "[5,   131] loss: 0.414\n",
      "[5,   136] loss: 0.283\n",
      "[5,   141] loss: 0.353\n",
      "[5,   146] loss: 0.351\n",
      "[5,   151] loss: 0.281\n",
      "[5,   156] loss: 0.338\n",
      "[5,   161] loss: 0.325\n",
      "[5,   166] loss: 0.294\n",
      "[5,   171] loss: 0.221\n",
      "[5,   176] loss: 0.308\n",
      "[5,   181] loss: 0.278\n",
      "[5,   186] loss: 0.283\n",
      "[5,   191] loss: 0.358\n",
      "[5,   196] loss: 0.432\n",
      "[5,   201] loss: 0.365\n",
      "[5,   206] loss: 0.278\n",
      "[5,   211] loss: 0.235\n",
      "[5,   216] loss: 0.389\n",
      "[5,   221] loss: 0.317\n",
      "Epoch : 4, Accuracy : 1.1075419187545776\n",
      "[6,     1] loss: 0.072\n",
      "[6,     6] loss: 0.377\n",
      "[6,    11] loss: 0.313\n",
      "[6,    16] loss: 0.402\n",
      "[6,    21] loss: 0.264\n",
      "[6,    26] loss: 0.241\n",
      "[6,    31] loss: 0.293\n",
      "[6,    36] loss: 0.340\n",
      "[6,    41] loss: 0.333\n",
      "[6,    46] loss: 0.241\n",
      "[6,    51] loss: 0.286\n",
      "[6,    56] loss: 0.382\n",
      "[6,    61] loss: 0.295\n",
      "[6,    66] loss: 0.281\n",
      "[6,    71] loss: 0.347\n",
      "[6,    76] loss: 0.313\n",
      "[6,    81] loss: 0.318\n",
      "[6,    86] loss: 0.296\n",
      "[6,    91] loss: 0.279\n",
      "[6,    96] loss: 0.465\n",
      "[6,   101] loss: 0.249\n",
      "[6,   106] loss: 0.277\n",
      "[6,   111] loss: 0.263\n",
      "[6,   116] loss: 0.339\n",
      "[6,   121] loss: 0.327\n",
      "[6,   126] loss: 0.419\n",
      "[6,   131] loss: 0.289\n",
      "[6,   136] loss: 0.244\n",
      "[6,   141] loss: 0.264\n",
      "[6,   146] loss: 0.207\n",
      "[6,   151] loss: 0.312\n",
      "[6,   156] loss: 0.322\n",
      "[6,   161] loss: 0.299\n",
      "[6,   166] loss: 0.448\n",
      "[6,   171] loss: 0.255\n",
      "[6,   176] loss: 0.332\n",
      "[6,   181] loss: 0.315\n",
      "[6,   186] loss: 0.215\n",
      "[6,   191] loss: 0.266\n",
      "[6,   196] loss: 0.386\n",
      "[6,   201] loss: 0.276\n",
      "[6,   206] loss: 0.287\n",
      "[6,   211] loss: 0.397\n",
      "[6,   216] loss: 0.272\n",
      "[6,   221] loss: 0.391\n",
      "Epoch : 5, Accuracy : 1.0959093570709229\n",
      "[7,     1] loss: 0.086\n",
      "[7,     6] loss: 0.344\n",
      "[7,    11] loss: 0.271\n",
      "[7,    16] loss: 0.318\n",
      "[7,    21] loss: 0.327\n",
      "[7,    26] loss: 0.285\n",
      "[7,    31] loss: 0.362\n",
      "[7,    36] loss: 0.270\n",
      "[7,    41] loss: 0.250\n",
      "[7,    46] loss: 0.333\n",
      "[7,    51] loss: 0.307\n",
      "[7,    56] loss: 0.295\n",
      "[7,    61] loss: 0.284\n",
      "[7,    66] loss: 0.376\n",
      "[7,    71] loss: 0.244\n",
      "[7,    76] loss: 0.307\n",
      "[7,    81] loss: 0.274\n",
      "[7,    86] loss: 0.293\n",
      "[7,    91] loss: 0.273\n",
      "[7,    96] loss: 0.317\n",
      "[7,   101] loss: 0.255\n",
      "[7,   106] loss: 0.298\n",
      "[7,   111] loss: 0.321\n",
      "[7,   116] loss: 0.407\n",
      "[7,   121] loss: 0.168\n",
      "[7,   126] loss: 0.213\n",
      "[7,   131] loss: 0.232\n",
      "[7,   136] loss: 0.182\n",
      "[7,   141] loss: 0.322\n",
      "[7,   146] loss: 0.292\n",
      "[7,   151] loss: 0.189\n",
      "[7,   156] loss: 0.339\n",
      "[7,   161] loss: 0.266\n",
      "[7,   166] loss: 0.306\n",
      "[7,   171] loss: 0.248\n",
      "[7,   176] loss: 0.378\n",
      "[7,   181] loss: 0.344\n",
      "[7,   186] loss: 0.240\n",
      "[7,   191] loss: 0.273\n",
      "[7,   196] loss: 0.315\n",
      "[7,   201] loss: 0.314\n",
      "[7,   206] loss: 0.247\n",
      "[7,   211] loss: 0.239\n",
      "[7,   216] loss: 0.282\n",
      "[7,   221] loss: 0.289\n",
      "Epoch : 6, Accuracy : 1.0812653303146362\n",
      "[8,     1] loss: 0.076\n",
      "[8,     6] loss: 0.266\n",
      "[8,    11] loss: 0.255\n",
      "[8,    16] loss: 0.239\n",
      "[8,    21] loss: 0.232\n",
      "[8,    26] loss: 0.275\n",
      "[8,    31] loss: 0.202\n",
      "[8,    36] loss: 0.284\n",
      "[8,    41] loss: 0.165\n",
      "[8,    46] loss: 0.291\n",
      "[8,    51] loss: 0.197\n",
      "[8,    56] loss: 0.365\n",
      "[8,    61] loss: 0.330\n",
      "[8,    66] loss: 0.233\n",
      "[8,    71] loss: 0.190\n",
      "[8,    76] loss: 0.301\n",
      "[8,    81] loss: 0.327\n",
      "[8,    86] loss: 0.287\n",
      "[8,    91] loss: 0.259\n",
      "[8,    96] loss: 0.259\n",
      "[8,   101] loss: 0.349\n",
      "[8,   106] loss: 0.250\n",
      "[8,   111] loss: 0.279\n",
      "[8,   116] loss: 0.205\n",
      "[8,   121] loss: 0.262\n",
      "[8,   126] loss: 0.286\n",
      "[8,   131] loss: 0.252\n",
      "[8,   136] loss: 0.219\n",
      "[8,   141] loss: 0.219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,   146] loss: 0.226\n",
      "[8,   151] loss: 0.250\n",
      "[8,   156] loss: 0.316\n",
      "[8,   161] loss: 0.189\n",
      "[8,   166] loss: 0.303\n",
      "[8,   171] loss: 0.309\n",
      "[8,   176] loss: 0.370\n",
      "[8,   181] loss: 0.359\n",
      "[8,   186] loss: 0.271\n",
      "[8,   191] loss: 0.293\n",
      "[8,   196] loss: 0.217\n",
      "[8,   201] loss: 0.262\n",
      "[8,   206] loss: 0.270\n",
      "[8,   211] loss: 0.226\n",
      "[8,   216] loss: 0.181\n",
      "[8,   221] loss: 0.307\n",
      "Epoch : 7, Accuracy : 1.077152967453003\n",
      "[9,     1] loss: 0.136\n",
      "[9,     6] loss: 0.230\n",
      "[9,    11] loss: 0.260\n",
      "[9,    16] loss: 0.223\n",
      "[9,    21] loss: 0.323\n",
      "[9,    26] loss: 0.300\n",
      "[9,    31] loss: 0.331\n",
      "[9,    36] loss: 0.254\n",
      "[9,    41] loss: 0.274\n",
      "[9,    46] loss: 0.276\n",
      "[9,    51] loss: 0.338\n",
      "[9,    56] loss: 0.277\n",
      "[9,    61] loss: 0.259\n",
      "[9,    66] loss: 0.277\n",
      "[9,    71] loss: 0.210\n",
      "[9,    76] loss: 0.181\n",
      "[9,    81] loss: 0.350\n",
      "[9,    86] loss: 0.222\n",
      "[9,    91] loss: 0.248\n",
      "[9,    96] loss: 0.263\n",
      "[9,   101] loss: 0.198\n",
      "[9,   106] loss: 0.233\n",
      "[9,   111] loss: 0.269\n",
      "[9,   116] loss: 0.288\n",
      "[9,   121] loss: 0.251\n",
      "[9,   126] loss: 0.304\n",
      "[9,   131] loss: 0.152\n",
      "[9,   136] loss: 0.335\n",
      "[9,   141] loss: 0.295\n",
      "[9,   146] loss: 0.278\n",
      "[9,   151] loss: 0.329\n",
      "[9,   156] loss: 0.250\n",
      "[9,   161] loss: 0.233\n",
      "[9,   166] loss: 0.273\n",
      "[9,   171] loss: 0.284\n",
      "[9,   176] loss: 0.288\n",
      "[9,   181] loss: 0.264\n",
      "[9,   186] loss: 0.180\n",
      "[9,   191] loss: 0.259\n",
      "[9,   196] loss: 0.249\n",
      "[9,   201] loss: 0.239\n",
      "[9,   206] loss: 0.247\n",
      "[9,   211] loss: 0.269\n",
      "[9,   216] loss: 0.279\n",
      "[9,   221] loss: 0.292\n",
      "Epoch : 8, Accuracy : 1.0736528635025024\n",
      "[10,     1] loss: 0.031\n",
      "[10,     6] loss: 0.258\n",
      "[10,    11] loss: 0.286\n",
      "[10,    16] loss: 0.292\n",
      "[10,    21] loss: 0.222\n",
      "[10,    26] loss: 0.194\n",
      "[10,    31] loss: 0.226\n",
      "[10,    36] loss: 0.232\n",
      "[10,    41] loss: 0.221\n",
      "[10,    46] loss: 0.341\n",
      "[10,    51] loss: 0.227\n",
      "[10,    56] loss: 0.232\n",
      "[10,    61] loss: 0.153\n",
      "[10,    66] loss: 0.304\n",
      "[10,    71] loss: 0.241\n",
      "[10,    76] loss: 0.223\n",
      "[10,    81] loss: 0.197\n",
      "[10,    86] loss: 0.200\n",
      "[10,    91] loss: 0.266\n",
      "[10,    96] loss: 0.243\n",
      "[10,   101] loss: 0.233\n",
      "[10,   106] loss: 0.198\n",
      "[10,   111] loss: 0.233\n",
      "[10,   116] loss: 0.223\n",
      "[10,   121] loss: 0.344\n",
      "[10,   126] loss: 0.352\n",
      "[10,   131] loss: 0.267\n",
      "[10,   136] loss: 0.151\n",
      "[10,   141] loss: 0.179\n",
      "[10,   146] loss: 0.264\n",
      "[10,   151] loss: 0.153\n",
      "[10,   156] loss: 0.294\n",
      "[10,   161] loss: 0.298\n",
      "[10,   166] loss: 0.157\n",
      "[10,   171] loss: 0.261\n",
      "[10,   176] loss: 0.255\n",
      "[10,   181] loss: 0.194\n",
      "[10,   186] loss: 0.249\n",
      "[10,   191] loss: 0.172\n",
      "[10,   196] loss: 0.284\n",
      "[10,   201] loss: 0.325\n",
      "[10,   206] loss: 0.269\n",
      "[10,   211] loss: 0.204\n",
      "[10,   216] loss: 0.328\n",
      "[10,   221] loss: 0.243\n",
      "Epoch : 9, Accuracy : 1.0704643726348877\n",
      "[11,     1] loss: 0.035\n",
      "[11,     6] loss: 0.180\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-00e1db8d740e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "# Dataloader or dataset faulty(returns batches of 0\n",
    "epochs = 15\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data['clip'].to(device),data['label'].to(device)\n",
    "        target = torch.argmax(labels,dim=1)\n",
    "        #print(inputs.size())\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 0:    # print every 2000 mini-batches\n",
    "            \n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 5,\n",
    "                            epoch * len(trainloader) + i)\n",
    "            \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 5))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # calculate accuracy\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        res = torch.zeros((3,3))\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data['clip'].to(device),data['label'].to(device)\n",
    "            target = torch.argmax(labels,dim=1)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "            \n",
    "            for p,gt in zip(preds,target):\n",
    "                res[int(p),int(gt)] += 1\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        N_total = res.sum()\n",
    "        N_correct = res.diag().sum()\n",
    "        \n",
    "        acc = N_total / N_correct\n",
    "        \n",
    "        writer.add_scalar('training acc',\n",
    "                    acc,\n",
    "                    epoch)\n",
    "        print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audiovisual train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "# Dataloader or dataset faulty(returns batches of 0\n",
    "epochs = 15\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data['clip'].to(device),data['label'].to(device)\n",
    "        target = torch.argmax(labels,dim=1)\n",
    "        #print(inputs.size())\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 0:    # print every 2000 mini-batches\n",
    "            \n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 5,\n",
    "                            epoch * len(trainloader) + i)\n",
    "            \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 5))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # calculate accuracy\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        res = torch.zeros((3,3))\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data['clip'].to(device),data['label'].to(device)\n",
    "            target = torch.argmax(labels,dim=1)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "            \n",
    "            for p,gt in zip(preds,labels):\n",
    "                res[int(p),int(gt)] += 1\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        N_total = res.sum()\n",
    "        N_correct = res.diag().sum()\n",
    "        \n",
    "        acc = N_total / N_correct\n",
    "        \n",
    "        writer.add_scalar('training acc',\n",
    "                    acc,\n",
    "                    epoch)\n",
    "        print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audiovisual eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.zeros((3,3))\n",
    "res_audio = torch.zeros((3,3))\n",
    "res_video = torch.zeros((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval starting...\n",
      "Epoch : 10, Accuracy : 1.0200668573379517\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net.to(device)\n",
    "model.to(device)\n",
    "# Dataloader or dataset faulty(returns batches of 0\n",
    "\n",
    "# calculate accuracy\n",
    "with torch.no_grad():\n",
    "    print(\"eval starting...\")\n",
    "    net.eval()\n",
    "    res = torch.zeros((3,3))\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data['clip'].to(device),data['label'].to(device)\n",
    "        inputs_audio = data['audio_sample']['ms'].to(device)\n",
    "        \n",
    "        target = torch.argmax(labels,dim=1)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        outputs_audio = net(inputs_audio)\n",
    "        \n",
    "        avg_pred = (outputs + outputs_audio) / 2\n",
    "        preds = torch.argmax(avg_pred,dim=1)\n",
    "        preds_audio = torch.argmax(outputs,dim=1)\n",
    "        preds_video = torch.argmax(outputs_audio,dim=1)\n",
    "\n",
    "        for p,gt in zip(preds,target):\n",
    "            res[int(p),int(gt)] += 1\n",
    "\n",
    "        \n",
    "        # audio\n",
    "        for p,gt in zip(preds_audio, target):\n",
    "            res_audio[int(p),int(gt)] += 1\n",
    "        # video\n",
    "        for p,gt in zip(preds_video, target):\n",
    "            res_video[int(p),int(gt)] += 1\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    N_total = res.sum()\n",
    "    N_correct = res.diag().sum()\n",
    "\n",
    "    acc = N_total / N_correct\n",
    "\n",
    "    writer.add_scalar('training acc',\n",
    "                acc,\n",
    "                epoch)\n",
    "    print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videods_test = SoccerNetDataset(root_dir=root_dir,\n",
    "                           npy_file=npy_file_test,\n",
    "                           npy_file_audio='test_samples.npy',\n",
    "                           train=False,\n",
    "                            nframes=4*25, transform=transform)\n",
    "\n",
    "testloader = DataLoader(videods_test,**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x15543d265208>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x15543d265208>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x15543d265208>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()Exception ignored in: \n",
      "  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "<bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x15543d265208>>    \n",
      "w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "\n",
      "      File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "AssertionError:   File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    can only join a child processassert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x15543d265208>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x15543d265208>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10, Accuracy : 1.1279069185256958\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net.to(device)\n",
    "model.to(device)\n",
    "# Dataloader or dataset faulty(returns batches of 0\n",
    "\n",
    "# calculate accuracy\n",
    "with torch.no_grad():\n",
    "    print(\"eval starting...\")\n",
    "    net.eval()\n",
    "    res = torch.zeros((3,3))\n",
    "    res_audio = torch.zeros((3,3))\n",
    "    res_video = torch.zeros((3,3))\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data['clip'].to(device),data['label'].to(device)\n",
    "        inputs_audio = data['audio_sample']['ms'].to(device)\n",
    "        label_audio = data['audio_sample']['label'].to(device)\n",
    "        #label_audio = \n",
    "        \n",
    "        target = torch.argmax(labels,dim=1)\n",
    "        target_audio = label_audio\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = torch.softmax(model(inputs),dim=1)\n",
    "        outputs_audio = torch.softmax(net(inputs_audio),dim=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        avg_pred = (outputs + outputs_audio) / 2\n",
    "        preds = torch.argmax(avg_pred,dim=1)\n",
    "        preds_audio = torch.argmax(outputs_audio,dim=1)\n",
    "        preds_video = torch.argmax(outputs,dim=1)\n",
    "\n",
    "        for p,gt in zip(preds,target):\n",
    "            res[int(p),int(gt)] += 1\n",
    "\n",
    "        \n",
    "        # audio\n",
    "        for p,gt in zip(preds_audio, target_audio):\n",
    "            res_audio[int(p),int(gt)] += 1\n",
    "        # video\n",
    "        for p,gt in zip(preds_video, target):\n",
    "            res_video[int(p),int(gt)] += 1\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    N_total = res.sum()\n",
    "    N_correct = res.diag().sum()\n",
    "\n",
    "    acc = N_correct / N_total\n",
    "\n",
    "    print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_total = res.sum()\n",
    "N_correct = res.diag().sum()\n",
    "\n",
    "acc = N_correct / N_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_total_audio = res_audio.sum()\n",
    "N_correct_audio = res_audio.diag().sum()\n",
    "\n",
    "acc_audio = N_correct_audio / N_total_audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_total_video = res_video.sum()\n",
    "N_correct_video = res_video.diag().sum()\n",
    "\n",
    "acc_video = N_correct_video / N_total_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8866)\n",
      "tensor(0.8122)\n",
      "tensor(0.8513)\n"
     ]
    }
   ],
   "source": [
    "print(acc)\n",
    "print(acc_audio)\n",
    "print(acc_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((12,3))\n",
    "b = torch.rand((12,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5143, 0.4434, 0.4136],\n",
       "        [0.2918, 0.7081, 0.5464],\n",
       "        [0.6591, 0.4193, 0.6603],\n",
       "        [0.5454, 0.0187, 0.4433],\n",
       "        [0.6008, 0.6664, 0.5428],\n",
       "        [0.0740, 0.5168, 0.4054],\n",
       "        [0.6531, 0.5964, 0.5219],\n",
       "        [0.6565, 0.3273, 0.8152],\n",
       "        [0.2550, 0.7734, 0.5334],\n",
       "        [0.6792, 0.6497, 0.4694],\n",
       "        [0.5513, 0.5988, 0.6295],\n",
       "        [0.4152, 0.4855, 0.4012]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = (a+b) / 2\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3526, 0.3285, 0.3189],\n",
       "        [0.2627, 0.3984, 0.3389],\n",
       "        [0.3587, 0.2822, 0.3591],\n",
       "        [0.4010, 0.2368, 0.3621],\n",
       "        [0.3321, 0.3546, 0.3133],\n",
       "        [0.2532, 0.3942, 0.3526],\n",
       "        [0.3544, 0.3348, 0.3108],\n",
       "        [0.3458, 0.2488, 0.4053],\n",
       "        [0.2500, 0.4198, 0.3302],\n",
       "        [0.3595, 0.3490, 0.2915],\n",
       "        [0.3195, 0.3350, 0.3455],\n",
       "        [0.3269, 0.3507, 0.3224]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(c,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "    N_total = res.sum()\n",
    "    N_correct = res.diag().sum()\n",
    "\n",
    "    acc = N_correct / N_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3965.)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3884.)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9796)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    res = torch.zeros((3,3))\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data['audio_samples']['ms'].to(device),data['audio_samples']['label'].to(device)\n",
    "        target = torch.argmax(labels,dim=1)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.argmax(outputs,dim=1)\n",
    "\n",
    "        for p,gt in zip(preds,labels):\n",
    "            res[int(p),int(gt)] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    N_total = res.sum()\n",
    "    N_correct = res.diag().sum()\n",
    "\n",
    "    acc = N_total / N_correct\n",
    "\n",
    "    writer.add_scalar('training acc',\n",
    "                acc,\n",
    "                epoch)\n",
    "    print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-daredevil",
   "language": "python",
   "name": "project-daredevil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
