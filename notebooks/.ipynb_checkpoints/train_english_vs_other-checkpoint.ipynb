{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "sys.path.append('../')\n",
    "from src.datasets.soccernet_generic import soccernet_dataset_generic\n",
    "from src.utils.helper import samples_by_language\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/work/oarongve/data/sound_dataset/SoccerNet-code/data/\"\n",
    "train_list = \"/work/oarongve/data/sound_dataset/SoccerNet-code/data/listgame_Train_300.npy\"\n",
    "valid_list = \"/work/oarongve/data/sound_dataset/SoccerNet-code/data/listgame_Valid_100.npy\"\n",
    "test_list = \"/work/oarongve/data/sound_dataset/SoccerNet-code/data/listgame_Test_100.npy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/bin/python3\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "which python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 30 11:14:05 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.165.02   Driver Version: 418.165.02   CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM3...  On   | 00000000:E2:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    48W / 350W |      0MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "langpath_train = '/work/oarongve/project-daredevil/project-daredevil/language-annotations/annotations/train_lang_dict.json'\n",
    "langpath_valid = '/work/oarongve/project-daredevil/project-daredevil/language-annotations/annotations/valid_lang_dict.json'\n",
    "langpath_test = '/work/oarongve/project-daredevil/project-daredevil/language-annotations/annotations/test_lang_dict.json'\n",
    "\n",
    "samples_train_all = samples_by_language(langpath_train,train_list,'all')\n",
    "samples_valid_all = samples_by_language(langpath_valid,valid_list,'all')\n",
    "samples_test_all = samples_by_language(langpath_test,test_list,'all')\n",
    "\n",
    "samples_train_english = samples_by_language(langpath_train,train_list,'english')\n",
    "samples_valid_english = samples_by_language(langpath_valid,valid_list,'english')\n",
    "samples_test_english = samples_by_language(langpath_test,test_list,'english')\n",
    "\n",
    "samples_train_other = samples_by_language(langpath_train,train_list,'other')\n",
    "samples_valid_other = samples_by_language(langpath_valid,valid_list,'other')\n",
    "samples_test_other = samples_by_language(langpath_test,test_list,'other')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_all = soccernet_dataset_generic(npy_file=train_list,root_dir=root_dir,lang='all',lang_dict=langpath_train)\n",
    "valid_set_all = soccernet_dataset_generic(npy_file=valid_list,root_dir=root_dir,lang='all',lang_dict=langpath_valid)\n",
    "\n",
    "train_set_english = soccernet_dataset_generic(npy_file=train_list,root_dir=root_dir,lang='english',lang_dict=langpath_train)\n",
    "valid_set_english = soccernet_dataset_generic(npy_file=valid_list,root_dir=root_dir,lang='english',lang_dict=langpath_valid)\n",
    "\n",
    "train_set_other = soccernet_dataset_generic(npy_file=train_list,root_dir=root_dir,lang='other',lang_dict=langpath_train)\n",
    "valid_set_other = soccernet_dataset_generic(npy_file=valid_list,root_dir=root_dir,lang='other',lang_dict=langpath_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description of dataset\n",
      "\n",
      "\n",
      "\n",
      " ********* Classes *********\n",
      "\n",
      " card = 0\n",
      " subs = 1\n",
      " goals = 2\n",
      " background = 3\n",
      "\n",
      " ********* Distribution and count *********\n",
      "\n",
      " N card: 1296 \n",
      " N subs: 1708 \n",
      " N goal: 961 \n",
      " N background: 1855 \n",
      " \n",
      " Total : 5820\n",
      "\n",
      "\n",
      " ********* Configuration *********\n",
      "\n",
      " npy_file: ['england_epl/2014-2015/2015-02-21 - 18-00 Chelsea 1 - 1 Burnley'\n",
      " 'england_epl/2014-2015/2015-02-21 - 18-00 Crystal Palace 1 - 2 Arsenal'\n",
      " 'england_epl/2014-2015/2015-02-21 - 18-00 Swansea 2 - 1 Manchester United'\n",
      " 'england_epl/2014-2015/2015-02-22 - 19-15 Southampton 0 - 2 Liverpool'\n",
      " 'england_epl/2015-2016/2015-08-08 - 19-30 Chelsea 2 - 2 Swansea'\n",
      " 'england_epl/2015-2016/2015-08-29 - 17-00 Chelsea 1 - 2 Crystal Palace'\n",
      " 'england_epl/2015-2016/2015-08-29 - 17-00 Manchester City 2 - 0 Watford'\n",
      " 'england_epl/2015-2016/2015-09-12 - 14-45 Everton 3 - 1 Chelsea'\n",
      " 'england_epl/2015-2016/2015-09-12 - 17-00 Crystal Palace 0 - 1 Manchester City'\n",
      " 'england_epl/2015-2016/2015-09-19 - 19-30 Manchester City 1 - 2 West Ham'\n",
      " 'england_epl/2015-2016/2015-09-26 - 17-00 Liverpool 3 - 2 Aston Villa'\n",
      " 'england_epl/2015-2016/2015-10-17 - 17-00 Chelsea 2 - 0 Aston Villa'\n",
      " 'england_epl/2015-2016/2015-10-31 - 15-45 Chelsea 1 - 3 Liverpool'\n",
      " 'england_epl/2015-2016/2015-11-07 - 18-00 Manchester United 2 - 0 West Brom'\n",
      " 'england_epl/2015-2016/2015-11-21 - 20-30 Manchester City 1 - 4 Liverpool'\n",
      " 'england_epl/2015-2016/2015-11-29 - 15-00 Tottenham 0 - 0 Chelsea'\n",
      " 'england_epl/2015-2016/2015-12-05 - 20-30 Chelsea 0 - 1 Bournemouth'\n",
      " 'england_epl/2015-2016/2015-12-19 - 18-00 Chelsea 3 - 1 Sunderland'\n",
      " 'england_epl/2015-2016/2015-12-26 - 18-00 Manchester City 4 - 1 Sunderland'\n",
      " 'england_epl/2015-2016/2016-01-03 - 16-30 Crystal Palace 0 - 3 Chelsea'\n",
      " 'england_epl/2015-2016/2016-01-13 - 22-45 Chelsea 2 - 2 West Brom'\n",
      " 'england_epl/2015-2016/2016-02-07 - 19-00 Chelsea 1 - 1 Manchester United'\n",
      " 'england_epl/2015-2016/2016-02-14 - 19-15 Manchester City 1 - 2 Tottenham'\n",
      " 'england_epl/2015-2016/2016-03-02 - 23-00 Liverpool 3 - 0 Manchester City'\n",
      " 'england_epl/2015-2016/2016-03-05 - 18-00 Chelsea 1 - 1 Stoke City'\n",
      " 'england_epl/2015-2016/2016-03-19 - 18-00 Chelsea 2 - 2 West Ham'\n",
      " 'england_epl/2015-2016/2016-04-09 - 17-00 Swansea 1 - 0 Chelsea'\n",
      " 'england_epl/2015-2016/2016-04-09 - 19-30 Manchester City 2 - 1 West Brom'\n",
      " 'england_epl/2015-2016/2016-05-07 - 17-00 Sunderland 3 - 2 Chelsea'\n",
      " 'england_epl/2016-2017/2016-08-14 - 18-00 Arsenal 3 - 4 Liverpool'\n",
      " 'england_epl/2016-2017/2016-08-20 - 17-00 Burnley 2 - 0 Liverpool'\n",
      " 'england_epl/2016-2017/2016-08-20 - 19-30 Leicester 0 - 0 Arsenal'\n",
      " 'england_epl/2016-2017/2016-09-10 - 17-00 Arsenal 2 - 1 Southampton'\n",
      " 'england_epl/2016-2017/2016-09-16 - 22-00 Chelsea 1 - 2 Liverpool'\n",
      " 'england_epl/2016-2017/2016-09-17 - 17-00 Hull City 1 - 4 Arsenal'\n",
      " 'england_epl/2016-2017/2016-09-24 - 19-30 Arsenal 3 - 0 Chelsea'\n",
      " 'england_epl/2016-2017/2016-10-17 - 22-00 Liverpool 0 - 0 Manchester United'\n",
      " 'england_epl/2016-2017/2016-10-22 - 19-30 Liverpool 2 - 1 West Brom'\n",
      " 'england_epl/2016-2017/2016-10-29 - 14-30 Sunderland 1 - 4 Arsenal'\n",
      " 'england_epl/2016-2017/2016-10-29 - 17-00 Tottenham 1 - 1 Leicester'\n",
      " 'england_epl/2016-2017/2016-11-06 - 17-15 Liverpool 6 - 1 Watford'\n",
      " 'england_epl/2016-2017/2016-11-06 - 19-30 Leicester 1 - 2 West Brom'\n",
      " 'england_epl/2016-2017/2016-11-19 - 18-00 Southampton 0 - 0 Liverpool'\n",
      " 'england_epl/2016-2017/2016-11-26 - 18-00 Liverpool 2 - 0 Sunderland'\n",
      " 'england_epl/2016-2017/2016-12-10 - 20-30 Leicester 4 - 2 Manchester City'\n",
      " 'england_epl/2016-2017/2016-12-11 - 19-30 Liverpool 2 - 2 West Ham'\n",
      " 'england_epl/2016-2017/2016-12-14 - 22-45 Middlesbrough 0 - 3 Liverpool'\n",
      " 'england_epl/2016-2017/2016-12-19 - 23-00 Everton 0 - 1 Liverpool'\n",
      " 'england_epl/2016-2017/2016-12-27 - 20-15 Liverpool 4 - 1 Stoke City'\n",
      " 'england_epl/2016-2017/2016-12-31 - 20-30 Liverpool 1 - 0 Manchester City'\n",
      " 'england_epl/2016-2017/2017-01-02 - 15-30 Middlesbrough 0 - 0 Leicester'\n",
      " 'england_epl/2016-2017/2017-01-02 - 18-00 Sunderland 2 - 2 Liverpool'\n",
      " 'england_epl/2016-2017/2017-01-14 - 20-30 Leicester 0 - 3 Chelsea'\n",
      " 'england_epl/2016-2017/2017-01-15 - 19-00 Manchester United 1 - 1 Liverpool'\n",
      " 'england_epl/2016-2017/2017-01-31 - 23-00 Liverpool 1 - 1 Chelsea'\n",
      " 'england_epl/2016-2017/2017-02-27 - 23-00 Leicester 3 - 1 Liverpool'\n",
      " 'england_epl/2016-2017/2017-04-26 - 21-45 Arsenal 1 - 0 Leicester'\n",
      " 'england_epl/2016-2017/2017-05-13 - 14-30 Manchester City 2 - 1 Leicester'\n",
      " 'europe_uefa-champions-league/2014-2015/2014-11-04 - 22-45 Arsenal 3 - 3 Anderlecht'\n",
      " 'europe_uefa-champions-league/2014-2015/2014-11-04 - 22-45 Dortmund 4 - 1 Galatasaray'\n",
      " 'europe_uefa-champions-league/2014-2015/2014-11-05 - 22-45 Bayern Munich 2 - 0 AS Roma'\n",
      " 'europe_uefa-champions-league/2014-2015/2014-12-09 - 22-45 Benfica 0 - 0 Bayer Leverkusen'\n",
      " 'europe_uefa-champions-league/2014-2015/2014-12-09 - 22-45 Dortmund 1 - 1 Anderlecht'\n",
      " 'europe_uefa-champions-league/2014-2015/2014-12-09 - 22-45 Liverpool 1 - 1 Basel'\n",
      " 'europe_uefa-champions-league/2014-2015/2014-12-10 - 22-45 Barcelona 3 - 1 Paris SG'\n",
      " 'europe_uefa-champions-league/2014-2015/2014-12-10 - 22-45 Bayern Munich 3 - 0 CSKA Moscow'\n",
      " 'europe_uefa-champions-league/2014-2015/2015-02-17 - 22-45 Paris SG 1 - 1 Chelsea'\n",
      " 'europe_uefa-champions-league/2014-2015/2015-02-17 - 22-45 Shakhtar Donetsk 0 - 0 Bayern Munich'\n",
      " 'europe_uefa-champions-league/2014-2015/2015-02-18 - 22-45 Schalke 0 - 2 Real Madrid'\n",
      " 'europe_uefa-champions-league/2014-2015/2015-02-25 - 22-45 Arsenal 1 - 3 Monaco'\n",
      " 'europe_uefa-champions-league/2014-2015/2015-02-25 - 22-45 Bayer Leverkusen 1 - 0 Atl. Madrid'\n",
      " 'europe_uefa-champions-league/2014-2015/2015-03-10 - 22-45 FC Porto 4 - 0 Basel'\n",
      " 'europe_uefa-champions-league/2014-2015/2015-03-18 - 22-45 Barcelona 1 - 0 Manchester City'\n",
      " 'europe_uefa-champions-league/2014-2015/2015-03-18 - 22-45 Dortmund 0 - 3 Juventus'\n",
      " 'europe_uefa-champions-league/2014-2015/2015-04-14 - 21-45 Atl. Madrid 0 - 0 Real Madrid'\n",
      " 'europe_uefa-champions-league/2014-2015/2015-04-14 - 21-45 Juventus 1 - 0 Monaco'\n",
      " 'europe_uefa-champions-league/2014-2015/2015-04-21 - 21-45 Bayern Munich 6 - 1 FC Porto'\n",
      " 'europe_uefa-champions-league/2014-2015/2015-04-22 - 21-45 Monaco 0 - 0 Juventus'\n",
      " 'europe_uefa-champions-league/2014-2015/2015-05-06 - 21-45 Barcelona 3 - 0 Bayern Munich'\n",
      " 'europe_uefa-champions-league/2014-2015/2015-05-12 - 21-45 Bayern Munich 3 - 2 Barcelona'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-09-15 - 21-45 Galatasaray 0 - 2 Atl. Madrid'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-09-15 - 21-45 Manchester City 1 - 2 Juventus'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-09-15 - 21-45 Paris SG 2 - 0 Malmo FF'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-09-15 - 21-45 Real Madrid 4 - 0 Shakhtar Donetsk'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-09-15 - 21-45 Sevilla 3 - 0 B. Monchengladbach'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-09-16 - 21-45 AS Roma 1 - 1 Barcelona'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-09-16 - 21-45 Bayer Leverkusen 4 - 1 BATE'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-09-16 - 21-45 Gent 1 - 1 Lyon'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-09-29 - 21-45 Arsenal 2 - 3 Olympiakos Piraeus'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-09-29 - 21-45 Lyon 0 - 1 Valencia'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-10-20 - 21-45 Arsenal 2 - 0 Bayern Munich'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-11-03 - 18-00 FC Astana 0 - 0 Atl. Madrid'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-11-03 - 22-45 B. Monchengladbach 1 - 1 Juventus'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-11-03 - 22-45 Manchester United 1 - 0 CSKA Moscow'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-11-03 - 22-45 PSV 2 - 0 Wolfsburg'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-11-04 - 22-45 Bayern Munich 5 - 1 Arsenal'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-11-04 - 22-45 Gent 1 - 0 Valencia'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-11-04 - 22-45 Lyon 0 - 2 Zenit Petersburg'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-11-04 - 22-45 Maccabi Tel Aviv 1 - 3 FC Porto'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-11-24 - 20-00 Zenit Petersburg 2 - 0 Valencia'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-11-24 - 22-45 Barcelona 6 - 1 AS Roma'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-11-24 - 22-45 Bayern Munich 4 - 0 Olympiakos Piraeus'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-11-24 - 22-45 FC Porto 0 - 2 Dyn. Kiev'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-11-24 - 22-45 Maccabi Tel Aviv 0 - 4 Chelsea'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-11-25 - 20-00 CSKA Moscow 0 - 2 Wolfsburg'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-11-25 - 22-45 Atl. Madrid 2 - 0 Galatasaray'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-11-25 - 22-45 B. Monchengladbach 4 - 2 Sevilla'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-11-25 - 22-45 Malmo FF 0 - 5 Paris SG'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-12-09 - 22-45 D. Zagreb 0 - 2 Bayern Munich'\n",
      " 'europe_uefa-champions-league/2016-2017/2016-09-13 - 21-45 Barcelona 7 - 0 Celtic'\n",
      " 'europe_uefa-champions-league/2016-2017/2016-09-13 - 21-45 Dyn. Kiev 1 - 2 Napoli'\n",
      " 'europe_uefa-champions-league/2016-2017/2016-09-28 - 21-45 Ludogorets 1 - 3 Paris SG'\n",
      " 'europe_uefa-champions-league/2016-2017/2016-10-19 - 21-45 Barcelona 4 - 0 Manchester City'\n",
      " 'europe_uefa-champions-league/2016-2017/2016-11-23 - 22-45 Celtic 0 - 2 Barcelona'\n",
      " 'europe_uefa-champions-league/2016-2017/2016-11-23 - 22-45 Napoli 0 - 0 Dyn. Kiev'\n",
      " 'europe_uefa-champions-league/2016-2017/2016-12-06 - 22-45 Benfica 1 - 2 Napoli'\n",
      " 'europe_uefa-champions-league/2016-2017/2017-02-14 - 22-45 Paris SG 4 - 0 Barcelona'\n",
      " 'europe_uefa-champions-league/2016-2017/2017-02-15 - 22-45 Real Madrid 3 - 1 Napoli'\n",
      " 'europe_uefa-champions-league/2016-2017/2017-03-07 - 22-45 Napoli 1 - 3 Real Madrid'\n",
      " 'europe_uefa-champions-league/2016-2017/2017-04-18 - 21-45 Real Madrid 4 - 2 Bayern Munich'\n",
      " 'france_ligue-1/2014-2015/2015-04-05 - 22-00 Marseille 2 - 3 Paris SG'\n",
      " 'france_ligue-1/2015-2016/2015-09-26 - 18-30 Nantes 1 - 4 Paris SG'\n",
      " 'france_ligue-1/2015-2016/2015-11-07 - 19-00 Paris SG 5 - 0 Toulouse'\n",
      " 'france_ligue-1/2016-2017/2016-08-12 - 21-00 Bastia 0 - 1 Paris SG'\n",
      " 'france_ligue-1/2016-2017/2016-09-16 - 21-45 Caen 0 - 6 Paris SG'\n",
      " 'france_ligue-1/2016-2017/2016-09-23 - 21-45 Toulouse 2 - 0 Paris SG'\n",
      " 'france_ligue-1/2016-2017/2016-10-01 - 18-00 Paris SG 2 - 0 Bordeaux'\n",
      " 'france_ligue-1/2016-2017/2016-10-15 - 18-00 Nancy 1 - 2 Paris SG'\n",
      " 'france_ligue-1/2016-2017/2016-10-28 - 21-45 Lille 0 - 1 Paris SG'\n",
      " 'france_ligue-1/2016-2017/2016-11-06 - 22-45 Paris SG 4 - 0 Rennes'\n",
      " 'france_ligue-1/2016-2017/2016-11-19 - 19-00 Paris SG 2 - 0 Nantes'\n",
      " 'france_ligue-1/2016-2017/2016-11-27 - 22-45 Lyon 1 - 2 Paris SG'\n",
      " 'france_ligue-1/2016-2017/2016-12-11 - 22-45 Paris SG 2 - 2 Nice'\n",
      " 'france_ligue-1/2016-2017/2016-12-17 - 19-00 Guingamp 2 - 1 Paris SG'\n",
      " 'france_ligue-1/2016-2017/2016-12-21 - 22-50 Paris SG 5 - 0 Lorient'\n",
      " 'france_ligue-1/2016-2017/2017-01-21 - 19-00 Nantes 0 - 2 Paris SG'\n",
      " 'france_ligue-1/2016-2017/2017-02-10 - 22-45 Bordeaux 0 - 3 Paris SG'\n",
      " 'france_ligue-1/2016-2017/2017-02-19 - 23-00 Paris SG 0 - 0 Toulouse'\n",
      " 'france_ligue-1/2016-2017/2017-02-26 - 23-00 Marseille 1 - 5 Paris SG'\n",
      " 'france_ligue-1/2016-2017/2017-03-12 - 23-00 Lorient 1 - 2 Paris SG'\n",
      " 'france_ligue-1/2016-2017/2017-03-19 - 23-00 Paris SG 2 - 1 Lyon'\n",
      " 'france_ligue-1/2016-2017/2017-04-14 - 21-45 Angers 0 - 2 Paris SG'\n",
      " 'france_ligue-1/2016-2017/2017-04-18 - 19-30 Metz 2 - 3 Paris SG'\n",
      " 'france_ligue-1/2016-2017/2017-04-22 - 18-00 Paris SG 2 - 0 Montpellier'\n",
      " 'france_ligue-1/2016-2017/2017-04-30 - 22-00 Nice 3 - 1 Paris SG'\n",
      " 'france_ligue-1/2016-2017/2017-05-06 - 18-00 Paris SG 5 - 0 Bastia'\n",
      " 'france_ligue-1/2016-2017/2017-05-20 - 22-00 Paris SG 1 - 1 Caen'\n",
      " 'germany_bundesliga/2014-2015/2015-02-21 - 17-30 Paderborn 0 - 6 Bayern Munich'\n",
      " 'germany_bundesliga/2014-2015/2015-04-11 - 16-30 Bayern Munich 3 - 0 Eintracht Frankfurt'\n",
      " 'germany_bundesliga/2014-2015/2015-04-25 - 16-30 Dortmund 2 - 0 Eintracht Frankfurt'\n",
      " 'germany_bundesliga/2014-2015/2015-05-09 - 16-30 Dortmund 2 - 0 Hertha Berlin'\n",
      " 'germany_bundesliga/2014-2015/2015-05-16 - 16-30 Wolfsburg 2 - 1 Dortmund'\n",
      " 'germany_bundesliga/2015-2016/2015-08-22 - 16-30 Hoffenheim 1 - 2 Bayern Munich'\n",
      " 'germany_bundesliga/2015-2016/2015-08-30 - 16-30 Dortmund 3 - 1 Hertha Berlin'\n",
      " 'germany_bundesliga/2015-2016/2015-09-19 - 16-30 Darmstadt 0 - 3 Bayern Munich'\n",
      " 'germany_bundesliga/2015-2016/2015-09-22 - 21-00 Bayern Munich 5 - 1 Wolfsburg'\n",
      " 'germany_bundesliga/2015-2016/2015-09-26 - 16-30 1. FSV Mainz 05 0 - 3 Bayern Munich'\n",
      " 'germany_bundesliga/2015-2016/2015-12-12 - 17-30 Bayern Munich 2 - 0 Ingolstadt'\n",
      " 'germany_bundesliga/2015-2016/2016-01-31 - 19-30 Bayern Munich 2 - 0 Hoffenheim'\n",
      " 'germany_bundesliga/2015-2016/2016-04-02 - 16-30 Bayern Munich 1 - 0 Eintracht Frankfurt'\n",
      " 'germany_bundesliga/2015-2016/2016-04-09 - 16-30 VfB Stuttgart 1 - 3 Bayern Munich'\n",
      " 'germany_bundesliga/2015-2016/2016-04-16 - 19-30 Bayern Munich 3 - 0 Schalke'\n",
      " 'germany_bundesliga/2016-2017/2016-09-17 - 16-30 Dortmund 6 - 0 Darmstadt'\n",
      " 'germany_bundesliga/2016-2017/2016-09-20 - 21-00 Wolfsburg 1 - 5 Dortmund'\n",
      " 'germany_bundesliga/2016-2017/2016-09-23 - 21-30 Dortmund 3 - 1 SC Freiburg'\n",
      " 'germany_bundesliga/2016-2017/2016-10-14 - 21-30 Dortmund 1 - 1 Hertha Berlin'\n",
      " 'germany_bundesliga/2016-2017/2016-10-22 - 16-30 Ingolstadt 3 - 3 Dortmund'\n",
      " 'germany_bundesliga/2016-2017/2016-10-29 - 19-30 Dortmund 0 - 0 Schalke'\n",
      " 'germany_bundesliga/2016-2017/2016-11-26 - 17-30 Eintracht Frankfurt 2 - 1 Dortmund'\n",
      " 'germany_bundesliga/2016-2017/2016-12-10 - 17-30 FC Koln 1 - 1 Dortmund'\n",
      " 'germany_bundesliga/2016-2017/2016-12-20 - 22-00 Dortmund 1 - 1 FC Augsburg'\n",
      " 'germany_bundesliga/2016-2017/2017-02-04 - 20-30 Dortmund 1 - 0 RB Leipzig'\n",
      " 'germany_bundesliga/2016-2017/2017-02-11 - 17-30 Darmstadt 2 - 1 Dortmund'\n",
      " 'germany_bundesliga/2016-2017/2017-02-18 - 17-30 Dortmund 3 - 0 Wolfsburg'\n",
      " 'germany_bundesliga/2016-2017/2017-03-17 - 22-30 Dortmund 1 - 0 Ingolstadt'\n",
      " 'germany_bundesliga/2016-2017/2017-04-01 - 16-30 Schalke 1 - 1 Dortmund'\n",
      " 'germany_bundesliga/2016-2017/2017-04-15 - 16-30 Dortmund 3 - 1 Eintracht Frankfurt'\n",
      " 'germany_bundesliga/2016-2017/2017-05-13 - 16-30 FC Augsburg 1 - 1 Dortmund'\n",
      " 'italy_serie-a/2014-2015/2015-02-15 - 14-30 AC Milan 1 - 1 Empoli'\n",
      " 'italy_serie-a/2014-2015/2015-04-11 - 21-45 Verona 0 - 3 Inter'\n",
      " 'italy_serie-a/2014-2015/2015-04-19 - 21-45 Inter 0 - 0 AC Milan'\n",
      " 'italy_serie-a/2014-2015/2015-04-25 - 21-45 Inter 2 - 1 AS Roma'\n",
      " 'italy_serie-a/2014-2015/2015-04-26 - 16-00 Torino 2 - 1 Juventus'\n",
      " 'italy_serie-a/2014-2015/2015-05-03 - 21-45 Napoli 3 - 0 AC Milan'\n",
      " 'italy_serie-a/2014-2015/2015-05-16 - 19-00 Inter 1 - 2 Juventus'\n",
      " 'italy_serie-a/2015-2016/2015-09-20 - 13-30 Chievo 0 - 1 Inter'\n",
      " 'italy_serie-a/2015-2016/2015-09-22 - 21-45 Udinese 2 - 3 AC Milan'\n",
      " 'italy_serie-a/2015-2016/2015-11-01 - 22-45 Lazio 1 - 3 AC Milan'\n",
      " 'italy_serie-a/2015-2016/2015-11-07 - 22-45 AC Milan 0 - 0 Atalanta'\n",
      " 'italy_serie-a/2015-2016/2015-11-22 - 22-45 Inter 4 - 0 Frosinone'\n",
      " 'italy_serie-a/2016-2017/2016-08-21 - 21-45 Pescara 2 - 2 Napoli'\n",
      " 'italy_serie-a/2016-2017/2016-08-28 - 21-45 Cagliari 2 - 2 AS Roma'\n",
      " 'italy_serie-a/2016-2017/2016-09-10 - 21-45 Palermo 0 - 3 Napoli'\n",
      " 'italy_serie-a/2016-2017/2016-09-16 - 21-45 Sampdoria 0 - 1 AC Milan'\n",
      " 'italy_serie-a/2016-2017/2016-09-17 - 21-45 Napoli 3 - 1 Bologna'\n",
      " 'italy_serie-a/2016-2017/2016-09-21 - 21-45 AS Roma 4 - 0 Crotone'\n",
      " 'italy_serie-a/2016-2017/2016-10-15 - 16-00 Napoli 1 - 3 AS Roma'\n",
      " 'italy_serie-a/2016-2017/2016-10-23 - 16-00 Crotone 1 - 2 Napoli'\n",
      " 'italy_serie-a/2016-2017/2016-10-23 - 21-45 AS Roma 4 - 1 Palermo'\n",
      " 'italy_serie-a/2016-2017/2016-10-25 - 21-45 Genoa 3 - 0 AC Milan'\n",
      " 'italy_serie-a/2016-2017/2016-10-26 - 21-45 Napoli 2 - 0 Empoli'\n",
      " 'italy_serie-a/2016-2017/2016-10-26 - 21-45 Sassuolo 1 - 3 AS Roma'\n",
      " 'italy_serie-a/2016-2017/2016-10-30 - 17-00 AC Milan 1 - 0 Pescara'\n",
      " 'italy_serie-a/2016-2017/2016-10-30 - 17-00 Empoli 0 - 0 AS Roma'\n",
      " 'italy_serie-a/2016-2017/2016-11-06 - 17-00 Palermo 1 - 2 AC Milan'\n",
      " 'italy_serie-a/2016-2017/2016-11-06 - 22-45 AS Roma 3 - 0 Bologna'\n",
      " 'italy_serie-a/2016-2017/2016-11-20 - 22-45 AC Milan 2 - 2 Inter'\n",
      " 'italy_serie-a/2016-2017/2016-11-27 - 22-45 AS Roma 3 - 2 Pescara'\n",
      " 'italy_serie-a/2016-2017/2016-12-04 - 14-30 AC Milan 2 - 1 Crotone'\n",
      " 'italy_serie-a/2016-2017/2016-12-17 - 20-00 AC Milan 0 - 0 Atalanta'\n",
      " 'italy_serie-a/2016-2017/2016-12-22 - 22-45 AS Roma 3 - 1 Chievo'\n",
      " 'italy_serie-a/2016-2017/2017-01-08 - 20-00 AC Milan 1 - 0 Cagliari'\n",
      " 'italy_serie-a/2016-2017/2017-01-15 - 17-00 Napoli 3 - 1 Pescara'\n",
      " 'italy_serie-a/2016-2017/2017-01-15 - 17-00 Udinese 0 - 1 AS Roma'\n",
      " 'italy_serie-a/2016-2017/2017-01-21 - 22-45 AC Milan 1 - 2 Napoli'\n",
      " 'italy_serie-a/2016-2017/2017-02-04 - 22-45 Bologna 1 - 7 Napoli'\n",
      " 'italy_serie-a/2016-2017/2017-02-10 - 22-45 Napoli 2 - 0 Genoa'\n",
      " 'italy_serie-a/2016-2017/2017-02-12 - 14-30 Crotone 0 - 2 AS Roma'\n",
      " 'italy_serie-a/2016-2017/2017-02-19 - 20-00 AS Roma 4 - 1 Torino'\n",
      " 'italy_serie-a/2016-2017/2017-03-04 - 17-00 AS Roma 1 - 2 Napoli'\n",
      " 'italy_serie-a/2016-2017/2017-03-12 - 17-00 Napoli 3 - 0 Crotone'\n",
      " 'italy_serie-a/2016-2017/2017-03-19 - 14-30 Empoli 2 - 3 Napoli'\n",
      " 'italy_serie-a/2016-2017/2017-03-19 - 22-45 AS Roma 3 - 1 Sassuolo'\n",
      " 'italy_serie-a/2016-2017/2017-04-09 - 16-00 Bologna 0 - 3 AS Roma'\n",
      " 'italy_serie-a/2016-2017/2017-04-09 - 21-45 Lazio 0 - 3 Napoli'\n",
      " 'italy_serie-a/2016-2017/2017-04-15 - 16-00 AS Roma 1 - 1 Atalanta'\n",
      " 'italy_serie-a/2016-2017/2017-04-23 - 13-30 Sassuolo 2 - 2 Napoli'\n",
      " 'italy_serie-a/2016-2017/2017-04-24 - 21-45 Pescara 1 - 4 AS Roma'\n",
      " 'italy_serie-a/2016-2017/2017-05-07 - 21-45 AC Milan 1 - 4 AS Roma'\n",
      " 'italy_serie-a/2016-2017/2017-05-14 - 16-00 Torino 0 - 5 Napoli'\n",
      " 'italy_serie-a/2016-2017/2017-05-14 - 21-45 AS Roma 3 - 1 Juventus'\n",
      " 'italy_serie-a/2016-2017/2017-05-20 - 19-00 Chievo 3 - 5 AS Roma'\n",
      " 'italy_serie-a/2016-2017/2017-05-28 - 19-00 AS Roma 3 - 2 Genoa'\n",
      " 'italy_serie-a/2016-2017/2017-05-28 - 19-00 Sampdoria 2 - 4 Napoli'\n",
      " 'spain_laliga/2014-2015/2015-02-21 - 18-00 Barcelona 0 - 1 Malaga'\n",
      " 'spain_laliga/2014-2015/2015-02-22 - 23-00 Elche 0 - 2 Real Madrid'\n",
      " 'spain_laliga/2014-2015/2015-05-09 - 21-00 Real Madrid 2 - 2 Valencia'\n",
      " 'spain_laliga/2014-2015/2015-05-17 - 20-00 Atl. Madrid 0 - 1 Barcelona'\n",
      " 'spain_laliga/2014-2015/2015-05-17 - 20-00 Espanyol 1 - 4 Real Madrid'\n",
      " 'spain_laliga/2014-2015/2015-05-23 - 19-30 Barcelona 2 - 2 Dep. La Coruna'\n",
      " 'spain_laliga/2015-2016/2015-08-29 - 21-30 Barcelona 1 - 0 Malaga'\n",
      " 'spain_laliga/2015-2016/2015-09-12 - 17-00 Espanyol 0 - 6 Real Madrid'\n",
      " 'spain_laliga/2015-2016/2015-09-23 - 22-00 Ath Bilbao 1 - 2 Real Madrid'\n",
      " 'spain_laliga/2015-2016/2015-09-26 - 19-15 Real Madrid 0 - 0 Malaga'\n",
      " 'spain_laliga/2015-2016/2015-10-04 - 21-30 Atl. Madrid 1 - 1 Real Madrid'\n",
      " 'spain_laliga/2015-2016/2015-11-21 - 20-15 Real Madrid 0 - 4 Barcelona'\n",
      " 'spain_laliga/2015-2016/2015-11-29 - 18-00 Eibar 0 - 2 Real Madrid'\n",
      " 'spain_laliga/2015-2016/2016-01-24 - 22-30 Betis 1 - 1 Real Madrid'\n",
      " 'spain_laliga/2015-2016/2016-01-31 - 22-30 Real Madrid 6 - 0 Espanyol'\n",
      " 'spain_laliga/2015-2016/2016-02-07 - 22-30 Granada CF 1 - 2 Real Madrid'\n",
      " 'spain_laliga/2015-2016/2016-02-21 - 18-00 Malaga 1 - 1 Real Madrid'\n",
      " 'spain_laliga/2015-2016/2016-03-05 - 18-00 Real Madrid 7 - 1 Celta Vigo'\n",
      " 'spain_laliga/2015-2016/2016-03-13 - 22-30 Las Palmas 1 - 2 Real Madrid'\n",
      " 'spain_laliga/2015-2016/2016-04-02 - 21-30 Barcelona 1 - 2 Real Madrid'\n",
      " 'spain_laliga/2015-2016/2016-04-09 - 17-00 Real Madrid 4 - 0 Eibar'\n",
      " 'spain_laliga/2015-2016/2016-04-16 - 17-00 Getafe 1 - 5 Real Madrid'\n",
      " 'spain_laliga/2015-2016/2016-04-20 - 23-00 Real Madrid 3 - 0 Villarreal'\n",
      " 'spain_laliga/2015-2016/2016-04-30 - 17-00 Real Sociedad 0 - 1 Real Madrid'\n",
      " 'spain_laliga/2016-2017/2016-08-20 - 19-15 Barcelona 6 - 2 Betis'\n",
      " 'spain_laliga/2016-2017/2016-08-27 - 21-15 Real Madrid 2 - 1 Celta Vigo'\n",
      " 'spain_laliga/2016-2017/2016-08-28 - 21-15 Ath Bilbao 0 - 1 Barcelona'\n",
      " 'spain_laliga/2016-2017/2016-09-18 - 21-45 Espanyol 0 - 2 Real Madrid'\n",
      " 'spain_laliga/2016-2017/2016-09-21 - 23-00 Barcelona 1 - 1 Atl. Madrid'\n",
      " 'spain_laliga/2016-2017/2016-10-02 - 17-15 Real Madrid 1 - 1 Eibar'\n",
      " 'spain_laliga/2016-2017/2016-10-15 - 21-45 Betis 1 - 6 Real Madrid'\n",
      " 'spain_laliga/2016-2017/2016-10-22 - 17-15 Valencia 2 - 3 Barcelona'\n",
      " 'spain_laliga/2016-2017/2016-10-29 - 17-15 Alaves 1 - 4 Real Madrid'\n",
      " 'spain_laliga/2016-2017/2016-10-29 - 21-45 Barcelona 1 - 0 Granada CF'\n",
      " 'spain_laliga/2016-2017/2016-11-06 - 14-00 Real Madrid 3 - 0 Leganes'\n",
      " 'spain_laliga/2016-2017/2016-11-19 - 18-15 Barcelona 0 - 0 Malaga'\n",
      " 'spain_laliga/2016-2017/2016-11-19 - 22-45 Atl. Madrid 0 - 3 Real Madrid'\n",
      " 'spain_laliga/2016-2017/2016-11-27 - 22-45 Real Sociedad 1 - 1 Barcelona'\n",
      " 'spain_laliga/2016-2017/2016-12-03 - 18-15 Barcelona 1 - 1 Real Madrid'\n",
      " 'spain_laliga/2016-2017/2016-12-10 - 22-45 Real Madrid 3 - 2 Dep. La Coruna'\n",
      " 'spain_laliga/2016-2017/2017-01-08 - 22-45 Villarreal 1 - 1 Barcelona'\n",
      " 'spain_laliga/2016-2017/2017-01-14 - 18-15 Barcelona 5 - 0 Las Palmas'\n",
      " 'spain_laliga/2016-2017/2017-01-15 - 22-45 Sevilla 2 - 1 Real Madrid'\n",
      " 'spain_laliga/2016-2017/2017-01-29 - 14-00 Betis 1 - 1 Barcelona'\n",
      " 'spain_laliga/2016-2017/2017-01-29 - 22-45 Real Madrid 3 - 0 Real Sociedad'\n",
      " 'spain_laliga/2016-2017/2017-02-19 - 22-45 Barcelona 2 - 1 Leganes'\n",
      " 'spain_laliga/2016-2017/2017-02-26 - 18-15 Atl. Madrid 1 - 2 Barcelona'\n",
      " 'spain_laliga/2016-2017/2017-02-26 - 22-45 Villarreal 2 - 3 Real Madrid'\n",
      " 'spain_laliga/2016-2017/2017-03-01 - 21-30 Barcelona 6 - 1 Gijon'\n",
      " 'spain_laliga/2016-2017/2017-03-01 - 23-30 Real Madrid 3 - 3 Las Palmas'\n",
      " 'spain_laliga/2016-2017/2017-03-04 - 18-15 Eibar 1 - 4 Real Madrid'\n",
      " 'spain_laliga/2016-2017/2017-03-04 - 22-45 Barcelona 5 - 0 Celta Vigo'\n",
      " 'spain_laliga/2016-2017/2017-03-12 - 18-15 Dep. La Coruna 2 - 1 Barcelona'\n",
      " 'spain_laliga/2016-2017/2017-03-18 - 18-15 Ath Bilbao 1 - 2 Real Madrid'\n",
      " 'spain_laliga/2016-2017/2017-03-19 - 22-45 Barcelona 4 - 2 Valencia'\n",
      " 'spain_laliga/2016-2017/2017-04-02 - 21-45 Granada CF 1 - 4 Barcelona'\n",
      " 'spain_laliga/2016-2017/2017-04-05 - 22-30 Leganes 2 - 4 Real Madrid'\n",
      " 'spain_laliga/2016-2017/2017-04-15 - 17-15 Gijon 2 - 3 Real Madrid'\n",
      " 'spain_laliga/2016-2017/2017-04-15 - 21-45 Barcelona 3 - 2 Real Sociedad'\n",
      " 'spain_laliga/2016-2017/2017-04-26 - 22-30 Dep. La Coruna 2 - 6 Real Madrid'\n",
      " 'spain_laliga/2016-2017/2017-05-06 - 19-30 Barcelona 4 - 1 Villarreal'\n",
      " 'spain_laliga/2016-2017/2017-05-06 - 21-45 Granada CF 0 - 4 Real Madrid'\n",
      " 'spain_laliga/2016-2017/2017-05-14 - 21-00 Real Madrid 4 - 1 Sevilla'\n",
      " 'spain_laliga/2016-2017/2017-05-17 - 22-00 Celta Vigo 1 - 4 Real Madrid'\n",
      " 'spain_laliga/2016-2017/2017-05-21 - 21-00 Barcelona 4 - 2 Eibar'\n",
      " 'spain_laliga/2016-2017/2017-05-21 - 21-00 Malaga 0 - 2 Real Madrid']                \n",
      " language: all                \n",
      " root_dir: /work/oarongve/data/sound_dataset/SoccerNet-code/data/                \n",
      " transform: Compose(\n",
      "    ToTensor()\n",
      ")                \n",
      " window_size: 4                \n",
      " background: True\n",
      "\n",
      "\n",
      " ********* End of description *********\n"
     ]
    }
   ],
   "source": [
    "train_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description of dataset\n",
      "\n",
      "\n",
      "\n",
      " ********* Classes *********\n",
      "\n",
      " card = 0\n",
      " subs = 1\n",
      " goals = 2\n",
      " background = 3\n",
      "\n",
      " ********* Distribution and count *********\n",
      "\n",
      " N card: 396 \n",
      " N subs: 562 \n",
      " N goal: 356 \n",
      " N background: 636 \n",
      " \n",
      " Total : 1950\n",
      "\n",
      "\n",
      " ********* Configuration *********\n",
      "\n",
      " npy_file: ['england_epl/2014-2015/2015-04-11 - 19-30 Burnley 0 - 1 Arsenal'\n",
      " 'england_epl/2015-2016/2015-08-30 - 18-00 Swansea 2 - 1 Manchester United'\n",
      " 'england_epl/2015-2016/2015-09-26 - 17-00 Leicester 2 - 5 Arsenal'\n",
      " 'england_epl/2015-2016/2015-09-26 - 17-00 Manchester United 3 - 0 Sunderland'\n",
      " 'england_epl/2015-2016/2015-10-03 - 17-00 Manchester City 6 - 1 Newcastle Utd'\n",
      " 'england_epl/2015-2016/2015-12-26 - 18-00 Chelsea 2 - 2 Watford'\n",
      " 'england_epl/2015-2016/2016-01-23 - 20-30 West Ham 2 - 2 Manchester City'\n",
      " 'england_epl/2015-2016/2016-01-24 - 19-00 Arsenal 0 - 1 Chelsea'\n",
      " 'england_epl/2015-2016/2016-02-13 - 20-30 Chelsea 5 - 1 Newcastle Utd'\n",
      " 'england_epl/2015-2016/2016-02-27 - 18-00 Southampton 1 - 2 Chelsea'\n",
      " 'england_epl/2015-2016/2016-03-05 - 18-00 Manchester City 4 - 0 Aston Villa'\n",
      " 'england_epl/2015-2016/2016-03-20 - 19-00 Manchester City 0 - 1 Manchester United'\n",
      " 'england_epl/2015-2016/2016-04-23 - 17-00 Bournemouth 1 - 4 Chelsea'\n",
      " 'england_epl/2016-2017/2016-10-01 - 14-30 Swansea 1 - 2 Liverpool'\n",
      " 'england_epl/2016-2017/2016-10-02 - 18-30 Burnley 0 - 1 Arsenal'\n",
      " 'england_epl/2016-2017/2016-10-22 - 17-00 Arsenal 0 - 0 Middlesbrough'\n",
      " 'england_epl/2016-2017/2016-10-29 - 19-30 Crystal Palace 2 - 4 Liverpool'\n",
      " 'england_epl/2016-2017/2016-12-04 - 16-30 Bournemouth 4 - 3 Liverpool'\n",
      " 'england_epl/2016-2017/2017-04-09 - 18-00 Everton 4 - 2 Leicester'\n",
      " 'europe_uefa-champions-league/2014-2015/2014-11-04 - 22-45 Real Madrid 1 - 0 Liverpool'\n",
      " 'europe_uefa-champions-league/2014-2015/2014-11-05 - 22-45 Ajax 0 - 2 Barcelona'\n",
      " 'europe_uefa-champions-league/2014-2015/2014-11-05 - 22-45 Manchester City 1 - 2 CSKA Moscow'\n",
      " 'europe_uefa-champions-league/2014-2015/2014-12-09 - 22-45 Galatasaray 1 - 4 Arsenal'\n",
      " 'europe_uefa-champions-league/2014-2015/2014-12-09 - 22-45 Real Madrid 4 - 0 Ludogorets'\n",
      " 'europe_uefa-champions-league/2014-2015/2015-03-11 - 22-45 Bayern Munich 7 - 0 Shakhtar Donetsk'\n",
      " 'europe_uefa-champions-league/2014-2015/2015-04-15 - 21-45 Paris SG 1 - 3 Barcelona'\n",
      " 'europe_uefa-champions-league/2014-2015/2015-04-21 - 21-45 Barcelona 2 - 0 Paris SG'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-09-15 - 21-45 PSV 2 - 1 Manchester United'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-09-16 - 21-45 Chelsea 4 - 0 Maccabi Tel Aviv'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-09-16 - 21-45 Dyn. Kiev 2 - 2 FC Porto'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-09-16 - 21-45 Olympiakos Piraeus 0 - 3 Bayern Munich'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-09-29 - 21-45 Barcelona 2 - 1 Bayer Leverkusen'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-09-29 - 21-45 FC Porto 2 - 1 Chelsea'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-11-03 - 22-45 Benfica 2 - 1 Galatasaray'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-11-04 - 22-45 Barcelona 3 - 0 BATE'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-11-24 - 20-00 BATE 1 - 1 Bayer Leverkusen'\n",
      " 'europe_uefa-champions-league/2015-2016/2015-11-25 - 22-45 Juventus 1 - 0 Manchester City'\n",
      " 'europe_uefa-champions-league/2016-2017/2016-09-28 - 21-45 Napoli 4 - 2 Benfica'\n",
      " 'europe_uefa-champions-league/2016-2017/2016-10-19 - 21-45 Paris SG 3 - 0 Basel'\n",
      " 'france_ligue-1/2015-2016/2015-09-19 - 18-30 Reims 1 - 1 Paris SG'\n",
      " 'france_ligue-1/2016-2017/2016-08-21 - 21-45 Paris SG 3 - 0 Metz'\n",
      " 'france_ligue-1/2016-2017/2016-09-09 - 21-45 Paris SG 1 - 1 St Etienne'\n",
      " 'france_ligue-1/2016-2017/2016-09-20 - 22-00 Paris SG 3 - 0 Dijon'\n",
      " 'france_ligue-1/2016-2017/2016-10-23 - 21-45 Paris SG 0 - 0 Marseille'\n",
      " 'france_ligue-1/2016-2017/2016-12-03 - 19-00 Montpellier 3 - 0 Paris SG'\n",
      " 'france_ligue-1/2016-2017/2017-03-04 - 19-00 Paris SG 1 - 0 Nancy'\n",
      " 'france_ligue-1/2016-2017/2017-04-09 - 22-00 Paris SG 4 - 0 Guingamp'\n",
      " 'france_ligue-1/2016-2017/2017-05-14 - 22-00 St Etienne 0 - 5 Paris SG'\n",
      " 'germany_bundesliga/2014-2015/2015-04-25 - 19-30 Bayern Munich 1 - 0 Hertha Berlin'\n",
      " 'germany_bundesliga/2014-2015/2015-05-02 - 16-30 Hoffenheim 1 - 1 Dortmund'\n",
      " 'germany_bundesliga/2015-2016/2015-09-20 - 18-30 Dortmund 3 - 0 Bayer Leverkusen'\n",
      " 'germany_bundesliga/2015-2016/2015-10-04 - 18-30 Bayern Munich 5 - 1 Dortmund'\n",
      " 'germany_bundesliga/2015-2016/2015-11-07 - 17-30 Bayern Munich 4 - 0 VfB Stuttgart'\n",
      " 'germany_bundesliga/2015-2016/2016-04-23 - 16-30 Hertha Berlin 0 - 2 Bayern Munich'\n",
      " 'germany_bundesliga/2016-2017/2016-12-03 - 17-30 Dortmund 4 - 1 B. Monchengladbach'\n",
      " 'germany_bundesliga/2016-2017/2017-02-25 - 17-30 SC Freiburg 0 - 3 Dortmund'\n",
      " 'italy_serie-a/2014-2015/2015-04-25 - 19-00 Udinese 2 - 1 AC Milan'\n",
      " 'italy_serie-a/2014-2015/2015-05-10 - 21-45 Lazio 1 - 2 Inter'\n",
      " 'italy_serie-a/2014-2015/2015-05-17 - 13-30 Sassuolo 3 - 2 AC Milan'\n",
      " 'italy_serie-a/2015-2016/2015-09-26 - 21-45 Napoli 2 - 1 Juventus'\n",
      " 'italy_serie-a/2016-2017/2016-08-20 - 19-00 AS Roma 4 - 0 Udinese'\n",
      " 'italy_serie-a/2016-2017/2016-09-18 - 21-45 Fiorentina 1 - 0 AS Roma'\n",
      " 'italy_serie-a/2016-2017/2016-09-21 - 21-45 Genoa 0 - 0 Napoli'\n",
      " 'italy_serie-a/2016-2017/2016-10-02 - 19-00 AC Milan 4 - 3 Sassuolo'\n",
      " 'italy_serie-a/2016-2017/2016-10-29 - 21-45 Juventus 2 - 1 Napoli'\n",
      " 'italy_serie-a/2016-2017/2016-11-05 - 22-45 Napoli 1 - 1 Lazio'\n",
      " 'italy_serie-a/2016-2017/2016-12-12 - 23-00 AS Roma 1 - 0 AC Milan'\n",
      " 'italy_serie-a/2016-2017/2017-01-22 - 22-45 AS Roma 1 - 0 Cagliari'\n",
      " 'italy_serie-a/2016-2017/2017-02-19 - 17-00 Chievo 1 - 3 Napoli'\n",
      " 'italy_serie-a/2016-2017/2017-03-12 - 22-45 Palermo 0 - 3 AS Roma'\n",
      " 'italy_serie-a/2016-2017/2017-04-02 - 21-45 Napoli 1 - 1 Juventus'\n",
      " 'italy_serie-a/2016-2017/2017-04-15 - 21-45 Napoli 3 - 0 Udinese'\n",
      " 'italy_serie-a/2016-2017/2017-04-30 - 13-30 AS Roma 1 - 3 Lazio'\n",
      " 'italy_serie-a/2016-2017/2017-05-06 - 19-00 Napoli 3 - 1 Cagliari'\n",
      " 'spain_laliga/2014-2015/2015-04-11 - 17-00 Real Madrid 3 - 0 Eibar'\n",
      " 'spain_laliga/2014-2015/2015-04-11 - 21-00 Sevilla 2 - 2 Barcelona'\n",
      " 'spain_laliga/2014-2015/2015-04-28 - 21-00 Barcelona 6 - 0 Getafe'\n",
      " 'spain_laliga/2014-2015/2015-05-02 - 19-00 Atl. Madrid 0 - 0 Ath Bilbao'\n",
      " 'spain_laliga/2014-2015/2015-05-02 - 21-00 Sevilla 2 - 3 Real Madrid'\n",
      " 'spain_laliga/2014-2015/2015-05-23 - 21-30 Real Madrid 7 - 3 Getafe'\n",
      " 'spain_laliga/2015-2016/2015-09-12 - 21-30 Atl. Madrid 1 - 2 Barcelona'\n",
      " 'spain_laliga/2015-2016/2015-09-26 - 17-00 Barcelona 2 - 1 Las Palmas'\n",
      " 'spain_laliga/2015-2016/2015-10-24 - 17-00 Celta Vigo 1 - 3 Real Madrid'\n",
      " 'spain_laliga/2015-2016/2015-12-13 - 22-30 Villarreal 1 - 0 Real Madrid'\n",
      " 'spain_laliga/2015-2016/2015-12-20 - 18-00 Real Madrid 1 - 0 Rayo Vallecano'\n",
      " 'spain_laliga/2015-2016/2016-01-03 - 22-30 Valencia 2 - 2 Real Madrid'\n",
      " 'spain_laliga/2015-2016/2016-01-09 - 22-30 Real Madrid 5 - 0 Dep. La Coruna'\n",
      " 'spain_laliga/2015-2016/2016-02-13 - 18-00 Real Madrid 4 - 2 Ath Bilbao'\n",
      " 'spain_laliga/2015-2016/2016-03-20 - 22-30 Real Madrid 4 - 0 Sevilla'\n",
      " 'spain_laliga/2016-2017/2016-08-21 - 21-15 Real Sociedad 0 - 3 Real Madrid'\n",
      " 'spain_laliga/2016-2017/2016-09-17 - 14-00 Leganes 1 - 5 Barcelona'\n",
      " 'spain_laliga/2016-2017/2016-10-02 - 21-45 Celta Vigo 4 - 3 Barcelona'\n",
      " 'spain_laliga/2016-2017/2016-10-15 - 17-15 Barcelona 4 - 0 Dep. La Coruna'\n",
      " 'spain_laliga/2016-2017/2017-01-07 - 15-00 Real Madrid 5 - 0 Granada CF'\n",
      " 'spain_laliga/2016-2017/2017-01-21 - 18-15 Real Madrid 2 - 1 Malaga'\n",
      " 'spain_laliga/2016-2017/2017-02-18 - 18-15 Real Madrid 2 - 0 Espanyol'\n",
      " 'spain_laliga/2016-2017/2017-04-23 - 21-45 Real Madrid 2 - 3 Barcelona'\n",
      " 'spain_laliga/2016-2017/2017-04-29 - 17-15 Real Madrid 2 - 1 Valencia'\n",
      " 'spain_laliga/2016-2017/2017-04-29 - 21-45 Espanyol 0 - 3 Barcelona'\n",
      " 'spain_laliga/2016-2017/2017-05-14 - 21-00 Las Palmas 1 - 4 Barcelona']                \n",
      " language: all                \n",
      " root_dir: /work/oarongve/data/sound_dataset/SoccerNet-code/data/                \n",
      " transform: Compose(\n",
      "    ToTensor()\n",
      ")                \n",
      " window_size: 4                \n",
      " background: True\n",
      "\n",
      "\n",
      " ********* End of description *********\n"
     ]
    }
   ],
   "source": [
    "valid_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:34<00:00,  8.66it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.92it/s]\n"
     ]
    }
   ],
   "source": [
    "train_set.load_waves()\n",
    "valid_set.load_waves()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:11<00:00, 26.67it/s]\n",
      "100%|██████████| 100/100 [00:03<00:00, 27.14it/s]\n"
     ]
    }
   ],
   "source": [
    "train_set.generate_mel_spectrograms(load_features=True)\n",
    "valid_set.generate_mel_spectrograms(load_features=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:02<00:00, 125.24it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 126.28it/s]\n"
     ]
    }
   ],
   "source": [
    "train_set.load_resnet_features()\n",
    "valid_set.load_resnet_features()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.set_window_size(w)\n",
    "valid_set.set_window_size(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on resnet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,window_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(512,1))\n",
    "        self.bn1 = nn.BatchNorm2d(self.conv1.out_channels)\n",
    "        self.conv2 = nn.Conv2d(self.conv1.out_channels, 64, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(self.conv2.out_channels)\n",
    "        self.fc1 = nn.Linear(self.conv2.out_channels*(window_size*2), 120)\n",
    "        self.fc2 = nn.Linear(self.fc1.out_features, 84)\n",
    "        self.fc3 = nn.Linear(84, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = x.reshape(x.size(0),-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = Net(w)\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.025, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "params = {'batch_size': 24,\n",
    "         'shuffle': True,\n",
    "         'num_workers':4,\n",
    "         'drop_last':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5820"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1950"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.set_window_size(w)\n",
    "valid_set.set_window_size(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_set,**params)\n",
    "validloader = DataLoader(valid_set,**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Accuracy : 0.8179012537002563\n",
      "Finished Training\n",
      "Epoch : 1, Accuracy : 0.8302469253540039\n",
      "Finished Training\n",
      "Epoch : 2, Accuracy : 0.7854938507080078\n",
      "Finished Training\n",
      "Epoch : 3, Accuracy : 0.8436213731765747\n",
      "Finished Training\n",
      "Epoch : 4, Accuracy : 0.8497942090034485\n",
      "Finished Training\n",
      "Epoch : 5, Accuracy : 0.8261317014694214\n",
      "Finished Training\n",
      "Epoch : 6, Accuracy : 0.8215020298957825\n",
      "Finished Training\n",
      "Epoch : 7, Accuracy : 0.8436213731765747\n",
      "Finished Training\n",
      "Epoch : 8, Accuracy : 0.8492798209190369\n",
      "Finished Training\n",
      "Epoch : 9, Accuracy : 0.8235596418380737\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "net.to(device)\n",
    "epochs = 10\n",
    "accs = list()\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader,0):\n",
    "        inputs = data['resnet_spot'].unsqueeze(1).permute(0,1,3,2).to(device)\n",
    "        target = data['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "            if i % 5 == 0:    # print every 2000 mini-batches\n",
    "\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 5))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    # calculate accuracy\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        res = torch.zeros((4,4))\n",
    "        for i, data in enumerate(validloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = data['resnet_spot'].unsqueeze(1).permute(0,1,3,2).to(device)\n",
    "            label = data['label'].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "\n",
    "            for p,gt in zip(preds,label):\n",
    "                res[int(p),int(gt)] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        N_total = res.sum()\n",
    "        N_correct = res.diag().sum()\n",
    "\n",
    "        acc = N_correct / N_total\n",
    "\n",
    "        print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "        accs.append(acc)\n",
    "\n",
    "        print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "resnet = torchvision.models.resnet18(pretrained=True)\n",
    "resnet.conv1 = nn.Conv2d(1,64,kernel_size=(7,7),stride=(2,2),padding=(3,3),bias=False)\n",
    "resnet.fc = nn.Linear(512,4,bias=True)\n",
    "#resnet.features.conv0 = nn.Conv2d(1, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "#resnet.classifier = nn.Linear(in_features=densenet.classifier.in_features, out_features=3,bias=True)\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=0.0001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Accuracy : 0.508230447769165\n",
      "Epoch : 1, Accuracy : 0.5612139701843262\n",
      "Epoch : 2, Accuracy : 0.5853909254074097\n",
      "Epoch : 3, Accuracy : 0.5843621492385864\n",
      "Epoch : 4, Accuracy : 0.6116254925727844\n",
      "Epoch : 5, Accuracy : 0.6136831045150757\n",
      "Epoch : 6, Accuracy : 0.6265432238578796\n",
      "Epoch : 7, Accuracy : 0.6244856119155884\n",
      "Epoch : 8, Accuracy : 0.6219135522842407\n",
      "Epoch : 9, Accuracy : 0.5725308656692505\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "resnet.to(device)\n",
    "epochs = 10\n",
    "accs_ms = list()\n",
    "for epoch in range(epochs):\n",
    "    for i, data in enumerate(trainloader,0):\n",
    "        \n",
    "        resnet.train()\n",
    "        inputs = data['ms_spot'].unsqueeze(1).permute(0,1,2,3).to(device)\n",
    "        target = data['label'].to(device)\n",
    "        inputs[inputs.isnan()] = 0.0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = resnet(inputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "            running_loss += loss.item()\n",
    "            # print statistics\n",
    "\n",
    "\n",
    "    # calculate accuracy\n",
    "    with torch.no_grad():\n",
    "        resnet.eval()\n",
    "        res = torch.zeros((4,4))\n",
    "        for i, data in enumerate(validloader\n",
    "                                 , 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = data['ms_spot'].unsqueeze(1).permute(0,1,2,3).to(device)\n",
    "            label = data['label'].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = resnet(inputs)\n",
    "\n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "\n",
    "            for p,gt in zip(preds,label):\n",
    "                res[int(p),int(gt)] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        N_total = res.sum()\n",
    "        N_correct = res.diag().sum()\n",
    "\n",
    "        acc = N_correct / N_total\n",
    "        accs_ms.append(acc)\n",
    "        print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge models 1 - softmax average during eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 9, Accuracy : 0.8492798209190369\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    resnet.eval()\n",
    "    net.eval()\n",
    "    \n",
    "    res_visual = torch.zeros((4,4))\n",
    "    res_audio = torch.zeros((4,4))\n",
    "    res = torch.zeros((4,4))\n",
    "    \n",
    "    \n",
    "    for i, data in enumerate(validloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs_audio = data['ms_spot'].unsqueeze(1).permute(0,1,2,3).to(device)\n",
    "        inputs_visual = data['resnet_spot'].unsqueeze(1).permute(0,1,3,2).to(device)\n",
    "        label = data['label'].to(device)\n",
    "        \n",
    "        inputs_audio[inputs_audio.isnan()] = 0.0\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs_audio = resnet(inputs_audio)\n",
    "        outputs_visual = net(inputs_visual)\n",
    "\n",
    "        fused_preds = torch.softmax(outputs_audio,dim=1) + torch.softmax(outputs_visual,dim=1)\n",
    "        preds_audio = torch.argmax(outputs_audio,dim=1)\n",
    "        preds_visual = torch.argmax(outputs_visual,dim=1)\n",
    "        \n",
    "        preds = torch.argmax(fused_preds,dim=1)\n",
    "        for p,gt in zip(preds,label):\n",
    "            res[int(p),int(gt)] += 1\n",
    "        \n",
    "        for p,gt in zip(preds_audio,label):\n",
    "            res_audio[int(p),int(gt)] += 1\n",
    "            \n",
    "        for p,gt in zip(preds_visual,label):\n",
    "            res_visual[int(p),int(gt)] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    N_total = res.sum()\n",
    "    N_correct = res.diag().sum()\n",
    "\n",
    "    acc = N_correct / N_total\n",
    "    accs_ms.append(acc)\n",
    "    print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(res_a):\n",
    "    N_total = res_a.sum()\n",
    "    N_correct = res_a.diag().sum()\n",
    "\n",
    "    acc = N_correct / N_total\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8493)\n"
     ]
    }
   ],
   "source": [
    "get_acc(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5730)\n"
     ]
    }
   ],
   "source": [
    "get_acc(res_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8220)\n"
     ]
    }
   ],
   "source": [
    "get_acc(res_visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class fusion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(fusion, self).__init__()\n",
    "        self.fc1 = nn.Linear(256,256)\n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.fc3 = nn.Linear(128,3)\n",
    "        self.bn = nn.BatchNorm1d(256)\n",
    "\n",
    "    def forward(self, x_audio,x_visual):\n",
    "        x = torch.cat((x_audio,x_visual),dim=1)\n",
    "        print(x.size())\n",
    "        x = x.view(-1,256)\n",
    "        x = self.bn(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.fc = nn.Linear(512,out_features=128,bias=True)\n",
    "net.fc3 = nn.Linear(84,128,bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Window sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "resnet = torchvision.models.resnet18(pretrained=True)\n",
    "resnet.conv1 = nn.Conv2d(1,64,kernel_size=(7,7),stride=(2,2),padding=(3,3),bias=False)\n",
    "resnet.fc = nn.Linear(512,4,bias=True)\n",
    "#resnet.features.conv0 = nn.Conv2d(1, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "#resnet.classifier = nn.Linear(in_features=densenet.classifier.in_features, out_features=3,bias=True)\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsizes = [2,4,8,16,32,64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-e50ebc19c9db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "#for w in wsizes:\n",
    "w = 4 \n",
    "# set window_size for training and validation set\n",
    "train_set.set_window_size(w)\n",
    "valid_set.set_window_size(w)\n",
    "\n",
    "resnet = torchvision.models.resnet18(pretrained=True)\n",
    "resnet.conv1 = nn.Conv2d(1,64,kernel_size=(7,7),stride=(2,2),padding=(3,3),bias=False)\n",
    "resnet.fc = nn.Linear(512,3,bias=True)\n",
    "#resnet.features.conv0 = nn.Conv2d(1, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "#resnet.classifier = nn.Linear(in_features=densenet.classifier.in_features, out_features=3,bias=True)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[5,10], gamma=0.1)\n",
    "\n",
    "# train\n",
    "\n",
    "resnet.to(device)\n",
    "\n",
    "epochs = 5\n",
    "accs_ms = list()\n",
    "print(w)\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for i, data in enumerate(trainloader,0):\n",
    "\n",
    "\n",
    "        resnet.train()\n",
    "        inputs = data['ms_spot'].unsqueeze(1).permute(0,1,2,3).to(device)\n",
    "        target = data['label'].to(device)\n",
    "        inputs[inputs.isnan()] = 0.0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = resnet(inputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        scheduler.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "            running_loss += loss.item()\n",
    "            # print statistics\n",
    "\n",
    "\n",
    "    # calculate accuracy\n",
    "    with torch.no_grad():\n",
    "        resnet.eval()\n",
    "        res = torch.zeros((3,3))\n",
    "        for i, data in enumerate(validloader\n",
    "                                 , 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = data['ms_spot'].unsqueeze(1).permute(0,1,2,3).to(device)\n",
    "            label = data['label'].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = resnet(inputs)\n",
    "\n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "\n",
    "            for p,gt in zip(preds,label):\n",
    "                res[int(p),int(gt)] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        N_total = res.sum()\n",
    "        N_correct = res.diag().sum()\n",
    "\n",
    "        acc = N_correct / N_total\n",
    "        accs_ms.append(acc)\n",
    "        print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in [2,4,8,16,32,64,128]:\n",
    "    acc = 0\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    net = Net(w)\n",
    "    import torch.optim as optim\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.025, momentum=0.9)\n",
    "    net.to(device)\n",
    "    epochs = 5\n",
    "    accs = list()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader,0):\n",
    "            inputs = data['resnet_spot'].unsqueeze(1).permute(0,1,3,2).to(device)\n",
    "            target = data['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "                if i % 5 == 0:    # print every 2000 mini-batches\n",
    "\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 5))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        # calculate accuracy\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            res = torch.zeros((3,3))\n",
    "            for i, data in enumerate(validloader, 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs = data['resnet_spot'].unsqueeze(1).permute(0,1,3,2).to(device)\n",
    "                label = data['label'].to(device)\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(inputs)\n",
    "\n",
    "                preds = torch.argmax(outputs,dim=1)\n",
    "\n",
    "                for p,gt in zip(preds,label):\n",
    "                    res[int(p),int(gt)] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            N_total = res.sum()\n",
    "            N_correct = res.diag().sum()\n",
    "\n",
    "            acc = N_correct / N_total\n",
    "\n",
    "            print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "            accs.append(acc)\n",
    "\n",
    "            print('Finished Training')\n",
    "    print(f\"window: {w} acc: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in [2,4,8,16,32,64,128]:\n",
    "    acc = 0\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    train_set.set_window_size(w)\n",
    "    valid_set.set_window_size(w)\n",
    "\n",
    "    trainloader = DataLoader(train_set,**params)\n",
    "    validloader = DataLoader(valid_set,**params)\n",
    "    \n",
    "    net = Net(w)\n",
    "    import torch.optim as optim\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.025, momentum=0.9)\n",
    "    net.to(device)\n",
    "    epochs = 5\n",
    "    accs = list()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader,0):\n",
    "            inputs = data['resnet_spot'].unsqueeze(1).permute(0,1,3,2).to(device)\n",
    "            target = data['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "                if i % 5 == 0:    # print every 2000 mini-batches\n",
    "\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 5))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        # calculate accuracy\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            res = torch.zeros((3,3))\n",
    "            for i, data in enumerate(validloader, 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs = data['resnet_spot'].unsqueeze(1).permute(0,1,3,2).to(device)\n",
    "                label = data['label'].to(device)\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(inputs)\n",
    "\n",
    "                preds = torch.argmax(outputs,dim=1)\n",
    "\n",
    "                for p,gt in zip(preds,label):\n",
    "                    res[int(p),int(gt)] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            N_total = res.sum()\n",
    "            N_correct = res.diag().sum()\n",
    "\n",
    "            acc = N_correct / N_total\n",
    "\n",
    "            print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "            accs.append(acc)\n",
    "\n",
    "            print('Finished Training')\n",
    "    print(f\"window: {w} acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "params = {'batch_size': 24,\n",
    "         'shuffle': True,\n",
    "         'num_workers':4,\n",
    "         'drop_last':True}\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Accuracy : 0.4542181193828583\n",
      "Epoch : 1, Accuracy : 0.5138888955116272\n",
      "Epoch : 2, Accuracy : 0.5226337313652039\n",
      "Epoch : 3, Accuracy : 0.5416666865348816\n",
      "Epoch : 4, Accuracy : 0.5673868060112\n",
      "window: 2 acc: 0.5673868060112\n",
      "Epoch : 0, Accuracy : 0.4933127462863922\n",
      "Epoch : 1, Accuracy : 0.5570987462997437\n",
      "Epoch : 2, Accuracy : 0.5895061492919922\n",
      "Epoch : 3, Accuracy : 0.6013374328613281\n",
      "Epoch : 4, Accuracy : 0.6141975522041321\n",
      "window: 4 acc: 0.6141975522041321\n",
      "Epoch : 0, Accuracy : 0.5041152238845825\n",
      "Epoch : 1, Accuracy : 0.5977365970611572\n",
      "Epoch : 2, Accuracy : 0.6039094924926758\n",
      "Epoch : 3, Accuracy : 0.6280864477157593\n",
      "Epoch : 4, Accuracy : 0.6100823283195496\n",
      "window: 8 acc: 0.6100823283195496\n",
      "Epoch : 0, Accuracy : 0.4609053432941437\n",
      "Epoch : 1, Accuracy : 0.5673868060112\n",
      "Epoch : 2, Accuracy : 0.595678985118866\n",
      "Epoch : 3, Accuracy : 0.6064814925193787\n",
      "Epoch : 4, Accuracy : 0.6322016716003418\n",
      "window: 16 acc: 0.6322016716003418\n",
      "Epoch : 0, Accuracy : 0.4202674925327301\n",
      "Epoch : 1, Accuracy : 0.4958847761154175\n",
      "Epoch : 2, Accuracy : 0.5390946269035339\n",
      "Epoch : 3, Accuracy : 0.5730452537536621\n",
      "Epoch : 4, Accuracy : 0.6018518805503845\n",
      "window: 32 acc: 0.6018518805503845\n",
      "Epoch : 0, Accuracy : 0.36676955223083496\n",
      "Epoch : 1, Accuracy : 0.45318931341171265\n",
      "Epoch : 2, Accuracy : 0.4830246865749359\n",
      "Epoch : 3, Accuracy : 0.48816871643066406\n",
      "Epoch : 4, Accuracy : 0.5324074029922485\n",
      "window: 64 acc: 0.5324074029922485\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 2.\nOriginal Traceback (most recent call last):\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 73, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 73, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [127, 5120] at entry 0 and [127, 5083] at entry 6\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-11cb049b3bb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0maccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 2.\nOriginal Traceback (most recent call last):\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 73, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 73, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [127, 5120] at entry 0 and [127, 5083] at entry 6\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "accs_w = list()\n",
    "for w in [2,4,8,16,32,64,128]:\n",
    "    acc = 0\n",
    "    running_loss = 0\n",
    "    # fix loader\n",
    "    train_set.set_window_size(w)\n",
    "    valid_set.set_window_size(w)\n",
    "\n",
    "    trainloader = DataLoader(train_set,**params)\n",
    "    validloader = DataLoader(valid_set,**params)\n",
    "\n",
    "    resnet = torchvision.models.resnet18(pretrained=True)\n",
    "    resnet.conv1 = nn.Conv2d(1,64,kernel_size=(7,7),stride=(2,2),padding=(3,3),bias=False)\n",
    "    resnet.fc = nn.Linear(512,4,bias=True)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(resnet.parameters(), lr=0.0001, momentum=0.9)\n",
    "    resnet.to(device)\n",
    "    \n",
    "    epochs = 5\n",
    "    accs = list()\n",
    "    for epoch in range(epochs):\n",
    "        for i, data in enumerate(trainloader,0):\n",
    "\n",
    "            resnet.train()\n",
    "            inputs = data['ms_spot'].unsqueeze(1).permute(0,1,2,3).to(device)\n",
    "            target = data['label'].to(device)\n",
    "            inputs[inputs.isnan()] = 0.0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = resnet(inputs)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "                running_loss += loss.item()\n",
    "                # print statistics\n",
    "\n",
    "\n",
    "        # calculate accuracy\n",
    "        with torch.no_grad():\n",
    "            resnet.eval()\n",
    "            res = torch.zeros((4,4))\n",
    "            for i, data in enumerate(validloader, 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs = data['ms_spot'].unsqueeze(1).permute(0,1,2,3).to(device)\n",
    "                label = data['label'].to(device)\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = resnet(inputs)\n",
    "\n",
    "                preds = torch.argmax(outputs,dim=1)\n",
    "\n",
    "                for p,gt in zip(preds,label):\n",
    "                    res[int(p),int(gt)] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            N_total = res.sum()\n",
    "            N_correct = res.diag().sum()\n",
    "\n",
    "            acc = N_correct / N_total\n",
    "            \n",
    "            print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "            accs.append(acc)\n",
    "            \n",
    "    accs_w.append(acc)\n",
    "    print(f\"window: {w} acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Accuracy : 0.7860082387924194\n",
      "Finished Training\n",
      "Epoch : 1, Accuracy : 0.7988682985305786\n",
      "Finished Training\n",
      "Epoch : 2, Accuracy : 0.8091563582420349\n",
      "Finished Training\n",
      "Epoch : 3, Accuracy : 0.7824074029922485\n",
      "Finished Training\n",
      "Epoch : 4, Accuracy : 0.8127571940422058\n",
      "Finished Training\n",
      "Epoch : 5, Accuracy : 0.798353910446167\n",
      "Finished Training\n",
      "Epoch : 6, Accuracy : 0.797325074672699\n",
      "Finished Training\n",
      "Epoch : 7, Accuracy : 0.7998971343040466\n",
      "Finished Training\n",
      "Epoch : 8, Accuracy : 0.7916666865348816\n",
      "Finished Training\n",
      "Epoch : 9, Accuracy : 0.8009259104728699\n",
      "Finished Training\n",
      "window: 2 acc: 0.8009259104728699\n",
      "Epoch : 0, Accuracy : 0.8209876418113708\n",
      "Finished Training\n",
      "Epoch : 1, Accuracy : 0.8235596418380737\n",
      "Finished Training\n",
      "Epoch : 2, Accuracy : 0.8420782089233398\n",
      "Finished Training\n",
      "Epoch : 3, Accuracy : 0.8117284178733826\n",
      "Finished Training\n",
      "Epoch : 4, Accuracy : 0.826646089553833\n",
      "Finished Training\n",
      "Epoch : 5, Accuracy : 0.838477373123169\n",
      "Finished Training\n",
      "Epoch : 6, Accuracy : 0.8369341492652893\n",
      "Finished Training\n",
      "Epoch : 7, Accuracy : 0.8271604776382446\n",
      "Finished Training\n",
      "Epoch : 8, Accuracy : 0.8410493731498718\n",
      "Finished Training\n",
      "Epoch : 9, Accuracy : 0.8364197611808777\n",
      "Finished Training\n",
      "window: 4 acc: 0.8364197611808777\n",
      "Epoch : 0, Accuracy : 0.8209876418113708\n",
      "Finished Training\n",
      "Epoch : 1, Accuracy : 0.8533950448036194\n",
      "Finished Training\n",
      "Epoch : 2, Accuracy : 0.8683127760887146\n",
      "Finished Training\n",
      "Epoch : 3, Accuracy : 0.8353909254074097\n",
      "Finished Training\n",
      "Epoch : 4, Accuracy : 0.8590534925460815\n",
      "Finished Training\n",
      "Epoch : 5, Accuracy : 0.8477365970611572\n",
      "Finished Training\n",
      "Epoch : 6, Accuracy : 0.8492798209190369\n",
      "Finished Training\n",
      "Epoch : 7, Accuracy : 0.8595678806304932\n",
      "Finished Training\n",
      "Epoch : 8, Accuracy : 0.845678985118866\n",
      "Finished Training\n",
      "Epoch : 9, Accuracy : 0.8497942090034485\n",
      "Finished Training\n",
      "window: 8 acc: 0.8497942090034485\n",
      "Epoch : 0, Accuracy : 0.8719135522842407\n",
      "Finished Training\n",
      "Epoch : 1, Accuracy : 0.876028835773468\n",
      "Finished Training\n",
      "Epoch : 2, Accuracy : 0.8713991641998291\n",
      "Finished Training\n",
      "Epoch : 3, Accuracy : 0.8775720000267029\n",
      "Finished Training\n",
      "Epoch : 4, Accuracy : 0.8971193432807922\n",
      "Finished Training\n",
      "Epoch : 5, Accuracy : 0.855967104434967\n",
      "Finished Training\n",
      "Epoch : 6, Accuracy : 0.8806584477424622\n",
      "Finished Training\n",
      "Epoch : 7, Accuracy : 0.8822016716003418\n",
      "Finished Training\n",
      "Epoch : 8, Accuracy : 0.8708847761154175\n",
      "Finished Training\n",
      "Epoch : 9, Accuracy : 0.8827160596847534\n",
      "Finished Training\n",
      "window: 16 acc: 0.8827160596847534\n",
      "Epoch : 0, Accuracy : 0.8657407164573669\n",
      "Finished Training\n",
      "Epoch : 1, Accuracy : 0.8852880597114563\n",
      "Finished Training\n",
      "Epoch : 2, Accuracy : 0.8719135522842407\n",
      "Finished Training\n",
      "Epoch : 3, Accuracy : 0.9048354029655457\n",
      "Finished Training\n",
      "Epoch : 4, Accuracy : 0.8811728358268738\n",
      "Finished Training\n",
      "Epoch : 5, Accuracy : 0.9079217910766602\n",
      "Finished Training\n",
      "Epoch : 6, Accuracy : 0.9094650149345398\n",
      "Finished Training\n",
      "Epoch : 7, Accuracy : 0.8883745074272156\n",
      "Finished Training\n",
      "Epoch : 8, Accuracy : 0.9027777910232544\n",
      "Finished Training\n",
      "Epoch : 9, Accuracy : 0.8976337313652039\n",
      "Finished Training\n",
      "window: 32 acc: 0.8976337313652039\n",
      "Epoch : 0, Accuracy : 0.8775720000267029\n",
      "Finished Training\n",
      "Epoch : 1, Accuracy : 0.8852880597114563\n",
      "Finished Training\n",
      "Epoch : 2, Accuracy : 0.8924897313117981\n",
      "Finished Training\n",
      "Epoch : 3, Accuracy : 0.895061731338501\n",
      "Finished Training\n",
      "Epoch : 4, Accuracy : 0.9074074029922485\n",
      "Finished Training\n",
      "Epoch : 5, Accuracy : 0.8945473432540894\n",
      "Finished Training\n",
      "Epoch : 6, Accuracy : 0.9104938507080078\n",
      "Finished Training\n",
      "Epoch : 7, Accuracy : 0.9002057909965515\n",
      "Finished Training\n",
      "Epoch : 8, Accuracy : 0.8683127760887146\n",
      "Finished Training\n",
      "Epoch : 9, Accuracy : 0.8930041193962097\n",
      "Finished Training\n",
      "window: 64 acc: 0.8930041193962097\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 73, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 73, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [127, 5120] at entry 0 and [127, 5116] at entry 5\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-af80a19d06b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'resnet_spot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 73, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 73, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [127, 5120] at entry 0 and [127, 5116] at entry 5\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "accs_w_v = list()\n",
    "for w in [2,4,8,16,32,64,128]:\n",
    "    acc = 0\n",
    "    running_loss = 0\n",
    "    # fix loader\n",
    "    train_set.set_window_size(w)\n",
    "    valid_set.set_window_size(w)\n",
    "\n",
    "    trainloader = DataLoader(train_set,**params)\n",
    "    validloader = DataLoader(valid_set,**params)\n",
    "\n",
    "    net = Net(w)\n",
    "    import torch.optim as optim\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.025, momentum=0.9)\n",
    "    \n",
    "    epochs = 5\n",
    "    accs = list()\n",
    "    net.to(device)\n",
    "    epochs = 10\n",
    "    accs = list()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader,0):\n",
    "            inputs = data['resnet_spot'].unsqueeze(1).permute(0,1,3,2).to(device)\n",
    "            target = data['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "                if i % 5 == 0:    # print every 2000 mini-batches\n",
    "\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 5))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        # calculate accuracy\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            res = torch.zeros((4,4))\n",
    "            for i, data in enumerate(validloader, 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs = data['resnet_spot'].unsqueeze(1).permute(0,1,3,2).to(device)\n",
    "                label = data['label'].to(device)\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(inputs)\n",
    "\n",
    "                preds = torch.argmax(outputs,dim=1)\n",
    "\n",
    "                for p,gt in zip(preds,label):\n",
    "                    res[int(p),int(gt)] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            N_total = res.sum()\n",
    "            N_correct = res.diag().sum()\n",
    "\n",
    "            acc = N_correct / N_total\n",
    "\n",
    "            print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "            accs.append(acc)\n",
    "\n",
    "            print('Finished Training')\n",
    "\n",
    "        accs_w_v.append(accs) # get best acc, save best model\n",
    "    print(f\"window: {w} acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put into more clean place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-daredevil",
   "language": "python",
   "name": "project-daredevil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
