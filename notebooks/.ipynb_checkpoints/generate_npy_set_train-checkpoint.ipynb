{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchaudio\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir   = \"/work/oarongve/data/sound_dataset/SoccerNet-code/data/\"\n",
    "train_file = root_dir+\"listgame_Train_300.npy\"\n",
    "valid_file = root_dir+\"listgame_Valid_100.npy\"\n",
    "test_file  = root_dir+\"listgame_Test_100.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No devices were found\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'nvidia-smi\\n'' returned non-zero exit status 6.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f0b607b6201c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nvidia-smi\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2369\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2370\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2371\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2372\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'nvidia-smi\\n'' returned non-zero exit status 6."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Test loading of some samples from train_samples.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s = np.load(root_dir+\"train_samples.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(s[0]['audiopath'][:-11]+str(0)+\"_ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_s = np.load(str(s[0]['audiopath'][:-11]+str(0)+\"_ms.npy\"),allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[0]['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import torchvision\n",
    "import datetime\n",
    "import torchaudio\n",
    "import librosa\n",
    "from subprocess import Popen, PIPE\n",
    "import re\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "class soccernet_ms_npy_DS(Dataset):\n",
    "    \"\"\"Soccernet Dataset\"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self,npy_file,\n",
    "                 root_dir,\n",
    "                 transform=None,\n",
    "                 train=True):\n",
    "    \n",
    "        self.samples = np.load(root_dir+npy_file,allow_pickle=True)        # GENERALIZE\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        \"\"\"Returns a sample containing video path, clip and label\"\"\"\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx.tolist()\n",
    "        \n",
    "        if self.train:\n",
    "            if idx in [2209,2210,2212,2213,2215,2217,2222]: # ultradirty hack - fix later\n",
    "                idx = 0\n",
    "        \n",
    "        path = str(self.samples[idx]['audiopath'][:-11]+str(idx)+\"_ms.npy\")\n",
    "        ms = np.load(path)\n",
    "        ms = ms-np.min(ms) / (np.max(ms)-np.min(ms))\n",
    "        label = self.samples[idx]['label']\n",
    "        info = self.samples[idx]['annotation']\n",
    "        idx_old = self.samples[idx]['idx']\n",
    "        \n",
    "        sample = {'path': path,\n",
    "                  'ms':ms,'idx': idx_old,\n",
    "                  'label':label}\n",
    "        \n",
    "        return sample\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples = np.load(root_dir+\"train_samples.npy\",allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_rm = list()\n",
    "for e in samples:\n",
    "    if e['idx'] not in [2209,2210,2011,2212,2213,2215,2217,2222]:\n",
    "        samples_rm.append(e)\n",
    "    else:\n",
    "        continue\n",
    "        #samples_rm.append(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(file=root_dir+\"train_samples_mod.npy\",arr=np.array(samples_rm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[2220]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Note: Can also see warning once\n",
    "# warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 12,\n",
    "         'shuffle': True,\n",
    "         'num_workers':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_npy = soccernet_ms_npy_DS(root_dir=root_dir,npy_file=\"train_samples.npy\")\n",
    "#X_valid_npy = soccernet_ms_npy_DS(root_dir=root_dir,npy_file=\"valid_samples.npy\")\n",
    "X_test_npy = soccernet_ms_npy_DS(root_dir=root_dir,npy_file=\"test_samples.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(X_train_npy,**params)\n",
    "testloader = DataLoader(X_test_npy,**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = list()\n",
    "mean = list()\n",
    "\n",
    "for e in X_train_npy:\n",
    "    print(e['ms'].mean())\n",
    "    mean.append(e['ms'].mean())\n",
    "    std.append(e['ms'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for s in range(len(X_train_npy)):\n",
    "    if np.isnan(X_train_npy[s]['ms']).any():\n",
    "        print(\"found one!\")\n",
    "        print(X_train_npy[s]['idx'])\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_npy[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(np.array(mean).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(np.array(mean)[0:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(np.array(mean)[2220:2230]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(mean)[2220:2230]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.pool = nn.MaxPool2d(4, 4)\n",
    "        self.fc1 = nn.Linear(2208, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = x.view(-1, 2208)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/simple_net3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=2208, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.025, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.222\n",
      "[1,     6] loss: 1.082\n",
      "[1,    11] loss: 1.066\n",
      "[1,    16] loss: 0.961\n",
      "[1,    21] loss: 1.020\n",
      "[1,    26] loss: 1.160\n",
      "[1,    31] loss: 1.126\n",
      "[1,    36] loss: 0.956\n",
      "[1,    41] loss: 0.895\n",
      "[1,    46] loss: 0.746\n",
      "[1,    51] loss: 0.748\n",
      "[1,    56] loss: 0.842\n",
      "[1,    61] loss: 1.133\n",
      "[1,    66] loss: 1.009\n",
      "[1,    71] loss: 0.898\n",
      "[1,    76] loss: 1.018\n",
      "[1,    81] loss: 0.710\n",
      "[1,    86] loss: 0.701\n",
      "[1,    91] loss: 0.690\n",
      "[1,    96] loss: 0.725\n",
      "[1,   101] loss: 0.735\n",
      "[1,   106] loss: 1.000\n",
      "[1,   111] loss: 0.773\n",
      "[1,   116] loss: 0.597\n",
      "[1,   121] loss: 0.665\n",
      "[1,   126] loss: 0.654\n",
      "[1,   131] loss: 0.757\n",
      "[1,   136] loss: 0.729\n",
      "[1,   141] loss: 0.751\n",
      "[1,   146] loss: 0.673\n",
      "[1,   151] loss: 0.842\n",
      "[1,   156] loss: 0.887\n",
      "[1,   161] loss: 0.906\n",
      "[1,   166] loss: 0.855\n",
      "[1,   171] loss: 0.550\n",
      "[1,   176] loss: 0.925\n",
      "[1,   181] loss: 0.606\n",
      "[1,   186] loss: 0.811\n",
      "[1,   191] loss: 0.788\n",
      "[1,   196] loss: 0.543\n",
      "[1,   201] loss: 0.662\n",
      "[1,   206] loss: 0.664\n",
      "[1,   211] loss: 0.604\n",
      "[1,   216] loss: 0.669\n",
      "[1,   221] loss: 0.626\n",
      "[1,   226] loss: 0.638\n",
      "[1,   231] loss: 0.579\n",
      "[1,   236] loss: 0.903\n",
      "[1,   241] loss: 0.576\n",
      "[1,   246] loss: 0.697\n",
      "[1,   251] loss: 0.854\n",
      "[1,   256] loss: 0.871\n",
      "[1,   261] loss: 0.892\n",
      "[1,   266] loss: 0.646\n",
      "[1,   271] loss: 0.723\n",
      "[1,   276] loss: 0.741\n",
      "[1,   281] loss: 0.636\n",
      "[1,   286] loss: 0.449\n",
      "[1,   291] loss: 0.603\n",
      "[1,   296] loss: 0.951\n",
      "[1,   301] loss: 0.747\n",
      "[1,   306] loss: 0.694\n",
      "[1,   311] loss: 0.768\n",
      "[1,   316] loss: 0.706\n",
      "[1,   321] loss: 0.748\n",
      "[1,   326] loss: 0.555\n",
      "[1,   331] loss: 0.683\n",
      "Epoch : 0, Accuracy : 0.7496318221092224\n",
      "[2,     1] loss: 0.093\n",
      "[2,     6] loss: 0.625\n",
      "[2,    11] loss: 0.601\n",
      "[2,    16] loss: 0.496\n",
      "[2,    21] loss: 0.556\n",
      "[2,    26] loss: 0.646\n",
      "[2,    31] loss: 0.608\n",
      "[2,    36] loss: 0.558\n",
      "[2,    41] loss: 0.678\n",
      "[2,    46] loss: 0.506\n",
      "[2,    51] loss: 0.588\n",
      "[2,    56] loss: 0.567\n",
      "[2,    61] loss: 0.530\n",
      "[2,    66] loss: 0.571\n",
      "[2,    71] loss: 0.569\n",
      "[2,    76] loss: 0.647\n",
      "[2,    81] loss: 0.577\n",
      "[2,    86] loss: 0.700\n",
      "[2,    91] loss: 0.573\n",
      "[2,    96] loss: 0.705\n",
      "[2,   101] loss: 0.778\n",
      "[2,   106] loss: 0.750\n",
      "[2,   111] loss: 0.454\n",
      "[2,   116] loss: 0.619\n",
      "[2,   121] loss: 0.572\n",
      "[2,   126] loss: 0.620\n",
      "[2,   131] loss: 0.573\n",
      "[2,   136] loss: 0.857\n",
      "[2,   141] loss: 0.804\n",
      "[2,   146] loss: 0.739\n",
      "[2,   151] loss: 0.534\n",
      "[2,   156] loss: 0.625\n",
      "[2,   161] loss: 0.560\n",
      "[2,   166] loss: 0.448\n",
      "[2,   171] loss: 0.550\n",
      "[2,   176] loss: 0.559\n",
      "[2,   181] loss: 0.725\n",
      "[2,   186] loss: 0.637\n",
      "[2,   191] loss: 0.692\n",
      "[2,   196] loss: 0.565\n",
      "[2,   201] loss: 0.518\n",
      "[2,   206] loss: 0.602\n",
      "[2,   211] loss: 0.594\n",
      "[2,   216] loss: 0.560\n",
      "[2,   221] loss: 0.614\n",
      "[2,   226] loss: 0.542\n",
      "[2,   231] loss: 0.552\n",
      "[2,   236] loss: 0.410\n",
      "[2,   241] loss: 0.727\n",
      "[2,   246] loss: 0.529\n",
      "[2,   251] loss: 0.640\n",
      "[2,   256] loss: 0.485\n",
      "[2,   261] loss: 0.443\n",
      "[2,   266] loss: 0.556\n",
      "[2,   271] loss: 0.387\n",
      "[2,   276] loss: 0.505\n",
      "[2,   281] loss: 0.477\n",
      "[2,   286] loss: 0.369\n",
      "[2,   291] loss: 0.464\n",
      "[2,   296] loss: 0.607\n",
      "[2,   301] loss: 0.707\n",
      "[2,   306] loss: 0.600\n",
      "[2,   311] loss: 0.471\n",
      "[2,   316] loss: 0.731\n",
      "[2,   321] loss: 0.557\n",
      "[2,   326] loss: 0.535\n",
      "[2,   331] loss: 0.788\n",
      "Epoch : 1, Accuracy : 0.7812960147857666\n",
      "[3,     1] loss: 0.115\n",
      "[3,     6] loss: 0.346\n",
      "[3,    11] loss: 0.407\n",
      "[3,    16] loss: 0.481\n",
      "[3,    21] loss: 0.527\n",
      "[3,    26] loss: 0.727\n",
      "[3,    31] loss: 0.465\n",
      "[3,    36] loss: 0.429\n",
      "[3,    41] loss: 0.584\n",
      "[3,    46] loss: 0.497\n",
      "[3,    51] loss: 0.515\n",
      "[3,    56] loss: 0.419\n",
      "[3,    61] loss: 0.605\n",
      "[3,    66] loss: 0.502\n",
      "[3,    71] loss: 0.585\n",
      "[3,    76] loss: 0.454\n",
      "[3,    81] loss: 0.441\n",
      "[3,    86] loss: 0.576\n",
      "[3,    91] loss: 0.376\n",
      "[3,    96] loss: 0.550\n",
      "[3,   101] loss: 0.384\n",
      "[3,   106] loss: 0.517\n",
      "[3,   111] loss: 0.429\n",
      "[3,   116] loss: 0.574\n",
      "[3,   121] loss: 0.455\n",
      "[3,   126] loss: 0.603\n",
      "[3,   131] loss: 0.456\n",
      "[3,   136] loss: 0.534\n",
      "[3,   141] loss: 0.446\n",
      "[3,   146] loss: 0.415\n",
      "[3,   151] loss: 0.462\n",
      "[3,   156] loss: 0.506\n",
      "[3,   161] loss: 0.535\n",
      "[3,   166] loss: 0.425\n",
      "[3,   171] loss: 0.514\n",
      "[3,   176] loss: 0.365\n",
      "[3,   181] loss: 0.342\n",
      "[3,   186] loss: 0.345\n",
      "[3,   191] loss: 0.401\n",
      "[3,   196] loss: 0.399\n",
      "[3,   201] loss: 0.632\n",
      "[3,   206] loss: 0.469\n",
      "[3,   211] loss: 0.531\n",
      "[3,   216] loss: 0.460\n",
      "[3,   221] loss: 0.521\n",
      "[3,   226] loss: 0.484\n",
      "[3,   231] loss: 0.536\n",
      "[3,   236] loss: 0.442\n",
      "[3,   241] loss: 0.418\n",
      "[3,   246] loss: 0.415\n",
      "[3,   251] loss: 0.376\n",
      "[3,   256] loss: 1.055\n",
      "[3,   261] loss: 0.434\n",
      "[3,   266] loss: 0.538\n",
      "[3,   271] loss: 0.599\n",
      "[3,   276] loss: 0.464\n",
      "[3,   281] loss: 0.377\n",
      "[3,   286] loss: 0.660\n",
      "[3,   291] loss: 0.431\n",
      "[3,   296] loss: 0.514\n",
      "[3,   301] loss: 0.538\n",
      "[3,   306] loss: 0.480\n",
      "[3,   311] loss: 0.546\n",
      "[3,   316] loss: 0.540\n",
      "[3,   321] loss: 0.574\n",
      "[3,   326] loss: 0.366\n",
      "[3,   331] loss: 0.397\n",
      "Epoch : 2, Accuracy : 0.7569955587387085\n",
      "[4,     1] loss: 0.155\n",
      "[4,     6] loss: 0.494\n",
      "[4,    11] loss: 0.468\n",
      "[4,    16] loss: 0.369\n",
      "[4,    21] loss: 0.531\n",
      "[4,    26] loss: 0.486\n",
      "[4,    31] loss: 0.366\n",
      "[4,    36] loss: 0.506\n",
      "[4,    41] loss: 0.382\n",
      "[4,    46] loss: 0.445\n",
      "[4,    51] loss: 0.356\n",
      "[4,    56] loss: 0.461\n",
      "[4,    61] loss: 0.509\n",
      "[4,    66] loss: 0.477\n",
      "[4,    71] loss: 0.437\n",
      "[4,    76] loss: 0.388\n",
      "[4,    81] loss: 0.451\n",
      "[4,    86] loss: 0.713\n",
      "[4,    91] loss: 0.405\n",
      "[4,    96] loss: 0.608\n",
      "[4,   101] loss: 0.487\n",
      "[4,   106] loss: 0.449\n",
      "[4,   111] loss: 0.444\n",
      "[4,   116] loss: 0.511\n",
      "[4,   121] loss: 0.368\n",
      "[4,   126] loss: 0.539\n",
      "[4,   131] loss: 0.540\n",
      "[4,   136] loss: 0.352\n",
      "[4,   141] loss: 0.420\n",
      "[4,   146] loss: 0.482\n",
      "[4,   151] loss: 0.270\n",
      "[4,   156] loss: 0.485\n",
      "[4,   161] loss: 0.282\n",
      "[4,   166] loss: 0.537\n",
      "[4,   171] loss: 0.321\n",
      "[4,   176] loss: 0.451\n",
      "[4,   181] loss: 0.567\n",
      "[4,   186] loss: 0.472\n",
      "[4,   191] loss: 0.325\n",
      "[4,   196] loss: 0.489\n",
      "[4,   201] loss: 0.409\n",
      "[4,   206] loss: 0.380\n",
      "[4,   211] loss: 0.470\n",
      "[4,   216] loss: 0.491\n",
      "[4,   221] loss: 0.344\n",
      "[4,   226] loss: 0.406\n",
      "[4,   231] loss: 0.427\n",
      "[4,   236] loss: 0.455\n",
      "[4,   241] loss: 0.524\n",
      "[4,   246] loss: 0.585\n",
      "[4,   251] loss: 0.526\n",
      "[4,   256] loss: 0.532\n",
      "[4,   261] loss: 0.470\n",
      "[4,   266] loss: 0.452\n",
      "[4,   271] loss: 0.339\n",
      "[4,   276] loss: 0.382\n",
      "[4,   281] loss: 0.477\n",
      "[4,   286] loss: 0.265\n",
      "[4,   291] loss: 0.316\n",
      "[4,   296] loss: 0.379\n",
      "[4,   301] loss: 0.226\n",
      "[4,   306] loss: 0.691\n",
      "[4,   311] loss: 0.395\n",
      "[4,   316] loss: 0.549\n",
      "[4,   321] loss: 0.523\n",
      "[4,   326] loss: 0.467\n",
      "[4,   331] loss: 0.359\n",
      "Epoch : 3, Accuracy : 0.7952871918678284\n",
      "[5,     1] loss: 0.104\n",
      "[5,     6] loss: 0.489\n",
      "[5,    11] loss: 0.407\n",
      "[5,    16] loss: 0.422\n",
      "[5,    21] loss: 0.380\n",
      "[5,    26] loss: 0.417\n",
      "[5,    31] loss: 0.402\n",
      "[5,    36] loss: 0.603\n",
      "[5,    41] loss: 0.332\n",
      "[5,    46] loss: 0.636\n",
      "[5,    51] loss: 0.465\n",
      "[5,    56] loss: 0.546\n",
      "[5,    61] loss: 0.535\n",
      "[5,    66] loss: 0.454\n",
      "[5,    71] loss: 0.342\n",
      "[5,    76] loss: 0.322\n",
      "[5,    81] loss: 0.552\n",
      "[5,    86] loss: 0.314\n",
      "[5,    91] loss: 0.520\n",
      "[5,    96] loss: 0.367\n",
      "[5,   101] loss: 0.465\n",
      "[5,   106] loss: 0.399\n",
      "[5,   111] loss: 0.362\n",
      "[5,   116] loss: 0.497\n",
      "[5,   121] loss: 0.537\n",
      "[5,   126] loss: 0.476\n",
      "[5,   131] loss: 0.429\n",
      "[5,   136] loss: 0.257\n",
      "[5,   141] loss: 0.325\n",
      "[5,   146] loss: 0.460\n",
      "[5,   151] loss: 0.427\n",
      "[5,   156] loss: 0.313\n",
      "[5,   161] loss: 0.478\n",
      "[5,   166] loss: 0.456\n",
      "[5,   171] loss: 0.381\n",
      "[5,   176] loss: 0.473\n",
      "[5,   181] loss: 0.493\n",
      "[5,   186] loss: 0.278\n",
      "[5,   191] loss: 0.507\n",
      "[5,   196] loss: 0.329\n",
      "[5,   201] loss: 0.388\n",
      "[5,   206] loss: 0.447\n",
      "[5,   211] loss: 0.327\n",
      "[5,   216] loss: 0.330\n",
      "[5,   221] loss: 0.608\n",
      "[5,   226] loss: 0.265\n",
      "[5,   231] loss: 0.364\n",
      "[5,   236] loss: 0.617\n",
      "[5,   241] loss: 0.391\n",
      "[5,   246] loss: 0.453\n",
      "[5,   251] loss: 0.460\n",
      "[5,   256] loss: 0.438\n",
      "[5,   261] loss: 0.518\n",
      "[5,   266] loss: 0.491\n",
      "[5,   271] loss: 0.412\n",
      "[5,   276] loss: 0.435\n",
      "[5,   281] loss: 0.369\n",
      "[5,   286] loss: 0.434\n",
      "[5,   291] loss: 0.414\n",
      "[5,   296] loss: 0.394\n",
      "[5,   301] loss: 0.453\n",
      "[5,   306] loss: 0.296\n",
      "[5,   311] loss: 0.409\n",
      "[5,   316] loss: 0.280\n",
      "[5,   321] loss: 0.266\n",
      "[5,   326] loss: 0.465\n",
      "[5,   331] loss: 0.383\n",
      "Epoch : 4, Accuracy : 0.8136966228485107\n",
      "[6,     1] loss: 0.061\n",
      "[6,     6] loss: 0.362\n",
      "[6,    11] loss: 0.389\n",
      "[6,    16] loss: 0.232\n",
      "[6,    21] loss: 0.351\n",
      "[6,    26] loss: 0.459\n",
      "[6,    31] loss: 0.415\n",
      "[6,    36] loss: 0.240\n",
      "[6,    41] loss: 0.449\n",
      "[6,    46] loss: 0.333\n",
      "[6,    51] loss: 0.610\n",
      "[6,    56] loss: 0.395\n",
      "[6,    61] loss: 0.492\n",
      "[6,    66] loss: 0.322\n",
      "[6,    71] loss: 0.486\n",
      "[6,    76] loss: 0.398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,    81] loss: 0.363\n",
      "[6,    86] loss: 0.294\n",
      "[6,    91] loss: 0.302\n",
      "[6,    96] loss: 0.306\n",
      "[6,   101] loss: 0.429\n",
      "[6,   106] loss: 0.467\n",
      "[6,   111] loss: 0.400\n",
      "[6,   116] loss: 0.395\n",
      "[6,   121] loss: 0.321\n",
      "[6,   126] loss: 0.316\n",
      "[6,   131] loss: 0.333\n",
      "[6,   136] loss: 0.519\n",
      "[6,   141] loss: 0.396\n",
      "[6,   146] loss: 0.491\n",
      "[6,   151] loss: 0.316\n",
      "[6,   156] loss: 0.402\n",
      "[6,   161] loss: 0.281\n",
      "[6,   166] loss: 0.652\n",
      "[6,   171] loss: 0.409\n",
      "[6,   176] loss: 0.506\n",
      "[6,   181] loss: 0.274\n",
      "[6,   186] loss: 0.402\n",
      "[6,   191] loss: 0.293\n",
      "[6,   196] loss: 0.447\n",
      "[6,   201] loss: 0.500\n",
      "[6,   206] loss: 0.393\n",
      "[6,   211] loss: 0.319\n",
      "[6,   216] loss: 0.542\n",
      "[6,   221] loss: 0.444\n",
      "[6,   226] loss: 0.303\n",
      "[6,   231] loss: 0.317\n",
      "[6,   236] loss: 0.392\n",
      "[6,   241] loss: 0.279\n",
      "[6,   246] loss: 0.362\n",
      "[6,   251] loss: 0.413\n",
      "[6,   256] loss: 0.469\n",
      "[6,   261] loss: 0.438\n",
      "[6,   266] loss: 0.234\n",
      "[6,   271] loss: 0.399\n",
      "[6,   276] loss: 0.426\n",
      "[6,   281] loss: 0.564\n",
      "[6,   286] loss: 0.380\n",
      "[6,   291] loss: 0.420\n",
      "[6,   296] loss: 0.333\n",
      "[6,   301] loss: 0.546\n",
      "[6,   306] loss: 0.286\n",
      "[6,   311] loss: 0.559\n",
      "[6,   316] loss: 0.415\n",
      "[6,   321] loss: 0.497\n",
      "[6,   326] loss: 0.440\n",
      "[6,   331] loss: 0.398\n",
      "Epoch : 5, Accuracy : 0.8129602074623108\n",
      "[7,     1] loss: 0.063\n",
      "[7,     6] loss: 0.308\n",
      "[7,    11] loss: 0.420\n",
      "[7,    16] loss: 0.351\n",
      "[7,    21] loss: 0.338\n",
      "[7,    26] loss: 0.382\n",
      "[7,    31] loss: 0.403\n",
      "[7,    36] loss: 0.181\n",
      "[7,    41] loss: 0.474\n",
      "[7,    46] loss: 0.440\n",
      "[7,    51] loss: 0.410\n",
      "[7,    56] loss: 0.347\n",
      "[7,    61] loss: 0.406\n",
      "[7,    66] loss: 0.546\n",
      "[7,    71] loss: 0.621\n",
      "[7,    76] loss: 0.331\n",
      "[7,    81] loss: 0.495\n",
      "[7,    86] loss: 0.581\n",
      "[7,    91] loss: 0.366\n",
      "[7,    96] loss: 0.283\n",
      "[7,   101] loss: 0.350\n",
      "[7,   106] loss: 0.275\n",
      "[7,   111] loss: 0.487\n",
      "[7,   116] loss: 0.472\n",
      "[7,   121] loss: 0.312\n",
      "[7,   126] loss: 0.284\n",
      "[7,   131] loss: 0.208\n",
      "[7,   136] loss: 0.328\n",
      "[7,   141] loss: 0.499\n",
      "[7,   146] loss: 0.541\n",
      "[7,   151] loss: 0.379\n",
      "[7,   156] loss: 0.598\n",
      "[7,   161] loss: 0.323\n",
      "[7,   166] loss: 0.333\n",
      "[7,   171] loss: 0.327\n",
      "[7,   176] loss: 0.554\n",
      "[7,   181] loss: 0.566\n",
      "[7,   186] loss: 0.439\n",
      "[7,   191] loss: 0.419\n",
      "[7,   196] loss: 0.418\n",
      "[7,   201] loss: 0.836\n",
      "[7,   206] loss: 0.282\n",
      "[7,   211] loss: 0.305\n",
      "[7,   216] loss: 0.361\n",
      "[7,   221] loss: 0.331\n",
      "[7,   226] loss: 0.551\n",
      "[7,   231] loss: 0.374\n",
      "[7,   236] loss: 0.404\n",
      "[7,   241] loss: 0.420\n",
      "[7,   246] loss: 0.399\n",
      "[7,   251] loss: 0.320\n",
      "[7,   256] loss: 0.411\n",
      "[7,   261] loss: 0.385\n",
      "[7,   266] loss: 0.395\n",
      "[7,   271] loss: 0.321\n",
      "[7,   276] loss: 0.308\n",
      "[7,   281] loss: 0.278\n",
      "[7,   286] loss: 0.603\n",
      "[7,   291] loss: 0.338\n",
      "[7,   296] loss: 0.549\n",
      "[7,   301] loss: 0.475\n",
      "[7,   306] loss: 0.378\n",
      "[7,   311] loss: 0.295\n",
      "[7,   316] loss: 0.566\n",
      "[7,   321] loss: 0.400\n",
      "[7,   326] loss: 0.524\n",
      "[7,   331] loss: 0.282\n",
      "Epoch : 6, Accuracy : 0.8195876479148865\n",
      "[8,     1] loss: 0.055\n",
      "[8,     6] loss: 0.384\n",
      "[8,    11] loss: 0.267\n",
      "[8,    16] loss: 0.369\n",
      "[8,    21] loss: 0.347\n",
      "[8,    26] loss: 0.278\n",
      "[8,    31] loss: 0.274\n",
      "[8,    36] loss: 0.221\n",
      "[8,    41] loss: 0.298\n",
      "[8,    46] loss: 0.224\n",
      "[8,    51] loss: 0.353\n",
      "[8,    56] loss: 0.305\n",
      "[8,    61] loss: 0.405\n",
      "[8,    66] loss: 0.161\n",
      "[8,    71] loss: 0.288\n",
      "[8,    76] loss: 0.373\n",
      "[8,    81] loss: 0.195\n",
      "[8,    86] loss: 0.252\n",
      "[8,    91] loss: 0.407\n",
      "[8,    96] loss: 0.249\n",
      "[8,   101] loss: 0.362\n",
      "[8,   106] loss: 0.325\n",
      "[8,   111] loss: 0.292\n",
      "[8,   116] loss: 0.330\n",
      "[8,   121] loss: 0.578\n",
      "[8,   126] loss: 0.445\n",
      "[8,   131] loss: 0.503\n",
      "[8,   136] loss: 0.393\n",
      "[8,   141] loss: 0.319\n",
      "[8,   146] loss: 0.271\n",
      "[8,   151] loss: 0.191\n",
      "[8,   156] loss: 0.466\n",
      "[8,   161] loss: 0.326\n",
      "[8,   166] loss: 0.309\n",
      "[8,   171] loss: 0.310\n",
      "[8,   176] loss: 0.463\n",
      "[8,   181] loss: 0.338\n",
      "[8,   186] loss: 0.393\n",
      "[8,   191] loss: 0.394\n",
      "[8,   196] loss: 0.359\n",
      "[8,   201] loss: 0.234\n",
      "[8,   206] loss: 0.247\n",
      "[8,   211] loss: 0.332\n",
      "[8,   216] loss: 0.381\n",
      "[8,   221] loss: 0.425\n",
      "[8,   226] loss: 0.300\n",
      "[8,   231] loss: 0.305\n",
      "[8,   236] loss: 0.449\n",
      "[8,   241] loss: 0.343\n",
      "[8,   246] loss: 0.313\n",
      "[8,   251] loss: 0.397\n",
      "[8,   256] loss: 0.238\n",
      "[8,   261] loss: 0.397\n",
      "[8,   266] loss: 0.268\n",
      "[8,   271] loss: 0.397\n",
      "[8,   276] loss: 0.299\n",
      "[8,   281] loss: 0.345\n",
      "[8,   286] loss: 0.480\n",
      "[8,   291] loss: 0.277\n",
      "[8,   296] loss: 0.376\n",
      "[8,   301] loss: 0.404\n",
      "[8,   306] loss: 0.296\n",
      "[8,   311] loss: 0.469\n",
      "[8,   316] loss: 0.301\n",
      "[8,   321] loss: 0.606\n",
      "[8,   326] loss: 0.319\n",
      "[8,   331] loss: 0.427\n",
      "Epoch : 7, Accuracy : 0.8114874958992004\n",
      "[9,     1] loss: 0.112\n",
      "[9,     6] loss: 0.285\n",
      "[9,    11] loss: 0.293\n",
      "[9,    16] loss: 0.358\n",
      "[9,    21] loss: 0.227\n",
      "[9,    26] loss: 0.330\n",
      "[9,    31] loss: 0.169\n",
      "[9,    36] loss: 0.188\n",
      "[9,    41] loss: 0.237\n",
      "[9,    46] loss: 0.270\n",
      "[9,    51] loss: 0.240\n",
      "[9,    56] loss: 0.194\n",
      "[9,    61] loss: 0.201\n",
      "[9,    66] loss: 0.195\n",
      "[9,    71] loss: 0.463\n",
      "[9,    76] loss: 0.404\n",
      "[9,    81] loss: 0.335\n",
      "[9,    86] loss: 0.334\n",
      "[9,    91] loss: 0.377\n",
      "[9,    96] loss: 0.202\n",
      "[9,   101] loss: 0.509\n",
      "[9,   106] loss: 0.197\n",
      "[9,   111] loss: 0.379\n",
      "[9,   116] loss: 0.269\n",
      "[9,   121] loss: 0.231\n",
      "[9,   126] loss: 0.261\n",
      "[9,   131] loss: 0.424\n",
      "[9,   136] loss: 0.464\n",
      "[9,   141] loss: 0.489\n",
      "[9,   146] loss: 0.438\n",
      "[9,   151] loss: 0.303\n",
      "[9,   156] loss: 0.340\n",
      "[9,   161] loss: 0.317\n",
      "[9,   166] loss: 0.217\n",
      "[9,   171] loss: 0.344\n",
      "[9,   176] loss: 0.242\n",
      "[9,   181] loss: 0.353\n",
      "[9,   186] loss: 0.347\n",
      "[9,   191] loss: 0.286\n",
      "[9,   196] loss: 0.298\n",
      "[9,   201] loss: 0.325\n",
      "[9,   206] loss: 0.245\n",
      "[9,   211] loss: 0.257\n",
      "[9,   216] loss: 0.303\n",
      "[9,   221] loss: 0.193\n",
      "[9,   226] loss: 0.467\n",
      "[9,   231] loss: 0.349\n",
      "[9,   236] loss: 0.420\n",
      "[9,   241] loss: 0.297\n",
      "[9,   246] loss: 0.359\n",
      "[9,   251] loss: 0.331\n",
      "[9,   256] loss: 0.281\n",
      "[9,   261] loss: 0.388\n",
      "[9,   266] loss: 0.251\n",
      "[9,   271] loss: 0.325\n",
      "[9,   276] loss: 0.322\n",
      "[9,   281] loss: 0.161\n",
      "[9,   286] loss: 0.210\n",
      "[9,   291] loss: 0.409\n",
      "[9,   296] loss: 0.335\n",
      "[9,   301] loss: 0.663\n",
      "[9,   306] loss: 0.471\n",
      "[9,   311] loss: 0.518\n",
      "[9,   316] loss: 0.442\n",
      "[9,   321] loss: 0.260\n",
      "[9,   326] loss: 0.472\n",
      "[9,   331] loss: 0.289\n",
      "Epoch : 8, Accuracy : 0.8284241557121277\n",
      "[10,     1] loss: 0.111\n",
      "[10,     6] loss: 0.276\n",
      "[10,    11] loss: 0.142\n",
      "[10,    16] loss: 0.302\n",
      "[10,    21] loss: 0.128\n",
      "[10,    26] loss: 0.535\n",
      "[10,    31] loss: 0.234\n",
      "[10,    36] loss: 0.288\n",
      "[10,    41] loss: 0.379\n",
      "[10,    46] loss: 0.314\n",
      "[10,    51] loss: 0.389\n",
      "[10,    56] loss: 0.462\n",
      "[10,    61] loss: 0.304\n",
      "[10,    66] loss: 0.293\n",
      "[10,    71] loss: 0.232\n",
      "[10,    76] loss: 0.175\n",
      "[10,    81] loss: 0.342\n",
      "[10,    86] loss: 0.238\n",
      "[10,    91] loss: 0.277\n",
      "[10,    96] loss: 0.371\n",
      "[10,   101] loss: 0.394\n",
      "[10,   106] loss: 0.330\n",
      "[10,   111] loss: 0.285\n",
      "[10,   116] loss: 0.439\n",
      "[10,   121] loss: 0.355\n",
      "[10,   126] loss: 0.379\n",
      "[10,   131] loss: 0.283\n",
      "[10,   136] loss: 0.698\n",
      "[10,   141] loss: 0.272\n",
      "[10,   146] loss: 0.386\n",
      "[10,   151] loss: 0.263\n",
      "[10,   156] loss: 0.295\n",
      "[10,   161] loss: 0.280\n",
      "[10,   166] loss: 0.250\n",
      "[10,   171] loss: 0.244\n",
      "[10,   176] loss: 0.222\n",
      "[10,   181] loss: 0.276\n",
      "[10,   186] loss: 0.266\n",
      "[10,   191] loss: 0.248\n",
      "[10,   196] loss: 0.307\n",
      "[10,   201] loss: 0.256\n",
      "[10,   206] loss: 0.201\n",
      "[10,   211] loss: 0.440\n",
      "[10,   216] loss: 0.314\n",
      "[10,   221] loss: 0.354\n",
      "[10,   226] loss: 0.256\n",
      "[10,   231] loss: 0.271\n",
      "[10,   236] loss: 0.330\n",
      "[10,   241] loss: 0.371\n",
      "[10,   246] loss: 0.352\n",
      "[10,   251] loss: 0.209\n",
      "[10,   256] loss: 0.230\n",
      "[10,   261] loss: 0.307\n",
      "[10,   266] loss: 0.261\n",
      "[10,   271] loss: 0.368\n",
      "[10,   276] loss: 0.210\n",
      "[10,   281] loss: 0.329\n",
      "[10,   286] loss: 0.353\n",
      "[10,   291] loss: 0.303\n",
      "[10,   296] loss: 0.250\n",
      "[10,   301] loss: 0.355\n",
      "[10,   306] loss: 0.371\n",
      "[10,   311] loss: 0.334\n",
      "[10,   316] loss: 0.205\n",
      "[10,   321] loss: 0.229\n",
      "[10,   326] loss: 0.447\n",
      "[10,   331] loss: 0.220\n",
      "Epoch : 9, Accuracy : 0.8284241557121277\n",
      "[11,     1] loss: 0.053\n",
      "[11,     6] loss: 0.284\n",
      "[11,    11] loss: 0.309\n",
      "[11,    16] loss: 0.323\n",
      "[11,    21] loss: 0.325\n",
      "[11,    26] loss: 0.378\n",
      "[11,    31] loss: 0.266\n",
      "[11,    36] loss: 0.213\n",
      "[11,    41] loss: 0.175\n",
      "[11,    46] loss: 0.325\n",
      "[11,    51] loss: 0.204\n",
      "[11,    56] loss: 0.306\n",
      "[11,    61] loss: 0.250\n",
      "[11,    66] loss: 0.224\n",
      "[11,    71] loss: 0.230\n",
      "[11,    76] loss: 0.108\n",
      "[11,    81] loss: 0.104\n",
      "[11,    86] loss: 0.159\n",
      "[11,    91] loss: 0.155\n",
      "[11,    96] loss: 0.308\n",
      "[11,   101] loss: 0.385\n",
      "[11,   106] loss: 0.425\n",
      "[11,   111] loss: 0.310\n",
      "[11,   116] loss: 0.378\n",
      "[11,   121] loss: 0.230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11,   126] loss: 0.247\n",
      "[11,   131] loss: 0.224\n",
      "[11,   136] loss: 0.264\n",
      "[11,   141] loss: 0.225\n",
      "[11,   146] loss: 0.164\n",
      "[11,   151] loss: 0.417\n",
      "[11,   156] loss: 0.374\n",
      "[11,   161] loss: 0.295\n",
      "[11,   166] loss: 0.351\n",
      "[11,   171] loss: 0.265\n",
      "[11,   176] loss: 0.337\n",
      "[11,   181] loss: 0.249\n",
      "[11,   186] loss: 0.208\n",
      "[11,   191] loss: 0.430\n",
      "[11,   196] loss: 0.186\n",
      "[11,   201] loss: 0.260\n",
      "[11,   206] loss: 0.241\n",
      "[11,   211] loss: 0.273\n",
      "[11,   216] loss: 0.496\n",
      "[11,   221] loss: 0.189\n",
      "[11,   226] loss: 0.368\n",
      "[11,   231] loss: 0.279\n",
      "[11,   236] loss: 0.319\n",
      "[11,   241] loss: 0.270\n",
      "[11,   246] loss: 0.214\n",
      "[11,   251] loss: 0.254\n",
      "[11,   256] loss: 0.280\n",
      "[11,   261] loss: 0.296\n",
      "[11,   266] loss: 0.307\n",
      "[11,   271] loss: 0.237\n",
      "[11,   276] loss: 0.184\n",
      "[11,   281] loss: 0.198\n",
      "[11,   286] loss: 0.324\n",
      "[11,   291] loss: 0.369\n",
      "[11,   296] loss: 0.252\n",
      "[11,   301] loss: 0.349\n",
      "[11,   306] loss: 0.354\n",
      "[11,   311] loss: 0.282\n",
      "[11,   316] loss: 0.333\n",
      "[11,   321] loss: 0.271\n",
      "[11,   326] loss: 0.312\n",
      "[11,   331] loss: 0.280\n",
      "Epoch : 10, Accuracy : 0.8357879519462585\n",
      "[12,     1] loss: 0.025\n",
      "[12,     6] loss: 0.279\n",
      "[12,    11] loss: 0.250\n",
      "[12,    16] loss: 0.399\n",
      "[12,    21] loss: 0.381\n",
      "[12,    26] loss: 0.283\n",
      "[12,    31] loss: 0.187\n",
      "[12,    36] loss: 0.261\n",
      "[12,    41] loss: 0.165\n",
      "[12,    46] loss: 0.403\n",
      "[12,    51] loss: 0.388\n",
      "[12,    56] loss: 0.276\n",
      "[12,    61] loss: 0.274\n",
      "[12,    66] loss: 0.374\n",
      "[12,    71] loss: 0.195\n",
      "[12,    76] loss: 0.234\n",
      "[12,    81] loss: 0.251\n",
      "[12,    86] loss: 0.176\n",
      "[12,    91] loss: 0.263\n",
      "[12,    96] loss: 0.643\n",
      "[12,   101] loss: 0.338\n",
      "[12,   106] loss: 0.256\n",
      "[12,   111] loss: 0.312\n",
      "[12,   116] loss: 0.215\n",
      "[12,   121] loss: 0.328\n",
      "[12,   126] loss: 0.321\n",
      "[12,   131] loss: 0.126\n",
      "[12,   136] loss: 0.243\n",
      "[12,   141] loss: 0.168\n",
      "[12,   146] loss: 0.174\n",
      "[12,   151] loss: 0.138\n",
      "[12,   156] loss: 0.481\n",
      "[12,   161] loss: 0.427\n",
      "[12,   166] loss: 0.205\n",
      "[12,   171] loss: 0.303\n",
      "[12,   176] loss: 0.491\n",
      "[12,   181] loss: 0.328\n",
      "[12,   186] loss: 0.485\n",
      "[12,   191] loss: 0.371\n",
      "[12,   196] loss: 0.410\n",
      "[12,   201] loss: 0.301\n",
      "[12,   206] loss: 0.292\n",
      "[12,   211] loss: 0.143\n",
      "[12,   216] loss: 0.221\n",
      "[12,   221] loss: 0.252\n",
      "[12,   226] loss: 0.197\n",
      "[12,   231] loss: 0.387\n",
      "[12,   236] loss: 0.234\n",
      "[12,   241] loss: 0.326\n",
      "[12,   246] loss: 0.206\n",
      "[12,   251] loss: 0.204\n",
      "[12,   256] loss: 0.198\n",
      "[12,   261] loss: 0.145\n",
      "[12,   266] loss: 0.302\n",
      "[12,   271] loss: 0.354\n",
      "[12,   276] loss: 0.297\n",
      "[12,   281] loss: 0.268\n",
      "[12,   286] loss: 0.203\n",
      "[12,   291] loss: 0.362\n",
      "[12,   296] loss: 0.503\n",
      "[12,   301] loss: 0.330\n",
      "[12,   306] loss: 0.325\n",
      "[12,   311] loss: 0.274\n",
      "[12,   316] loss: 0.284\n",
      "[12,   321] loss: 0.287\n",
      "[12,   326] loss: 0.371\n",
      "[12,   331] loss: 0.250\n",
      "Epoch : 11, Accuracy : 0.8129602074623108\n",
      "[13,     1] loss: 0.023\n",
      "[13,     6] loss: 0.198\n",
      "[13,    11] loss: 0.262\n",
      "[13,    16] loss: 0.300\n",
      "[13,    21] loss: 0.223\n",
      "[13,    26] loss: 0.277\n",
      "[13,    31] loss: 0.221\n",
      "[13,    36] loss: 0.228\n",
      "[13,    41] loss: 0.123\n",
      "[13,    46] loss: 0.138\n",
      "[13,    51] loss: 0.346\n",
      "[13,    56] loss: 0.211\n",
      "[13,    61] loss: 0.266\n",
      "[13,    66] loss: 0.267\n",
      "[13,    71] loss: 0.237\n",
      "[13,    76] loss: 0.313\n",
      "[13,    81] loss: 0.316\n",
      "[13,    86] loss: 0.347\n",
      "[13,    91] loss: 0.211\n",
      "[13,    96] loss: 0.259\n",
      "[13,   101] loss: 0.184\n",
      "[13,   106] loss: 0.115\n",
      "[13,   111] loss: 0.337\n",
      "[13,   116] loss: 0.230\n",
      "[13,   121] loss: 0.221\n",
      "[13,   126] loss: 0.249\n",
      "[13,   131] loss: 0.207\n",
      "[13,   136] loss: 0.216\n",
      "[13,   141] loss: 0.236\n",
      "[13,   146] loss: 0.147\n",
      "[13,   151] loss: 0.185\n",
      "[13,   156] loss: 0.142\n",
      "[13,   161] loss: 0.293\n",
      "[13,   166] loss: 0.276\n",
      "[13,   171] loss: 0.369\n",
      "[13,   176] loss: 0.321\n",
      "[13,   181] loss: 0.385\n",
      "[13,   186] loss: 0.174\n",
      "[13,   191] loss: 0.296\n",
      "[13,   196] loss: 0.217\n",
      "[13,   201] loss: 0.249\n",
      "[13,   206] loss: 0.345\n",
      "[13,   211] loss: 0.235\n",
      "[13,   216] loss: 0.321\n",
      "[13,   221] loss: 0.111\n",
      "[13,   226] loss: 0.251\n",
      "[13,   231] loss: 0.221\n",
      "[13,   236] loss: 0.609\n",
      "[13,   241] loss: 0.215\n",
      "[13,   246] loss: 0.253\n",
      "[13,   251] loss: 0.125\n",
      "[13,   256] loss: 0.440\n",
      "[13,   261] loss: 0.323\n",
      "[13,   266] loss: 0.254\n",
      "[13,   271] loss: 0.245\n",
      "[13,   276] loss: 0.249\n",
      "[13,   281] loss: 0.170\n",
      "[13,   286] loss: 0.317\n",
      "[13,   291] loss: 0.197\n",
      "[13,   296] loss: 0.147\n",
      "[13,   301] loss: 0.134\n",
      "[13,   306] loss: 0.258\n",
      "[13,   311] loss: 0.279\n",
      "[13,   316] loss: 0.330\n",
      "[13,   321] loss: 0.310\n",
      "[13,   326] loss: 0.399\n",
      "[13,   331] loss: 0.169\n",
      "Epoch : 12, Accuracy : 0.8085419535636902\n",
      "[14,     1] loss: 0.067\n",
      "[14,     6] loss: 0.260\n",
      "[14,    11] loss: 0.350\n",
      "[14,    16] loss: 0.286\n",
      "[14,    21] loss: 0.198\n",
      "[14,    26] loss: 0.226\n",
      "[14,    31] loss: 0.182\n",
      "[14,    36] loss: 0.284\n",
      "[14,    41] loss: 0.168\n",
      "[14,    46] loss: 0.162\n",
      "[14,    51] loss: 0.328\n",
      "[14,    56] loss: 0.254\n",
      "[14,    61] loss: 0.359\n",
      "[14,    66] loss: 0.295\n",
      "[14,    71] loss: 0.233\n",
      "[14,    76] loss: 0.282\n",
      "[14,    81] loss: 0.269\n",
      "[14,    86] loss: 0.206\n",
      "[14,    91] loss: 0.140\n",
      "[14,    96] loss: 0.284\n",
      "[14,   101] loss: 0.161\n",
      "[14,   106] loss: 0.087\n",
      "[14,   111] loss: 0.439\n",
      "[14,   116] loss: 0.247\n",
      "[14,   121] loss: 0.447\n",
      "[14,   126] loss: 0.275\n",
      "[14,   131] loss: 0.215\n",
      "[14,   136] loss: 0.222\n",
      "[14,   141] loss: 0.303\n",
      "[14,   146] loss: 0.163\n",
      "[14,   151] loss: 0.274\n",
      "[14,   156] loss: 0.279\n",
      "[14,   161] loss: 0.332\n",
      "[14,   166] loss: 0.323\n",
      "[14,   171] loss: 0.624\n",
      "[14,   176] loss: 0.481\n",
      "[14,   181] loss: 0.334\n",
      "[14,   186] loss: 0.260\n",
      "[14,   191] loss: 0.342\n",
      "[14,   196] loss: 0.488\n",
      "[14,   201] loss: 0.119\n",
      "[14,   206] loss: 0.242\n",
      "[14,   211] loss: 0.194\n",
      "[14,   216] loss: 0.386\n",
      "[14,   221] loss: 0.409\n",
      "[14,   226] loss: 0.330\n",
      "[14,   231] loss: 0.339\n",
      "[14,   236] loss: 0.244\n",
      "[14,   241] loss: 0.344\n",
      "[14,   246] loss: 0.352\n",
      "[14,   251] loss: 0.353\n",
      "[14,   256] loss: 0.301\n",
      "[14,   261] loss: 0.275\n",
      "[14,   266] loss: 0.530\n",
      "[14,   271] loss: 0.278\n",
      "[14,   276] loss: 0.357\n",
      "[14,   281] loss: 0.211\n",
      "[14,   286] loss: 0.142\n",
      "[14,   291] loss: 0.278\n",
      "[14,   296] loss: 0.203\n",
      "[14,   301] loss: 0.165\n",
      "[14,   306] loss: 0.136\n",
      "[14,   311] loss: 0.158\n",
      "[14,   316] loss: 0.170\n",
      "[14,   321] loss: 0.237\n",
      "[14,   326] loss: 0.126\n",
      "[14,   331] loss: 0.368\n",
      "Epoch : 13, Accuracy : 0.7805596590042114\n",
      "[15,     1] loss: 0.057\n",
      "[15,     6] loss: 0.346\n",
      "[15,    11] loss: 0.183\n",
      "[15,    16] loss: 0.332\n",
      "[15,    21] loss: 0.095\n",
      "[15,    26] loss: 0.131\n",
      "[15,    31] loss: 0.143\n",
      "[15,    36] loss: 0.176\n",
      "[15,    41] loss: 0.218\n",
      "[15,    46] loss: 0.325\n",
      "[15,    51] loss: 0.159\n",
      "[15,    56] loss: 0.505\n",
      "[15,    61] loss: 0.265\n",
      "[15,    66] loss: 0.345\n",
      "[15,    71] loss: 0.335\n",
      "[15,    76] loss: 0.326\n",
      "[15,    81] loss: 0.255\n",
      "[15,    86] loss: 0.347\n",
      "[15,    91] loss: 0.189\n",
      "[15,    96] loss: 0.233\n",
      "[15,   101] loss: 0.178\n",
      "[15,   106] loss: 0.209\n",
      "[15,   111] loss: 0.367\n",
      "[15,   116] loss: 0.184\n",
      "[15,   121] loss: 0.149\n",
      "[15,   126] loss: 0.334\n",
      "[15,   131] loss: 0.249\n",
      "[15,   136] loss: 0.250\n",
      "[15,   141] loss: 0.113\n",
      "[15,   146] loss: 0.277\n",
      "[15,   151] loss: 0.335\n",
      "[15,   156] loss: 0.163\n",
      "[15,   161] loss: 0.259\n",
      "[15,   166] loss: 0.094\n",
      "[15,   171] loss: 0.155\n",
      "[15,   176] loss: 0.126\n",
      "[15,   181] loss: 0.235\n",
      "[15,   186] loss: 0.234\n",
      "[15,   191] loss: 0.344\n",
      "[15,   196] loss: 0.222\n",
      "[15,   201] loss: 0.292\n",
      "[15,   206] loss: 0.228\n",
      "[15,   211] loss: 0.256\n",
      "[15,   216] loss: 0.159\n",
      "[15,   221] loss: 0.183\n",
      "[15,   226] loss: 0.280\n",
      "[15,   231] loss: 0.225\n",
      "[15,   236] loss: 0.175\n",
      "[15,   241] loss: 0.249\n",
      "[15,   246] loss: 0.219\n",
      "[15,   251] loss: 0.346\n",
      "[15,   256] loss: 0.180\n",
      "[15,   261] loss: 0.257\n",
      "[15,   266] loss: 0.157\n",
      "[15,   271] loss: 0.367\n",
      "[15,   276] loss: 0.447\n",
      "[15,   281] loss: 0.226\n",
      "[15,   286] loss: 0.314\n",
      "[15,   291] loss: 0.255\n",
      "[15,   296] loss: 0.236\n",
      "[15,   301] loss: 0.307\n",
      "[15,   306] loss: 0.160\n",
      "[15,   311] loss: 0.233\n",
      "[15,   316] loss: 0.189\n",
      "[15,   321] loss: 0.177\n",
      "[15,   326] loss: 0.492\n",
      "[15,   331] loss: 0.219\n",
      "Epoch : 14, Accuracy : 0.8107510805130005\n",
      "[16,     1] loss: 0.059\n",
      "[16,     6] loss: 0.275\n",
      "[16,    11] loss: 0.207\n",
      "[16,    16] loss: 0.138\n",
      "[16,    21] loss: 0.219\n",
      "[16,    26] loss: 0.187\n",
      "[16,    31] loss: 0.134\n",
      "[16,    36] loss: 0.110\n",
      "[16,    41] loss: 0.083\n",
      "[16,    46] loss: 0.074\n",
      "[16,    51] loss: 0.201\n",
      "[16,    56] loss: 0.154\n",
      "[16,    61] loss: 0.199\n",
      "[16,    66] loss: 0.183\n",
      "[16,    71] loss: 0.148\n",
      "[16,    76] loss: 0.144\n",
      "[16,    81] loss: 0.246\n",
      "[16,    86] loss: 0.154\n",
      "[16,    91] loss: 0.129\n",
      "[16,    96] loss: 0.214\n",
      "[16,   101] loss: 0.306\n",
      "[16,   106] loss: 0.112\n",
      "[16,   111] loss: 0.248\n",
      "[16,   116] loss: 0.200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16,   121] loss: 0.539\n",
      "[16,   126] loss: 0.248\n",
      "[16,   131] loss: 0.331\n",
      "[16,   136] loss: 0.191\n",
      "[16,   141] loss: 0.330\n",
      "[16,   146] loss: 0.288\n",
      "[16,   151] loss: 0.219\n",
      "[16,   156] loss: 0.205\n",
      "[16,   161] loss: 0.261\n",
      "[16,   166] loss: 0.336\n",
      "[16,   171] loss: 0.340\n",
      "[16,   176] loss: 0.304\n",
      "[16,   181] loss: 0.254\n",
      "[16,   186] loss: 0.291\n",
      "[16,   191] loss: 0.198\n",
      "[16,   196] loss: 0.307\n",
      "[16,   201] loss: 0.253\n",
      "[16,   206] loss: 0.273\n",
      "[16,   211] loss: 0.205\n",
      "[16,   216] loss: 0.441\n",
      "[16,   221] loss: 0.332\n",
      "[16,   226] loss: 0.253\n",
      "[16,   231] loss: 0.157\n",
      "[16,   236] loss: 0.140\n",
      "[16,   241] loss: 0.199\n",
      "[16,   246] loss: 0.128\n",
      "[16,   251] loss: 0.087\n",
      "[16,   256] loss: 0.289\n",
      "[16,   261] loss: 0.314\n",
      "[16,   266] loss: 0.311\n",
      "[16,   271] loss: 0.252\n",
      "[16,   276] loss: 0.318\n",
      "[16,   281] loss: 0.144\n",
      "[16,   286] loss: 0.223\n",
      "[16,   291] loss: 0.243\n",
      "[16,   296] loss: 0.231\n",
      "[16,   301] loss: 0.344\n",
      "[16,   306] loss: 0.103\n",
      "[16,   311] loss: 0.362\n",
      "[16,   316] loss: 0.161\n",
      "[16,   321] loss: 0.289\n",
      "[16,   326] loss: 0.173\n",
      "[16,   331] loss: 0.285\n",
      "Epoch : 15, Accuracy : 0.8217967748641968\n",
      "[17,     1] loss: 0.003\n",
      "[17,     6] loss: 0.131\n",
      "[17,    11] loss: 0.198\n",
      "[17,    16] loss: 0.212\n",
      "[17,    21] loss: 0.299\n",
      "[17,    26] loss: 0.136\n",
      "[17,    31] loss: 0.312\n",
      "[17,    36] loss: 0.256\n",
      "[17,    41] loss: 0.321\n",
      "[17,    46] loss: 0.224\n",
      "[17,    51] loss: 0.349\n",
      "[17,    56] loss: 0.190\n",
      "[17,    61] loss: 0.150\n",
      "[17,    66] loss: 0.082\n",
      "[17,    71] loss: 0.154\n",
      "[17,    76] loss: 0.119\n",
      "[17,    81] loss: 0.177\n",
      "[17,    86] loss: 0.134\n",
      "[17,    91] loss: 0.083\n",
      "[17,    96] loss: 0.137\n",
      "[17,   101] loss: 0.236\n",
      "[17,   106] loss: 0.147\n",
      "[17,   111] loss: 0.063\n",
      "[17,   116] loss: 0.158\n",
      "[17,   121] loss: 0.110\n",
      "[17,   126] loss: 0.268\n",
      "[17,   131] loss: 0.199\n",
      "[17,   136] loss: 0.312\n",
      "[17,   141] loss: 0.088\n",
      "[17,   146] loss: 0.305\n",
      "[17,   151] loss: 0.162\n",
      "[17,   156] loss: 0.161\n",
      "[17,   161] loss: 0.234\n",
      "[17,   166] loss: 0.182\n",
      "[17,   171] loss: 0.068\n",
      "[17,   176] loss: 0.080\n",
      "[17,   181] loss: 0.188\n",
      "[17,   186] loss: 0.068\n",
      "[17,   191] loss: 0.133\n",
      "[17,   196] loss: 0.037\n",
      "[17,   201] loss: 0.283\n",
      "[17,   206] loss: 0.128\n",
      "[17,   211] loss: 0.223\n",
      "[17,   216] loss: 0.227\n",
      "[17,   221] loss: 0.101\n",
      "[17,   226] loss: 0.098\n",
      "[17,   231] loss: 0.331\n",
      "[17,   236] loss: 0.371\n",
      "[17,   241] loss: 0.171\n",
      "[17,   246] loss: 0.316\n",
      "[17,   251] loss: 0.253\n",
      "[17,   256] loss: 0.222\n",
      "[17,   261] loss: 0.436\n",
      "[17,   266] loss: 0.339\n",
      "[17,   271] loss: 0.400\n",
      "[17,   276] loss: 0.165\n",
      "[17,   281] loss: 0.226\n",
      "[17,   286] loss: 0.200\n",
      "[17,   291] loss: 0.159\n",
      "[17,   296] loss: 0.235\n",
      "[17,   301] loss: 0.203\n",
      "[17,   306] loss: 0.239\n",
      "[17,   311] loss: 0.303\n",
      "[17,   316] loss: 0.219\n",
      "[17,   321] loss: 0.206\n",
      "[17,   326] loss: 0.155\n",
      "[17,   331] loss: 0.111\n",
      "Epoch : 16, Accuracy : 0.822533130645752\n",
      "[18,     1] loss: 0.051\n",
      "[18,     6] loss: 0.117\n",
      "[18,    11] loss: 0.102\n",
      "[18,    16] loss: 0.247\n",
      "[18,    21] loss: 0.263\n",
      "[18,    26] loss: 0.161\n",
      "[18,    31] loss: 0.213\n",
      "[18,    36] loss: 0.222\n",
      "[18,    41] loss: 0.143\n",
      "[18,    46] loss: 0.135\n",
      "[18,    51] loss: 0.180\n",
      "[18,    56] loss: 0.207\n",
      "[18,    61] loss: 0.726\n",
      "[18,    66] loss: 0.195\n",
      "[18,    71] loss: 0.207\n",
      "[18,    76] loss: 0.192\n",
      "[18,    81] loss: 0.221\n",
      "[18,    86] loss: 0.348\n",
      "[18,    91] loss: 0.132\n",
      "[18,    96] loss: 0.128\n",
      "[18,   101] loss: 0.124\n",
      "[18,   106] loss: 0.174\n",
      "[18,   111] loss: 0.181\n",
      "[18,   116] loss: 0.121\n",
      "[18,   121] loss: 0.077\n",
      "[18,   126] loss: 0.136\n",
      "[18,   131] loss: 0.187\n",
      "[18,   136] loss: 0.306\n",
      "[18,   141] loss: 0.072\n",
      "[18,   146] loss: 0.273\n",
      "[18,   151] loss: 0.159\n",
      "[18,   156] loss: 0.104\n",
      "[18,   161] loss: 0.118\n",
      "[18,   166] loss: 0.277\n",
      "[18,   171] loss: 0.103\n",
      "[18,   176] loss: 0.174\n",
      "[18,   181] loss: 0.085\n",
      "[18,   186] loss: 0.122\n",
      "[18,   191] loss: 0.304\n",
      "[18,   196] loss: 0.149\n",
      "[18,   201] loss: 0.105\n",
      "[18,   206] loss: 0.106\n",
      "[18,   211] loss: 0.102\n",
      "[18,   216] loss: 0.291\n",
      "[18,   221] loss: 0.174\n",
      "[18,   226] loss: 0.166\n",
      "[18,   231] loss: 0.196\n",
      "[18,   236] loss: 0.171\n",
      "[18,   241] loss: 0.175\n",
      "[18,   246] loss: 0.154\n",
      "[18,   251] loss: 0.102\n",
      "[18,   256] loss: 0.139\n",
      "[18,   261] loss: 0.228\n",
      "[18,   266] loss: 0.148\n",
      "[18,   271] loss: 0.143\n",
      "[18,   276] loss: 0.159\n",
      "[18,   281] loss: 0.111\n",
      "[18,   286] loss: 0.130\n",
      "[18,   291] loss: 0.302\n",
      "[18,   296] loss: 0.196\n",
      "[18,   301] loss: 0.367\n",
      "[18,   306] loss: 0.205\n",
      "[18,   311] loss: 0.226\n",
      "[18,   316] loss: 0.144\n",
      "[18,   321] loss: 0.134\n",
      "[18,   326] loss: 0.174\n",
      "[18,   331] loss: 0.293\n",
      "Epoch : 17, Accuracy : 0.8114874958992004\n",
      "[19,     1] loss: 0.102\n",
      "[19,     6] loss: 0.132\n",
      "[19,    11] loss: 0.145\n",
      "[19,    16] loss: 0.075\n",
      "[19,    21] loss: 0.099\n",
      "[19,    26] loss: 0.094\n",
      "[19,    31] loss: 0.106\n",
      "[19,    36] loss: 0.081\n",
      "[19,    41] loss: 0.209\n",
      "[19,    46] loss: 0.061\n",
      "[19,    51] loss: 0.125\n",
      "[19,    56] loss: 0.266\n",
      "[19,    61] loss: 0.153\n",
      "[19,    66] loss: 0.382\n",
      "[19,    71] loss: 0.244\n",
      "[19,    76] loss: 0.208\n",
      "[19,    81] loss: 0.382\n",
      "[19,    86] loss: 0.329\n",
      "[19,    91] loss: 0.099\n",
      "[19,    96] loss: 0.133\n",
      "[19,   101] loss: 0.200\n",
      "[19,   106] loss: 0.125\n",
      "[19,   111] loss: 0.118\n",
      "[19,   116] loss: 0.297\n",
      "[19,   121] loss: 0.166\n",
      "[19,   126] loss: 0.215\n",
      "[19,   131] loss: 0.162\n",
      "[19,   136] loss: 0.167\n",
      "[19,   141] loss: 0.114\n",
      "[19,   146] loss: 0.290\n",
      "[19,   151] loss: 0.166\n",
      "[19,   156] loss: 0.293\n",
      "[19,   161] loss: 0.129\n",
      "[19,   166] loss: 0.130\n",
      "[19,   171] loss: 0.495\n",
      "[19,   176] loss: 0.252\n",
      "[19,   181] loss: 0.187\n",
      "[19,   186] loss: 0.205\n",
      "[19,   191] loss: 0.225\n",
      "[19,   196] loss: 0.203\n",
      "[19,   201] loss: 0.523\n",
      "[19,   206] loss: 0.206\n",
      "[19,   211] loss: 0.378\n",
      "[19,   216] loss: 0.210\n",
      "[19,   221] loss: 0.336\n",
      "[19,   226] loss: 0.409\n",
      "[19,   231] loss: 0.188\n",
      "[19,   236] loss: 0.092\n",
      "[19,   241] loss: 0.162\n",
      "[19,   246] loss: 0.194\n",
      "[19,   251] loss: 0.183\n",
      "[19,   256] loss: 0.228\n",
      "[19,   261] loss: 0.325\n",
      "[19,   266] loss: 0.391\n",
      "[19,   271] loss: 0.300\n",
      "[19,   276] loss: 0.266\n",
      "[19,   281] loss: 0.209\n",
      "[19,   286] loss: 0.299\n",
      "[19,   291] loss: 0.125\n",
      "[19,   296] loss: 0.142\n",
      "[19,   301] loss: 0.025\n",
      "[19,   306] loss: 0.468\n",
      "[19,   311] loss: 0.167\n",
      "[19,   316] loss: 0.237\n",
      "[19,   321] loss: 0.240\n",
      "[19,   326] loss: 0.148\n",
      "[19,   331] loss: 0.196\n",
      "Epoch : 18, Accuracy : 0.8203240036964417\n",
      "[20,     1] loss: 0.004\n",
      "[20,     6] loss: 0.325\n",
      "[20,    11] loss: 0.168\n",
      "[20,    16] loss: 0.384\n",
      "[20,    21] loss: 0.119\n",
      "[20,    26] loss: 0.181\n",
      "[20,    31] loss: 0.122\n",
      "[20,    36] loss: 0.132\n",
      "[20,    41] loss: 0.226\n",
      "[20,    46] loss: 0.107\n",
      "[20,    51] loss: 0.325\n",
      "[20,    56] loss: 0.181\n",
      "[20,    61] loss: 0.221\n",
      "[20,    66] loss: 0.123\n",
      "[20,    71] loss: 0.193\n",
      "[20,    76] loss: 0.548\n",
      "[20,    81] loss: 0.230\n",
      "[20,    86] loss: 0.461\n",
      "[20,    91] loss: 0.163\n",
      "[20,    96] loss: 0.404\n",
      "[20,   101] loss: 0.248\n",
      "[20,   106] loss: 0.325\n",
      "[20,   111] loss: 0.155\n",
      "[20,   116] loss: 0.289\n",
      "[20,   121] loss: 0.151\n",
      "[20,   126] loss: 0.198\n",
      "[20,   131] loss: 0.043\n",
      "[20,   136] loss: 0.128\n",
      "[20,   141] loss: 0.088\n",
      "[20,   146] loss: 0.063\n",
      "[20,   151] loss: 0.166\n",
      "[20,   156] loss: 0.159\n",
      "[20,   161] loss: 0.325\n",
      "[20,   166] loss: 0.240\n",
      "[20,   171] loss: 0.129\n",
      "[20,   176] loss: 0.220\n",
      "[20,   181] loss: 0.051\n",
      "[20,   186] loss: 0.201\n",
      "[20,   191] loss: 0.068\n",
      "[20,   196] loss: 0.130\n",
      "[20,   201] loss: 0.082\n",
      "[20,   206] loss: 0.110\n",
      "[20,   211] loss: 0.104\n",
      "[20,   216] loss: 0.144\n",
      "[20,   221] loss: 0.228\n",
      "[20,   226] loss: 0.184\n",
      "[20,   231] loss: 0.103\n",
      "[20,   236] loss: 0.230\n",
      "[20,   241] loss: 0.183\n",
      "[20,   246] loss: 0.242\n",
      "[20,   251] loss: 0.313\n",
      "[20,   256] loss: 0.347\n",
      "[20,   261] loss: 0.151\n",
      "[20,   266] loss: 0.219\n",
      "[20,   271] loss: 0.255\n",
      "[20,   276] loss: 0.184\n",
      "[20,   281] loss: 0.187\n",
      "[20,   286] loss: 0.235\n",
      "[20,   291] loss: 0.267\n",
      "[20,   296] loss: 0.124\n",
      "[20,   301] loss: 0.193\n",
      "[20,   306] loss: 0.191\n",
      "[20,   311] loss: 0.145\n",
      "[20,   316] loss: 0.170\n",
      "[20,   321] loss: 0.120\n",
      "[20,   326] loss: 0.172\n",
      "[20,   331] loss: 0.184\n",
      "Epoch : 19, Accuracy : 0.8100147247314453\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dataloader or dataset faulty(returns batches of 0\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    net.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data['ms'].to(device),data['label'].to(device)\n",
    "\n",
    "        #print(inputs.size())\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 0:    # print every 2000 mini-batches\n",
    "            \n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 5,\n",
    "                            epoch * len(trainloader) + i)\n",
    "            \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 5))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # calculate accuracy\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        res = torch.zeros((3,3))\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data['ms'].to(device),data['label'].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "            \n",
    "            for p,gt in zip(preds,labels):\n",
    "                res[int(p),int(gt)] += 1\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        N_total = res.sum()\n",
    "        N_correct = res.diag().sum()\n",
    "        \n",
    "        acc = N_correct / N_total\n",
    "        \n",
    "        writer.add_scalar('training acc',\n",
    "                    acc,\n",
    "                    epoch)\n",
    "        print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# densenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/dense_net_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = torchvision.models.densenet161(pretrained=True)\n",
    "densenet.features.conv0 = nn.Conv2d(1, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "densenet.classifier = nn.Linear(in_features=densenet.classifier.in_features, out_features=3,bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(densenet.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(1, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(816, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(912, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(912, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1008, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer25): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer26): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer27): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer28): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer29): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer30): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer31): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer32): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer33): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer34): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer35): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer36): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(2112, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2112, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2160, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(2208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=2208, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densenet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.056\n",
      "[1,    21] loss: 1.071\n",
      "[1,    41] loss: 1.061\n",
      "[1,    61] loss: 0.876\n",
      "[1,    81] loss: 0.719\n",
      "[1,   101] loss: 0.764\n",
      "[1,   121] loss: 0.612\n",
      "[1,   141] loss: 0.657\n",
      "[1,   161] loss: 0.678\n",
      "[1,   181] loss: 0.661\n",
      "[1,   201] loss: 0.692\n",
      "[1,   221] loss: 0.723\n",
      "[1,   241] loss: 0.565\n",
      "[1,   261] loss: 0.610\n",
      "[1,   281] loss: 0.634\n",
      "[1,   301] loss: 0.558\n",
      "[1,   321] loss: 0.606\n",
      "Epoch : 0, Accuracy : 0.7746686339378357\n",
      "[2,     1] loss: 0.042\n",
      "[2,    21] loss: 0.516\n",
      "[2,    41] loss: 0.435\n",
      "[2,    61] loss: 0.419\n",
      "[2,    81] loss: 0.422\n",
      "[2,   101] loss: 0.451\n",
      "[2,   121] loss: 0.411\n",
      "[2,   141] loss: 0.472\n",
      "[2,   161] loss: 0.423\n",
      "[2,   181] loss: 0.495\n",
      "[2,   201] loss: 0.464\n",
      "[2,   221] loss: 0.378\n",
      "[2,   241] loss: 0.518\n",
      "[2,   261] loss: 0.466\n",
      "[2,   281] loss: 0.411\n",
      "[2,   301] loss: 0.356\n",
      "[2,   321] loss: 0.518\n",
      "Epoch : 1, Accuracy : 0.8107510805130005\n",
      "[3,     1] loss: 0.013\n",
      "[3,    21] loss: 0.321\n",
      "[3,    41] loss: 0.358\n",
      "[3,    61] loss: 0.298\n",
      "[3,    81] loss: 0.371\n",
      "[3,   101] loss: 0.300\n",
      "[3,   121] loss: 0.286\n",
      "[3,   141] loss: 0.334\n",
      "[3,   161] loss: 0.355\n",
      "[3,   181] loss: 0.375\n",
      "[3,   201] loss: 0.421\n",
      "[3,   221] loss: 0.327\n",
      "[3,   241] loss: 0.371\n",
      "[3,   261] loss: 0.338\n",
      "[3,   281] loss: 0.469\n",
      "[3,   301] loss: 0.272\n",
      "[3,   321] loss: 0.366\n",
      "Epoch : 2, Accuracy : 0.861561119556427\n",
      "[4,     1] loss: 0.003\n",
      "[4,    21] loss: 0.225\n",
      "[4,    41] loss: 0.234\n",
      "[4,    61] loss: 0.237\n",
      "[4,    81] loss: 0.186\n",
      "[4,   101] loss: 0.229\n",
      "[4,   121] loss: 0.161\n",
      "[4,   141] loss: 0.251\n",
      "[4,   161] loss: 0.198\n",
      "[4,   181] loss: 0.221\n",
      "[4,   201] loss: 0.216\n",
      "[4,   221] loss: 0.229\n",
      "[4,   241] loss: 0.321\n",
      "[4,   261] loss: 0.170\n",
      "[4,   281] loss: 0.204\n",
      "[4,   301] loss: 0.192\n",
      "[4,   321] loss: 0.212\n",
      "Epoch : 3, Accuracy : 0.8497790694236755\n",
      "[5,     1] loss: 0.021\n",
      "[5,    21] loss: 0.155\n",
      "[5,    41] loss: 0.169\n",
      "[5,    61] loss: 0.144\n",
      "[5,    81] loss: 0.181\n",
      "[5,   101] loss: 0.144\n",
      "[5,   121] loss: 0.141\n",
      "[5,   141] loss: 0.214\n",
      "[5,   161] loss: 0.272\n",
      "[5,   181] loss: 0.184\n",
      "[5,   201] loss: 0.207\n",
      "[5,   221] loss: 0.240\n",
      "[5,   241] loss: 0.147\n",
      "[5,   261] loss: 0.124\n",
      "[5,   281] loss: 0.214\n",
      "[5,   301] loss: 0.148\n",
      "[5,   321] loss: 0.175\n",
      "Epoch : 4, Accuracy : 0.8372606635093689\n",
      "[6,     1] loss: 0.004\n",
      "[6,    21] loss: 0.085\n",
      "[6,    41] loss: 0.095\n",
      "[6,    61] loss: 0.131\n",
      "[6,    81] loss: 0.086\n",
      "[6,   101] loss: 0.082\n",
      "[6,   121] loss: 0.094\n",
      "[6,   141] loss: 0.062\n",
      "[6,   161] loss: 0.055\n",
      "[6,   181] loss: 0.099\n",
      "[6,   201] loss: 0.165\n",
      "[6,   221] loss: 0.122\n",
      "[6,   241] loss: 0.112\n",
      "[6,   261] loss: 0.078\n",
      "[6,   281] loss: 0.083\n",
      "[6,   301] loss: 0.124\n",
      "[6,   321] loss: 0.106\n",
      "Epoch : 5, Accuracy : 0.8468335866928101\n",
      "[7,     1] loss: 0.001\n",
      "[7,    21] loss: 0.041\n",
      "[7,    41] loss: 0.079\n",
      "[7,    61] loss: 0.086\n",
      "[7,    81] loss: 0.084\n",
      "[7,   101] loss: 0.147\n",
      "[7,   121] loss: 0.117\n",
      "[7,   141] loss: 0.115\n",
      "[7,   161] loss: 0.120\n",
      "[7,   181] loss: 0.083\n",
      "[7,   201] loss: 0.124\n",
      "[7,   221] loss: 0.067\n",
      "[7,   241] loss: 0.093\n",
      "[7,   261] loss: 0.201\n",
      "[7,   281] loss: 0.200\n",
      "[7,   301] loss: 0.150\n",
      "[7,   321] loss: 0.122\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-545ee59c497a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mdensenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ms'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Dataloader or dataset faulty(returns batches of 0\n",
    "epochs = 15\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    densenet.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data['ms'].to(device),data['label'].to(device)\n",
    "\n",
    "        #print(inputs.size())\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = densenet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 0:    # print every 2000 mini-batches\n",
    "            \n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 20,\n",
    "                            epoch * len(trainloader) + i)\n",
    "            \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 20))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # calculate accuracy\n",
    "    with torch.no_grad():\n",
    "        densenet.eval()\n",
    "        res = torch.zeros((3,3))\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data['ms'].to(device),data['label'].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = densenet(inputs)\n",
    "            \n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "            \n",
    "            for p,gt in zip(preds,labels):\n",
    "                res[int(p),int(gt)] += 1\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        N_total = res.sum()\n",
    "        N_correct = res.diag().sum()\n",
    "        \n",
    "        acc = N_correct / N_total\n",
    "        \n",
    "        writer.add_scalar('training acc',\n",
    "                    acc,\n",
    "                    epoch)\n",
    "        print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "        densenet.train()\n",
    "        res = torch.zeros((3,3))\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data['ms'].to(device),data['label'].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = densenet(inputs)\n",
    "            \n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "            print(outputs)\n",
    "            for p,gt in zip(preds,labels):\n",
    "                res[int(p),int(gt)] += 1\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        N_total = res.sum()\n",
    "        N_correct = res.diag().sum()\n",
    "        \n",
    "        acc = N_correct / N_total\n",
    "        \n",
    "        writer.add_scalar('training acc',\n",
    "                    acc,\n",
    "                    epoch)\n",
    "        print(f\"Epoch : {epoch}, Accuracy : {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.diag().sum() / res.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save validation list for dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = soccernet_ms_npy_DS(root_dir=root_dir,npy_file=train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file=root_dir+\"valid_samples.npy\",arr=samples,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.load(root_dir+\"valid_samples.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save test list for dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = SoccerNetDataset(root_dir=root_dir,npy_file=test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = list()\n",
    "for e in X:\n",
    "    samples.append(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file=root_dir+\"test_samples.npy\",arr=samples,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.load(root_dir+\"test_samples.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.pool = nn.MaxPool2d(4, 4)\n",
    "        self.fc1 = nn.Linear(2208, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = x.view(-1, 2208)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Note: Can also see warning once\n",
    "# warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/mel_spec_experiment_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(labels == torch.argmax(outputs, dim=1)).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/mel_spec_experiment_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device)\n",
    "# Dataloader or dataset faulty(returns batches of 0\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    net.train()\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data['mel_spectogram'].to(device),data['label'].to(device)\n",
    "\n",
    "        #print(inputs.size())\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 0:    # print every 2000 mini-batches\n",
    "            \n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 5,\n",
    "                            epoch * len(dataloader) + i)\n",
    "            \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 5))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # calculate accuracy\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        res = torch.zeros((3,3))\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data['mel_spectogram'].to(device),data['label'].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "            \n",
    "            for p,gt in zip(preds,labels):\n",
    "                res[int(p),int(gt)] += 1\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        N_total = res.sum()\n",
    "        N_correct = res.diag().sum()\n",
    "        \n",
    "        acc = N_total / N_correct\n",
    "        \n",
    "        writer.add_scalar('training acc',\n",
    "                    acc,\n",
    "                    epoch)\n",
    "        print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate samples to look for cases where y, sr from librosa is inconsistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.fc1.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device)\n",
    "\n",
    "running_loss = 0.0\n",
    "for i, data in enumerate(dataloader, 0):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data['mel_spectogram'].unsqueeze(0).to(device),torch.argmax(data['one_hot_label']).to(device)\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    running_loss += loss.item()\n",
    "    if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "        print('[%d, %5d] loss: %.3f' %\n",
    "              (epoch + 1, i + 1, running_loss / 2000))\n",
    "        running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
