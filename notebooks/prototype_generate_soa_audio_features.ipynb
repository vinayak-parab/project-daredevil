{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchaudio\n",
    "import time\n",
    "# to fix relative import problem\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import src.datasets.soccernet_ms_extracted as dataset\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir   = \"/work/oarongve/data/sound_dataset/SoccerNet-code/data/\"\n",
    "train_file = root_dir+\"listgame_Train_300.npy\"\n",
    "valid_file = root_dir+\"listgame_Valid_100.npy\"\n",
    "test_file  = root_dir+\"listgame_Test_100.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 10 14:10:12 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.165.02   Driver Version: 418.165.02   CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM3...  On   | 00000000:E7:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    50W / 350W |      0MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Test loading of some samples from train_samples.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Note: Can also see warning once\n",
    "# warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 12,\n",
    "         'shuffle': True,\n",
    "         'num_workers':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(X_train_npy,**params)\n",
    "testloader = DataLoader(X_test_npy,**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gameTime': '1 - 13:10', 'label': 'soccer-ball', 'team': 'home', 'duration1': 'Duration: 00:45:00.00', 'duration2': 'Duration: 00:45:00.00'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'path': '/work/oarongve/data/sound_dataset/SoccerNet-code/data/england_epl/2014-2015/2015-02-21 - 18-00 Chelsea 1 - 1 Burnley/0_ms.npy',\n",
       " 'ms': array([[[ 0.3697104 , -1.9689162 , -4.3114905 , ..., -4.1874843 ,\n",
       "          -4.4186516 , -4.0682044 ],\n",
       "         [ 0.39576104, -1.942303  , -4.1987357 , ..., -4.090648  ,\n",
       "          -4.33303   , -4.065091  ],\n",
       "         [ 0.6711389 , -1.66066   , -3.4416826 , ..., -3.385782  ,\n",
       "          -3.6704643 , -4.1973424 ],\n",
       "         ...,\n",
       "         [-0.8570114 , -0.695406  ,  0.23381191, ..., -2.7876408 ,\n",
       "          -2.9752624 , -4.062506  ],\n",
       "         [-1.6340435 , -0.92085844, -0.90301675, ..., -3.304437  ,\n",
       "          -3.8753335 , -4.149126  ],\n",
       "         [-1.1152141 , -2.0846589 , -1.8565004 , ..., -4.2993913 ,\n",
       "          -5.5238667 , -4.6549234 ]]], dtype=float32),\n",
       " 'idx': 0,\n",
       " 'label': 2,\n",
       " 'info': {'gameTime': '1 - 13:10',\n",
       "  'label': 'soccer-ball',\n",
       "  'team': 'home',\n",
       "  'duration1': 'Duration: 00:45:00.00',\n",
       "  'duration2': 'Duration: 00:45:00.00'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_npy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = list()\n",
    "mean = list()\n",
    "\n",
    "for e in X_train_npy:\n",
    "    print(e['ms'].mean())\n",
    "    mean.append(e['ms'].mean())\n",
    "    std.append(e['ms'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for s in range(len(X_train_npy)):\n",
    "    if np.isnan(X_train_npy[s]['ms']).any():\n",
    "        print(\"found one!\")\n",
    "        print(X_train_npy[s]['idx'])\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_npy[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(np.array(mean).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(np.array(mean)[0:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(np.array(mean)[2220:2230]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(mean)[2220:2230]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.pool = nn.MaxPool2d(4, 4)\n",
    "        self.fc1 = nn.Linear(2208, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = x.view(-1, 2208)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/simple_net3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.025, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataloader or dataset faulty(returns batches of 0\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    net.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data['ms'].to(device),data['label'].to(device)\n",
    "\n",
    "        #print(inputs.size())\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 0:    # print every 2000 mini-batches\n",
    "            \n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 5,\n",
    "                            epoch * len(trainloader) + i)\n",
    "            \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 5))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # calculate accuracy\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        res = torch.zeros((3,3))\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data['ms'].to(device),data['label'].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "            \n",
    "            for p,gt in zip(preds,labels):\n",
    "                res[int(p),int(gt)] += 1\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        N_total = res.sum()\n",
    "        N_correct = res.diag().sum()\n",
    "        \n",
    "        acc = N_correct / N_total\n",
    "        \n",
    "        writer.add_scalar('training acc',\n",
    "                    acc,\n",
    "                    epoch)\n",
    "        print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# densenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/dense_net_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-66183815dc89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdensenet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdensenet161\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdensenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdensenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdensenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "densenet = torchvision.models.densenet161(pretrained=True)\n",
    "densenet.features.conv0 = nn.Conv2d(1, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "densenet.classifier = nn.Linear(in_features=densenet.classifier.in_features, out_features=3,bias=True)\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(densenet.parameters(), lr=0.001, momentum=0.9)\n",
    "densenet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(densenet.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataloader or dataset faulty(returns batches of 0\n",
    "epochs = 15\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    densenet.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data['ms'].to(device),data['label'].to(device)\n",
    "\n",
    "        #print(inputs.size())\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = densenet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 0:    # print every 2000 mini-batches\n",
    "            \n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 20,\n",
    "                            epoch * len(trainloader) + i)\n",
    "            \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 20))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # calculate accuracy\n",
    "    with torch.no_grad():\n",
    "        densenet.eval()\n",
    "        res = torch.zeros((3,3))\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data['ms'].to(device),data['label'].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = densenet(inputs)\n",
    "            \n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "            \n",
    "            for p,gt in zip(preds,labels):\n",
    "                res[int(p),int(gt)] += 1\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        N_total = res.sum()\n",
    "        N_correct = res.diag().sum()\n",
    "        \n",
    "        acc = N_correct / N_total\n",
    "        \n",
    "        writer.add_scalar('training acc',\n",
    "                    acc,\n",
    "                    epoch)\n",
    "        print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "        densenet.train()\n",
    "        res = torch.zeros((3,3))\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data['ms'].to(device),data['label'].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = densenet(inputs)\n",
    "            \n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "            print(outputs)\n",
    "            for p,gt in zip(preds,labels):\n",
    "                res[int(p),int(gt)] += 1\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        N_total = res.sum()\n",
    "        N_correct = res.diag().sum()\n",
    "        \n",
    "        acc = N_correct / N_total\n",
    "        \n",
    "        writer.add_scalar('training acc',\n",
    "                    acc,\n",
    "                    epoch)\n",
    "        print(f\"Epoch : {epoch}, Accuracy : {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.diag().sum() / res.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save validation list for dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = soccernet_ms_npy_DS(root_dir=root_dir,npy_file=train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file=root_dir+\"valid_samples.npy\",arr=samples,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.load(root_dir+\"valid_samples.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save test list for dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = SoccerNetDataset(root_dir=root_dir,npy_file=test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = list()\n",
    "for e in X:\n",
    "    samples.append(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file=root_dir+\"test_samples.npy\",arr=samples,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.load(root_dir+\"test_samples.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.pool = nn.MaxPool2d(4, 4)\n",
    "        self.fc1 = nn.Linear(2208, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = x.view(-1, 2208)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Note: Can also see warning once\n",
    "# warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/mel_spec_experiment_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(labels == torch.argmax(outputs, dim=1)).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/mel_spec_experiment_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device)\n",
    "# Dataloader or dataset faulty(returns batches of 0\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    net.train()\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data['mel_spectogram'].to(device),data['label'].to(device)\n",
    "\n",
    "        #print(inputs.size())\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 0:    # print every 2000 mini-batches\n",
    "            \n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 5,\n",
    "                            epoch * len(dataloader) + i)\n",
    "            \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 5))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # calculate accuracy\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        res = torch.zeros((3,3))\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data['mel_spectogram'].to(device),data['label'].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "            \n",
    "            for p,gt in zip(preds,labels):\n",
    "                res[int(p),int(gt)] += 1\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        N_total = res.sum()\n",
    "        N_correct = res.diag().sum()\n",
    "        \n",
    "        acc = N_total / N_correct\n",
    "        \n",
    "        writer.add_scalar('training acc',\n",
    "                    acc,\n",
    "                    epoch)\n",
    "        print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate samples to look for cases where y, sr from librosa is inconsistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.fc1.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device)\n",
    "\n",
    "running_loss = 0.0\n",
    "for i, data in enumerate(dataloader, 0):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data['mel_spectogram'].unsqueeze(0).to(device),torch.argmax(data['one_hot_label']).to(device)\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    running_loss += loss.item()\n",
    "    if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "        print('[%d, %5d] loss: %.3f' %\n",
    "              (epoch + 1, i + 1, running_loss / 2000))\n",
    "        running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import torchvision\n",
    "import datetime\n",
    "from subprocess import Popen, PIPE\n",
    "import re\n",
    "\n",
    "class SoccerNetDataset(Dataset):\n",
    "    \"\"\"Soccernet Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self,npy_file,\n",
    "                 root_dir,nframes=1,\n",
    "                 stride_frames=1,\n",
    "                 frame_center='center',\n",
    "                 transform=None,\n",
    "                 train=False,\n",
    "                 tshift={'active':False,\n",
    "                         'mu':0,'sigma':(0.4/3), \n",
    "                         'interval':[-0.45,0.45],\n",
    "                         'mode': 'uniform'}):\n",
    "        self.npy_file = np.load(npy_file)\n",
    "        self.samples = list() # maybe change structure later depending on efficiency        \n",
    "        self.tshift = tshift\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.frame_center = frame_center\n",
    "        self.nframes = nframes\n",
    "        self.stride_frames = stride_frames\n",
    "        self.train = train\n",
    "        # For each path in npy_file, get all annotations\n",
    "\n",
    "\n",
    "        for e in self.npy_file:\n",
    "            path, annotations = self.get_annotations(e)\n",
    "\n",
    "            duration1 = self.getVideoLength(self.root_dir + e + \"/1.mkv\")\n",
    "            duration2 = self.getVideoLength(self.root_dir + e + \"/2.mkv\")\n",
    "            #print(f\"duration1 : {duration1}, duration2: {duration2}\")\n",
    "            for annotation in annotations:\n",
    "                # Check that annotations hold correct labels\n",
    "                        if (\"card\" in annotation[\"label\"]) or (\"subs\" in annotation[\"label\"]) or (\"soccer\" in annotation[\"label\"]):\n",
    "                            annotation[\"duration1\"] = duration1\n",
    "                            annotation[\"duration2\"] = duration2\n",
    "                            self.samples.append([path,annotation,\"soccernet\"])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def getVideoLength(self,video_file):\n",
    "        res = Popen(['ffmpeg', '-i', video_file, '-hide_banner'],stdout=PIPE,stderr=PIPE)\n",
    "        none,meta = res.communicate()\n",
    "        meta_out = meta.decode()\n",
    "        #---| Take out info\n",
    "        duration = re.search(r'Duration:.*', meta_out)\n",
    "        return duration.group()[:21]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        \"\"\"Returns a sample containing video path, clip and label\"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx.tolist()\n",
    "        \n",
    "        if self.train:\n",
    "            if idx in [2209,2210,2212,2213,2215,2217,2222]: # ultradirty hack - fix later\n",
    "                idx = 0\n",
    "        # get annotations\n",
    "        time_half = int(self.samples[idx][1][\"gameTime\"][0])\n",
    "        time_minute = int(self.samples[idx][1][\"gameTime\"][-5:-3])\n",
    "        time_second = int(self.samples[idx][1][\"gameTime\"][-2:])\n",
    "        annotation = self.samples[idx][1]\n",
    "        source = self.samples[idx][2]\n",
    "        \n",
    "\n",
    "\n",
    "        # Get label\n",
    "        if (\"card\" in annotation[\"label\"]): label = 0\n",
    "        elif (\"subs\" in annotation[\"label\"]): label = 1\n",
    "        elif (\"soccer\" in annotation[\"label\"]): label = 2\n",
    "        elif (\"background\" in annotation[\"label\"]): label = 3\n",
    "        else: \n",
    "            print(\"Warning, label not compatible with set\")\n",
    "            return\n",
    "            \n",
    "        # Get videopath\n",
    "        if source == 'soccernet':\n",
    "            vidpath = os.path.join(self.root_dir,\n",
    "                                str(self.samples[idx][0]),\n",
    "                                    str(time_half)+\".mkv\")\n",
    "        else:\n",
    "            vidpath = str(self.samples[idx][0])\n",
    "        \n",
    "        \n",
    "        # Get video frames \n",
    "        \n",
    "        # get start in second, use labeled time as center TODO: fix centerframe as keyframe and stride\n",
    "        fps = 25.0 # assume fps = 25 for now, should be so\n",
    "        start_sec = time_minute*60 + time_second\n",
    "        end_sec = start_sec\n",
    "\n",
    "        if self.nframes == 1:\n",
    "            end_sec = start_sec\n",
    "        \n",
    "        if start_sec == 0:\n",
    "            end_sec += (1/fps) # possibly unstable solution\n",
    "            \n",
    "        \n",
    "        if self.frame_center == 'center' and self.nframes > 1:\n",
    "            \n",
    "            end_sec = end_sec + (self.nframes/fps) # might need to subtract 1/fps\n",
    "            # Shift backwards to center around time but check that time > 0\n",
    "            diff = (end_sec - start_sec) / 2 # TODO : Might result in bad precision\n",
    "            temp_start_sec = start_sec - diff\n",
    "            temp_end_sec = end_sec - diff\n",
    "            \n",
    "            # Only change as long as the shift operation doesnt shift out of bounds \n",
    "            if temp_start_sec >= 0:\n",
    "                start_sec = temp_start_sec\n",
    "                end_sec = temp_end_sec\n",
    "                \n",
    "            # TODO : Find new samplesize if self.stride_frames > 1\n",
    "            # if self.stride_frames > 1:\n",
    "            # For now, this is an operation for another place\n",
    "                \n",
    "        elif self.frame_center == 'back' and self.nframes > 1:\n",
    "            print(\"This option should NOT be used during inference, please use 'center' instead\")\n",
    "            end_sec = end_sec + (self.nframes/fps) # might need to subtract 1/fps\n",
    "        elif self.frame_center == 'front' and self.nframes > 1:\n",
    "            #print(\"This option should NOT be used during inference, please use 'center' instead\")\n",
    "            \n",
    "            end_sec = end_sec + (self.nframes/fps) # might need to subtract 1/fps\n",
    "            \n",
    "            # Shift forward such that the last frame is at annotated time t around time but check that time > 0\n",
    "            diff = (end_sec - start_sec) # TODO : Might result in bad precision\n",
    "            temp_start_sec = start_sec - diff\n",
    "            temp_end_sec = end_sec - diff\n",
    "            \n",
    "            # Only change as long as the shift operation doesnt shift out of bounds \n",
    "            if temp_start_sec >= 0:\n",
    "                start_sec = temp_start_sec\n",
    "                end_sec = temp_end_sec\n",
    "\n",
    "        \n",
    "        # Temporal translation transform\n",
    "        \n",
    "        if self.tshift['active'] and self.frame_center == 'center' and source == 'soccernet':\n",
    "            t0 = self.tshift['interval'][0]\n",
    "            t = self.tshift['interval'][1]\n",
    "            \n",
    "            if self.tshift['mode'] == 'uniform':    \n",
    "                delta = np.floor(np.random.uniform(t0,t) * self.nframes)\n",
    "            elif self.tshift['mode'] == 'normal':\n",
    "                mu = self.tshift['mu']\n",
    "                sigma = self.tshift['sigma']\n",
    "                temporal_window_size = self.nframes / 25.0\n",
    "                delta = np.random.normal(mu,sigma)\n",
    "                if delta < t0:\n",
    "                    delta = t0\n",
    "                elif delta > t:\n",
    "                    delta = t\n",
    "                delta = delta * temporal_window_size\n",
    "            else: return \"Please choose uniform or normal distribution\"\n",
    "            \n",
    "            # change delta from frames to seconds with correct stepsize\n",
    "            shifted_start = start_sec+delta\n",
    "            shifted_end = end_sec+delta\n",
    "            # Verify that shifted window stays inside \n",
    "            # get duration of video\n",
    "            if time_half == 1:\n",
    "                video_length = self.samples[idx][1][\"duration1\"]\n",
    "            elif time_half == 2:\n",
    "                video_length = self.samples[idx][1][\"duration2\"]\n",
    "\n",
    "            video_length_min = video_length[-8:-6]\n",
    "            video_length_sec = video_length[-5:-3]\n",
    "            total_sec = int(video_length_min)*60 + int(video_length_sec)\n",
    "            \n",
    "            if shifted_start < 0 or shifted_end > total_sec:\n",
    "                shifted_start = start_sec\n",
    "                shifted_end = end_sec\n",
    "            \n",
    "            start_sec = shifted_start\n",
    "            end_sec = shifted_end\n",
    "\n",
    "        # Buffer to endsec incase of bad load\n",
    "        end_sec = end_sec + 0.9 # loads more frames than needed, then reduced later\n",
    "        clip,_,info = torchvision.io.read_video(vidpath, start_pts=start_sec, end_pts=end_sec, pts_unit='sec')\n",
    "        \n",
    "        # TODO : This should be tested\n",
    "        clip = clip[:self.nframes,:,:,:]\n",
    "        \n",
    "\n",
    "        one_hot_labels = np.zeros(3)\n",
    "        one_hot_labels[label] = 1\n",
    "\n",
    "        csize = clip.size()\n",
    "        abnormal_count = 0\n",
    "        bad_count = 0   \n",
    "        abnormal_2_count = 0\n",
    "        # At this point clip is [T x H x W x C]\n",
    "        if clip.size()[3] != 3 or clip.size()[0] != self.nframes or clip.size()[1] != 224 or clip.size()[2] != 398:\n",
    "            abnormal_count += 1\n",
    "            if clip.size()[1] != 224 or clip.size()[2] != 398 or clip.size()[0] / self.nframes < 0.6:\n",
    "                clip = torch.zeros([self.nframes,224,398,3]).byte()\n",
    "                bad_count += 1\n",
    "            elif clip.size()[1] == 224 and clip.size()[2] == 398 and clip.size()[0] / self.nframes > 0.6:\n",
    "                a = clip.size()[0]\n",
    "                b = self.nframes - a\n",
    "                last_f = clip[(a-1):,:,:,:]\n",
    "                dup = last_f.repeat(b,1,1,1)\n",
    "                clip = torch.cat((clip,dup)).byte()\n",
    "                abnormal_2_count += 1\n",
    "\n",
    "        \n",
    "\n",
    "        sample = {'vidpath': vidpath,'clip': clip, 'annotation':annotation,'label':one_hot_labels,'idx':idx,\n",
    "                 'csize':csize, 'source': source}\n",
    "        \n",
    "\n",
    "        if self.transform:\n",
    "            sample['clip'] = self.transform(sample['clip'])\n",
    "        return sample\n",
    "            \n",
    "    def get_annotations(self,path):\n",
    "        \"\"\" Reads json files and returns \"\"\"\n",
    "        with open(self.root_dir+path+\"/Labels.json\") as jsonfile:\n",
    "            json_label = json.load(jsonfile)\n",
    "        \n",
    "        labels = [e for e in json_label['annotations']]\n",
    "        \n",
    "        return path,labels\n",
    "    def get_keyframe(self,idx):\n",
    "        if self.frame_center == 'back': return self.__getitem__(idx)['clip'][0,:,:,:]\n",
    "        elif self.frame_center == 'center': return self.__getitem__(idx)['clip'][self.nframes//2,:,:,:]\n",
    "        elif self.frame_center == 'front': return self.__getitem__(idx)['clip'][self.nframes-1,:,:,:]\n",
    "    def describe(self):\n",
    "        card = 0\n",
    "        subs = 0\n",
    "        goal = 0\n",
    "        background = 0\n",
    "\n",
    "        for sample in self.samples:\n",
    "            annotation = sample[1]\n",
    "        # Get label\n",
    "            if (\"card\" in annotation[\"label\"]): card += 1\n",
    "            elif (\"subs\" in annotation[\"label\"]): subs +=1\n",
    "            elif (\"soccer\" in annotation[\"label\"]): goal += 1\n",
    "            elif (\"background\" in annotation[\"label\"]): background += 1\n",
    "\n",
    "        print(\"Description of dataset\\n\\n\")\n",
    "        print(\"\\n ********* Classes *********\")\n",
    "        print(\"\\n card = 0\\n subs = 1\\n goals = 2\\n background = 3\")\n",
    "\n",
    "        print(\"\\n ********* Distribution and count *********\")\n",
    "        print(f\"\\n N card: {card} \\n N subs: {subs} \\n N goal: {goal} \\n N background: {background} \\n \\n Total : {card+subs+goal+background}\")\n",
    "        \n",
    "        print(\"\\n\\n ********* Configuration *********\")\n",
    "        print(f\"\\n npy_file: {self.npy_file} \\n tshift: {self.tshift} \\n root_dir: {self.root_dir} \\n transform: {self.transform} \\n frame_center: {self.frame_center} \\n nframes: {self.nframes} \\n stride_frames: {self.stride_frames} \\n background: {self.background}\")\n",
    "        print(\"\\n\\n ********* End of description *********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_file_train = \"/work/oarongve/data/listgame_Train_300.npy\"\n",
    "npy_file_test = \"/work/oarongve/data/listgame_Test_100.npy\"\n",
    "root_dir = \"/work/oarongve/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "videods = SoccerNetDataset(root_dir=root_dir,npy_file=npy_file,train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vidpath': '/work/oarongve/data/england_epl/2014-2015/2015-05-17 - 18-00 Manchester United 1 - 1 Arsenal/1.mkv',\n",
       " 'clip': tensor([[[[ 90,  71,  75],\n",
       "           [ 60,  41,  45],\n",
       "           [ 72,  50,  53],\n",
       "           ...,\n",
       "           [ 71,  61,  65],\n",
       "           [125, 115, 119],\n",
       "           [109,  99, 103]],\n",
       " \n",
       "          [[101,  82,  86],\n",
       "           [ 84,  65,  69],\n",
       "           [ 54,  32,  35],\n",
       "           ...,\n",
       "           [ 89,  79,  83],\n",
       "           [163, 153, 157],\n",
       "           [132, 122, 126]],\n",
       " \n",
       "          [[ 78,  61,  62],\n",
       "           [ 62,  45,  46],\n",
       "           [ 63,  44,  46],\n",
       "           ...,\n",
       "           [ 77,  71,  76],\n",
       "           [157, 151, 156],\n",
       "           [121, 115, 120]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[102, 130,  55],\n",
       "           [113, 141,  66],\n",
       "           [115, 145,  67],\n",
       "           ...,\n",
       "           [119, 142,  80],\n",
       "           [118, 141,  77],\n",
       "           [ 95, 118,  54]],\n",
       " \n",
       "          [[100, 128,  51],\n",
       "           [114, 142,  65],\n",
       "           [115, 145,  67],\n",
       "           ...,\n",
       "           [121, 144,  82],\n",
       "           [119, 142,  78],\n",
       "           [ 97, 120,  56]],\n",
       " \n",
       "          [[106, 134,  57],\n",
       "           [120, 148,  71],\n",
       "           [122, 152,  74],\n",
       "           ...,\n",
       "           [127, 150,  88],\n",
       "           [123, 146,  82],\n",
       "           [101, 124,  60]]]], dtype=torch.uint8),\n",
       " 'annotation': {'gameTime': '1 - 29:19',\n",
       "  'label': 'soccer-ball',\n",
       "  'team': 'home',\n",
       "  'duration1': 'Duration: 00:45:00.00',\n",
       "  'duration2': 'Duration: 00:50:43.72'},\n",
       " 'label': array([0., 0., 1.]),\n",
       " 'idx': 0,\n",
       " 'csize': torch.Size([1, 224, 398, 3]),\n",
       " 'source': 'soccernet'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videods[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-daredevil",
   "language": "python",
   "name": "project-daredevil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
