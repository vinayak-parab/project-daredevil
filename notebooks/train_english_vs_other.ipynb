{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "sys.path.append('../')\n",
    "from src.datasets.soccernet_generic import soccernet_dataset_generic\n",
    "from src.utils.helper import samples_by_language\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/work/oarongve/data/sound_dataset/SoccerNet-code/data/\"\n",
    "train_list = \"/work/oarongve/data/sound_dataset/SoccerNet-code/data/listgame_Train_300.npy\"\n",
    "valid_list = \"/work/oarongve/data/sound_dataset/SoccerNet-code/data/listgame_Valid_100.npy\"\n",
    "test_list = \"/work/oarongve/data/sound_dataset/SoccerNet-code/data/listgame_Test_100.npy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "which python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langpath_train = '/work/oarongve/project-daredevil/project-daredevil/language-annotations/annotations/train_lang_dict.json'\n",
    "langpath_valid = '/work/oarongve/project-daredevil/project-daredevil/language-annotations/annotations/valid_lang_dict.json'\n",
    "langpath_test = '/work/oarongve/project-daredevil/project-daredevil/language-annotations/annotations/test_lang_dict.json'\n",
    "\n",
    "samples_train_all = samples_by_language(langpath_train,train_list,'all')\n",
    "samples_valid_all = samples_by_language(langpath_valid,valid_list,'all')\n",
    "samples_test_all = samples_by_language(langpath_test,test_list,'all')\n",
    "\n",
    "samples_train_english = samples_by_language(langpath_train,train_list,'english')\n",
    "samples_valid_english = samples_by_language(langpath_valid,valid_list,'english')\n",
    "samples_test_english = samples_by_language(langpath_test,test_list,'english')\n",
    "\n",
    "samples_train_other = samples_by_language(langpath_train,train_list,'other')\n",
    "samples_valid_other = samples_by_language(langpath_valid,valid_list,'other')\n",
    "samples_test_other = samples_by_language(langpath_test,test_list,'other')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_all = soccernet_dataset_generic(npy_file=train_list,root_dir=root_dir,lang='all',lang_dict=langpath_train)\n",
    "valid_set_all = soccernet_dataset_generic(npy_file=valid_list,root_dir=root_dir,lang='all',lang_dict=langpath_valid)\n",
    "\n",
    "train_set_english = soccernet_dataset_generic(npy_file=train_list,root_dir=root_dir,lang='english',lang_dict=langpath_train)\n",
    "valid_set_english = soccernet_dataset_generic(npy_file=valid_list,root_dir=root_dir,lang='english',lang_dict=langpath_valid)\n",
    "\n",
    "train_set_other = soccernet_dataset_generic(npy_file=train_list,root_dir=root_dir,lang='other',lang_dict=langpath_train)\n",
    "valid_set_other = soccernet_dataset_generic(npy_file=valid_list,root_dir=root_dir,lang='other',lang_dict=langpath_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.load_waves()\n",
    "valid_set.load_waves()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.generate_mel_spectrograms(load_features=True)\n",
    "valid_set.generate_mel_spectrograms(load_features=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.load_resnet_features()\n",
    "valid_set.load_resnet_features()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.set_window_size(w)\n",
    "valid_set.set_window_size(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on resnet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,window_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(512,1))\n",
    "        self.bn1 = nn.BatchNorm2d(self.conv1.out_channels)\n",
    "        self.conv2 = nn.Conv2d(self.conv1.out_channels, 64, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(self.conv2.out_channels)\n",
    "        self.fc1 = nn.Linear(self.conv2.out_channels*(window_size*2), 120)\n",
    "        self.fc2 = nn.Linear(self.fc1.out_features, 84)\n",
    "        self.fc3 = nn.Linear(84, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = x.reshape(x.size(0),-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = Net(w)\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.025, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "params = {'batch_size': 24,\n",
    "         'shuffle': True,\n",
    "         'num_workers':4,\n",
    "         'drop_last':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.set_window_size(w)\n",
    "valid_set.set_window_size(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_set,**params)\n",
    "validloader = DataLoader(valid_set,**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net.to(device)\n",
    "epochs = 10\n",
    "accs = list()\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader,0):\n",
    "        inputs = data['resnet_spot'].unsqueeze(1).permute(0,1,3,2).to(device)\n",
    "        target = data['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "            if i % 5 == 0:    # print every 2000 mini-batches\n",
    "\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 5))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    # calculate accuracy\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        res = torch.zeros((4,4))\n",
    "        for i, data in enumerate(validloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = data['resnet_spot'].unsqueeze(1).permute(0,1,3,2).to(device)\n",
    "            label = data['label'].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "\n",
    "            for p,gt in zip(preds,label):\n",
    "                res[int(p),int(gt)] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        N_total = res.sum()\n",
    "        N_correct = res.diag().sum()\n",
    "\n",
    "        acc = N_correct / N_total\n",
    "\n",
    "        print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "        accs.append(acc)\n",
    "\n",
    "        print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "resnet = torchvision.models.resnet18(pretrained=True)\n",
    "resnet.conv1 = nn.Conv2d(1,64,kernel_size=(7,7),stride=(2,2),padding=(3,3),bias=False)\n",
    "resnet.fc = nn.Linear(512,4,bias=True)\n",
    "#resnet.features.conv0 = nn.Conv2d(1, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "#resnet.classifier = nn.Linear(in_features=densenet.classifier.in_features, out_features=3,bias=True)\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=0.0001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.to(device)\n",
    "epochs = 10\n",
    "accs_ms = list()\n",
    "for epoch in range(epochs):\n",
    "    for i, data in enumerate(trainloader,0):\n",
    "        \n",
    "        resnet.train()\n",
    "        inputs = data['ms_spot'].unsqueeze(1).permute(0,1,2,3).to(device)\n",
    "        target = data['label'].to(device)\n",
    "        inputs[inputs.isnan()] = 0.0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = resnet(inputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "            running_loss += loss.item()\n",
    "            # print statistics\n",
    "\n",
    "\n",
    "    # calculate accuracy\n",
    "    with torch.no_grad():\n",
    "        resnet.eval()\n",
    "        res = torch.zeros((4,4))\n",
    "        for i, data in enumerate(validloader\n",
    "                                 , 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = data['ms_spot'].unsqueeze(1).permute(0,1,2,3).to(device)\n",
    "            label = data['label'].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = resnet(inputs)\n",
    "\n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "\n",
    "            for p,gt in zip(preds,label):\n",
    "                res[int(p),int(gt)] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        N_total = res.sum()\n",
    "        N_correct = res.diag().sum()\n",
    "\n",
    "        acc = N_correct / N_total\n",
    "        accs_ms.append(acc)\n",
    "        print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge models 1 - softmax average during eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    resnet.eval()\n",
    "    net.eval()\n",
    "    \n",
    "    res_visual = torch.zeros((4,4))\n",
    "    res_audio = torch.zeros((4,4))\n",
    "    res = torch.zeros((4,4))\n",
    "    \n",
    "    \n",
    "    for i, data in enumerate(validloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs_audio = data['ms_spot'].unsqueeze(1).permute(0,1,2,3).to(device)\n",
    "        inputs_visual = data['resnet_spot'].unsqueeze(1).permute(0,1,3,2).to(device)\n",
    "        label = data['label'].to(device)\n",
    "        \n",
    "        inputs_audio[inputs_audio.isnan()] = 0.0\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs_audio = resnet(inputs_audio)\n",
    "        outputs_visual = net(inputs_visual)\n",
    "\n",
    "        fused_preds = torch.softmax(outputs_audio,dim=1) + torch.softmax(outputs_visual,dim=1)\n",
    "        preds_audio = torch.argmax(outputs_audio,dim=1)\n",
    "        preds_visual = torch.argmax(outputs_visual,dim=1)\n",
    "        \n",
    "        preds = torch.argmax(fused_preds,dim=1)\n",
    "        for p,gt in zip(preds,label):\n",
    "            res[int(p),int(gt)] += 1\n",
    "        \n",
    "        for p,gt in zip(preds_audio,label):\n",
    "            res_audio[int(p),int(gt)] += 1\n",
    "            \n",
    "        for p,gt in zip(preds_visual,label):\n",
    "            res_visual[int(p),int(gt)] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    N_total = res.sum()\n",
    "    N_correct = res.diag().sum()\n",
    "\n",
    "    acc = N_correct / N_total\n",
    "    accs_ms.append(acc)\n",
    "    print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(res_a):\n",
    "    N_total = res_a.sum()\n",
    "    N_correct = res_a.diag().sum()\n",
    "\n",
    "    acc = N_correct / N_total\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc(res_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc(res_visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class fusion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(fusion, self).__init__()\n",
    "        self.fc1 = nn.Linear(256,256)\n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.fc3 = nn.Linear(128,3)\n",
    "        self.bn = nn.BatchNorm1d(256)\n",
    "\n",
    "    def forward(self, x_audio,x_visual):\n",
    "        x = torch.cat((x_audio,x_visual),dim=1)\n",
    "        print(x.size())\n",
    "        x = x.view(-1,256)\n",
    "        x = self.bn(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.fc = nn.Linear(512,out_features=128,bias=True)\n",
    "net.fc3 = nn.Linear(84,128,bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Window sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "resnet = torchvision.models.resnet18(pretrained=True)\n",
    "resnet.conv1 = nn.Conv2d(1,64,kernel_size=(7,7),stride=(2,2),padding=(3,3),bias=False)\n",
    "resnet.fc = nn.Linear(512,4,bias=True)\n",
    "#resnet.features.conv0 = nn.Conv2d(1, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "#resnet.classifier = nn.Linear(in_features=densenet.classifier.in_features, out_features=3,bias=True)\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsizes = [2,4,8,16,32,64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "#for w in wsizes:\n",
    "w = 4 \n",
    "# set window_size for training and validation set\n",
    "train_set.set_window_size(w)\n",
    "valid_set.set_window_size(w)\n",
    "\n",
    "resnet = torchvision.models.resnet18(pretrained=True)\n",
    "resnet.conv1 = nn.Conv2d(1,64,kernel_size=(7,7),stride=(2,2),padding=(3,3),bias=False)\n",
    "resnet.fc = nn.Linear(512,3,bias=True)\n",
    "#resnet.features.conv0 = nn.Conv2d(1, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "#resnet.classifier = nn.Linear(in_features=densenet.classifier.in_features, out_features=3,bias=True)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[5,10], gamma=0.1)\n",
    "\n",
    "# train\n",
    "\n",
    "resnet.to(device)\n",
    "\n",
    "epochs = 5\n",
    "accs_ms = list()\n",
    "print(w)\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for i, data in enumerate(trainloader,0):\n",
    "\n",
    "\n",
    "        resnet.train()\n",
    "        inputs = data['ms_spot'].unsqueeze(1).permute(0,1,2,3).to(device)\n",
    "        target = data['label'].to(device)\n",
    "        inputs[inputs.isnan()] = 0.0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = resnet(inputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        scheduler.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "            running_loss += loss.item()\n",
    "            # print statistics\n",
    "\n",
    "\n",
    "    # calculate accuracy\n",
    "    with torch.no_grad():\n",
    "        resnet.eval()\n",
    "        res = torch.zeros((3,3))\n",
    "        for i, data in enumerate(validloader\n",
    "                                 , 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = data['ms_spot'].unsqueeze(1).permute(0,1,2,3).to(device)\n",
    "            label = data['label'].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = resnet(inputs)\n",
    "\n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "\n",
    "            for p,gt in zip(preds,label):\n",
    "                res[int(p),int(gt)] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        N_total = res.sum()\n",
    "        N_correct = res.diag().sum()\n",
    "\n",
    "        acc = N_correct / N_total\n",
    "        accs_ms.append(acc)\n",
    "        print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in [2,4,8,16,32,64,128]:\n",
    "    acc = 0\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    net = Net(w)\n",
    "    import torch.optim as optim\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.025, momentum=0.9)\n",
    "    net.to(device)\n",
    "    epochs = 5\n",
    "    accs = list()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader,0):\n",
    "            inputs = data['resnet_spot'].unsqueeze(1).permute(0,1,3,2).to(device)\n",
    "            target = data['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "                if i % 5 == 0:    # print every 2000 mini-batches\n",
    "\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 5))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        # calculate accuracy\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            res = torch.zeros((3,3))\n",
    "            for i, data in enumerate(validloader, 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs = data['resnet_spot'].unsqueeze(1).permute(0,1,3,2).to(device)\n",
    "                label = data['label'].to(device)\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(inputs)\n",
    "\n",
    "                preds = torch.argmax(outputs,dim=1)\n",
    "\n",
    "                for p,gt in zip(preds,label):\n",
    "                    res[int(p),int(gt)] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            N_total = res.sum()\n",
    "            N_correct = res.diag().sum()\n",
    "\n",
    "            acc = N_correct / N_total\n",
    "\n",
    "            print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "            accs.append(acc)\n",
    "\n",
    "            print('Finished Training')\n",
    "    print(f\"window: {w} acc: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in [2,4,8,16,32,64,128]:\n",
    "    acc = 0\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    train_set.set_window_size(w)\n",
    "    valid_set.set_window_size(w)\n",
    "\n",
    "    trainloader = DataLoader(train_set,**params)\n",
    "    validloader = DataLoader(valid_set,**params)\n",
    "    \n",
    "    net = Net(w)\n",
    "    import torch.optim as optim\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.025, momentum=0.9)\n",
    "    net.to(device)\n",
    "    epochs = 5\n",
    "    accs = list()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader,0):\n",
    "            inputs = data['resnet_spot'].unsqueeze(1).permute(0,1,3,2).to(device)\n",
    "            target = data['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "                if i % 5 == 0:    # print every 2000 mini-batches\n",
    "\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 5))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        # calculate accuracy\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            res = torch.zeros((3,3))\n",
    "            for i, data in enumerate(validloader, 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs = data['resnet_spot'].unsqueeze(1).permute(0,1,3,2).to(device)\n",
    "                label = data['label'].to(device)\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(inputs)\n",
    "\n",
    "                preds = torch.argmax(outputs,dim=1)\n",
    "\n",
    "                for p,gt in zip(preds,label):\n",
    "                    res[int(p),int(gt)] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            N_total = res.sum()\n",
    "            N_correct = res.diag().sum()\n",
    "\n",
    "            acc = N_correct / N_total\n",
    "\n",
    "            print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "            accs.append(acc)\n",
    "\n",
    "            print('Finished Training')\n",
    "    print(f\"window: {w} acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "params = {'batch_size': 24,\n",
    "         'shuffle': True,\n",
    "         'num_workers':4,\n",
    "         'drop_last':True}\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "accs_w = list()\n",
    "for w in [2,4,8,16,32,64,128]:\n",
    "    acc = 0\n",
    "    running_loss = 0\n",
    "    # fix loader\n",
    "    train_set.set_window_size(w)\n",
    "    valid_set.set_window_size(w)\n",
    "\n",
    "    trainloader = DataLoader(train_set,**params)\n",
    "    validloader = DataLoader(valid_set,**params)\n",
    "\n",
    "    resnet = torchvision.models.resnet18(pretrained=True)\n",
    "    resnet.conv1 = nn.Conv2d(1,64,kernel_size=(7,7),stride=(2,2),padding=(3,3),bias=False)\n",
    "    resnet.fc = nn.Linear(512,4,bias=True)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(resnet.parameters(), lr=0.0001, momentum=0.9)\n",
    "    resnet.to(device)\n",
    "    \n",
    "    epochs = 5\n",
    "    accs = list()\n",
    "    for epoch in range(epochs):\n",
    "        for i, data in enumerate(trainloader,0):\n",
    "\n",
    "            resnet.train()\n",
    "            inputs = data['ms_spot'].unsqueeze(1).permute(0,1,2,3).to(device)\n",
    "            target = data['label'].to(device)\n",
    "            inputs[inputs.isnan()] = 0.0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = resnet(inputs)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "                running_loss += loss.item()\n",
    "                # print statistics\n",
    "\n",
    "\n",
    "        # calculate accuracy\n",
    "        with torch.no_grad():\n",
    "            resnet.eval()\n",
    "            res = torch.zeros((4,4))\n",
    "            for i, data in enumerate(validloader, 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs = data['ms_spot'].unsqueeze(1).permute(0,1,2,3).to(device)\n",
    "                label = data['label'].to(device)\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = resnet(inputs)\n",
    "\n",
    "                preds = torch.argmax(outputs,dim=1)\n",
    "\n",
    "                for p,gt in zip(preds,label):\n",
    "                    res[int(p),int(gt)] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            N_total = res.sum()\n",
    "            N_correct = res.diag().sum()\n",
    "\n",
    "            acc = N_correct / N_total\n",
    "            \n",
    "            print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "            accs.append(acc)\n",
    "            \n",
    "    accs_w.append(acc)\n",
    "    print(f\"window: {w} acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "accs_w_v = list()\n",
    "for w in [2,4,8,16,32,64,128]:\n",
    "    acc = 0\n",
    "    running_loss = 0\n",
    "    # fix loader\n",
    "    train_set.set_window_size(w)\n",
    "    valid_set.set_window_size(w)\n",
    "\n",
    "    trainloader = DataLoader(train_set,**params)\n",
    "    validloader = DataLoader(valid_set,**params)\n",
    "\n",
    "    net = Net(w)\n",
    "    import torch.optim as optim\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.025, momentum=0.9)\n",
    "    \n",
    "    epochs = 5\n",
    "    accs = list()\n",
    "    net.to(device)\n",
    "    epochs = 10\n",
    "    accs = list()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader,0):\n",
    "            inputs = data['resnet_spot'].unsqueeze(1).permute(0,1,3,2).to(device)\n",
    "            target = data['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "                if i % 5 == 0:    # print every 2000 mini-batches\n",
    "\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 5))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        # calculate accuracy\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            res = torch.zeros((4,4))\n",
    "            for i, data in enumerate(validloader, 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs = data['resnet_spot'].unsqueeze(1).permute(0,1,3,2).to(device)\n",
    "                label = data['label'].to(device)\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(inputs)\n",
    "\n",
    "                preds = torch.argmax(outputs,dim=1)\n",
    "\n",
    "                for p,gt in zip(preds,label):\n",
    "                    res[int(p),int(gt)] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            N_total = res.sum()\n",
    "            N_correct = res.diag().sum()\n",
    "\n",
    "            acc = N_correct / N_total\n",
    "\n",
    "            print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "            accs.append(acc)\n",
    "\n",
    "            print('Finished Training')\n",
    "\n",
    "        accs_w_v.append(accs) # get best acc, save best model\n",
    "    print(f\"window: {w} acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put into more clean place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-daredevil",
   "language": "python",
   "name": "project-daredevil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
