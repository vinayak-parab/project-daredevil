{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchaudio\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir   = \"/work/oarongve/data/sound_dataset/SoccerNet-code/data/\"\n",
    "train_file = root_dir+\"listgame_Train_300.npy\"\n",
    "valid_file = root_dir+\"listgame_Valid_100.npy\"\n",
    "test_file  = root_dir+\"listgame_Test_100.npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librosa test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 8000 # Should be 16 kHz\n",
    "WINDOW_LENGTH = int(0.025 * SAMPLE_RATE) # Should be 25 ms\n",
    "N_FFT = 512 # Should be 512\n",
    "STEP_SIZE = int(0.01 * SAMPLE_RATE) # Should be 10ms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 20 15:56:57 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.165.02   Driver Version: 418.165.02   CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM3...  On   | 00000000:E0:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    47W / 350W |      0MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import torchvision\n",
    "import datetime\n",
    "import torchaudio\n",
    "import librosa\n",
    "from subprocess import Popen, PIPE\n",
    "import re\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "class SoccerNetDataset(Dataset):\n",
    "    \"\"\"Soccernet Dataset\"\"\"\n",
    "    \n",
    "    SAMPLE_RATE = 8000 # Should be 16 kHz\n",
    "    WINDOW_LENGTH = int(0.025 * SAMPLE_RATE) # Should be 25 ms\n",
    "    N_FFT = 512 # Should be 512\n",
    "    STEP_SIZE = int(0.01 * SAMPLE_RATE) # Should be 10ms\n",
    "    \n",
    "    def __init__(self,npy_file,\n",
    "                 root_dir,\n",
    "                 transform=None,\n",
    "                 background=False,\n",
    "                 wsize=4):\n",
    "    \n",
    "        self.wsize = wsize\n",
    "        self.npy_file = np.load(npy_file)\n",
    "        self.samples = list() # maybe change structure later depending on efficiency        \n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        for e in self.npy_file:\n",
    "            path, annotations = self.get_annotations(e)\n",
    "\n",
    "            duration1 = self.getVideoLength(self.root_dir + e + \"/1.mkv\")\n",
    "            duration2 = self.getVideoLength(self.root_dir + e + \"/2.mkv\")\n",
    "            #print(f\"duration1 : {duration1}, duration2: {duration2}\")\n",
    "            for annotation in annotations:\n",
    "                # Check that annotations hold correct labels\n",
    "                        if (\"card\" in annotation[\"label\"]) or (\"subs\" in annotation[\"label\"]) or (\"soccer\" in annotation[\"label\"]):\n",
    "                            annotation[\"duration1\"] = duration1\n",
    "                            annotation[\"duration2\"] = duration2\n",
    "                            self.samples.append([path,annotation])\n",
    "\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def getVideoLength(self,video_file):\n",
    "        res = Popen(['ffmpeg', '-i', video_file, '-hide_banner'],stdout=PIPE,stderr=PIPE)\n",
    "        none,meta = res.communicate()\n",
    "        meta_out = meta.decode()\n",
    "        #---| Take out info\n",
    "        duration = re.search(r'Duration:.*', meta_out)\n",
    "        return duration.group()[:21]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        \"\"\"Returns a sample containing video path, clip and label\"\"\"\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx.tolist()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # get annotations\n",
    "        time_half = int(self.samples[idx][1][\"gameTime\"][0])\n",
    "        time_minute = int(self.samples[idx][1][\"gameTime\"][-5:-3])\n",
    "        time_second = int(self.samples[idx][1][\"gameTime\"][-2:])\n",
    "        annotation = self.samples[idx][1]\n",
    "\n",
    "        # Get label\n",
    "        if (\"card\" in annotation[\"label\"]): label = 0\n",
    "        elif (\"subs\" in annotation[\"label\"]): label = 1\n",
    "        elif (\"soccer\" in annotation[\"label\"]): label = 2\n",
    "        elif (\"background\" in annotation[\"label\"]): label = 3\n",
    "        else: \n",
    "            print(\"Warning, label not compatible with set\")\n",
    "            return\n",
    "\n",
    "        # Get audiopath\n",
    "        audiopath = os.path.join(self.root_dir,\n",
    "                              str(self.samples[idx][0]),\n",
    "                                str(time_half)+\"_audio.wav\")\n",
    "        \n",
    "        path = self.root_dir+str(self.samples[idx][0])+\"/\"\n",
    "\n",
    "        \n",
    "        one_hot_label = np.zeros(4)\n",
    "        one_hot_label[label] = 1\n",
    "        # Get video frames \n",
    "        \n",
    "        # get start in second, use labeled time as center TODO: fix centerframe as keyframe and stride\n",
    "        fps = 25.0 # assume fps = 25 for now, should be so\n",
    "        start_sec = time_minute*60 + time_second\n",
    "        end_sec = start_sec\n",
    "        \n",
    "        if start_sec == 0:\n",
    "            end_sec += (1/fps) # possibly unstable solution\n",
    "            \n",
    "        end_sec = end_sec + self.wsize # might need to subtract 1/fps\n",
    "        # Shift backwards to center around time but check that time > 0\n",
    "        diff = (end_sec - start_sec) / 2 # TODO : Might result in bad precision\n",
    "        temp_start_sec = start_sec - diff\n",
    "        temp_end_sec = end_sec - diff\n",
    "\n",
    "        # Only change as long as the shift operation doesnt shift out of bounds \n",
    "        if temp_start_sec >= 0:\n",
    "            start_sec = temp_start_sec\n",
    "            end_sec = temp_end_sec\n",
    "        \n",
    "        # Buffer to endsec incase of bad load\n",
    "        end_sec = end_sec + 0.9 # loads more frames than needed, then reduced later\n",
    "        \n",
    "        y, sr = librosa.load(audiopath,sr=SAMPLE_RATE,offset=start_sec,duration=self.wsize+1)\n",
    "        \n",
    "        y = y[:SAMPLE_RATE*4]\n",
    "        \n",
    "        ms = torchaudio.transforms.MelSpectrogram(sample_rate=SAMPLE_RATE,\n",
    "                                                n_fft=N_FFT,\n",
    "                                                win_length=WINDOW_LENGTH,\n",
    "                                                hop_length=STEP_SIZE)(torch.Tensor(y)).log10().unsqueeze(0)\n",
    "        \n",
    "        ms = ms[:,:,:401]\n",
    "        \n",
    "        np.save(file=path+str(idx)+\"_ms.npy\", arr = ms)\n",
    "        \n",
    "        if ms.size() != (1,128,401):\n",
    "            print(f\"ms size :{ms.size()}, using zeros instead ...\")\n",
    "            ms = torch.zeros((1,128,401))\n",
    "        \n",
    "        \n",
    "        sample = {'path': str(self.samples[idx][0]),'ms':ms,'audiopath': audiopath, 'annotation':annotation,'idx':idx, 'one_hot_label':one_hot_label,'label':label}\n",
    "        \n",
    "        return sample\n",
    "            \n",
    "    def get_annotations(self,path):\n",
    "        \"\"\" Reads json files and returns \"\"\"\n",
    "        with open(self.root_dir+path+\"/Labels.json\") as jsonfile:\n",
    "            json_label = json.load(jsonfile)\n",
    "        \n",
    "        labels = [e for e in json_label['annotations']]\n",
    "        \n",
    "        return path,labels\n",
    "    def get_keyframe(self,idx):\n",
    "        if self.frame_center == 'back': return self.__getitem__(idx)['clip'][0,:,:,:]\n",
    "        elif self.frame_center == 'center': return self.__getitem__(idx)['clip'][self.nframes//2,:,:,:]\n",
    "        elif self.frame_center == 'front': return self.__getitem__(idx)['clip'][self.nframes-1,:,:,:]\n",
    "    def describe(self):\n",
    "        card = 0\n",
    "        subs = 0\n",
    "        goal = 0\n",
    "        background = 0\n",
    "\n",
    "        for sample in self.samples:\n",
    "            annotation = sample[1]\n",
    "        # Get label\n",
    "            if (\"card\" in annotation[\"label\"]): card += 1\n",
    "            elif (\"subs\" in annotation[\"label\"]): subs +=1\n",
    "            elif (\"soccer\" in annotation[\"label\"]): goal += 1\n",
    "            elif (\"background\" in annotation[\"label\"]): background += 1\n",
    "\n",
    "        print(\"Description of dataset\\n\\n\")\n",
    "        print(\"\\n ********* Classes *********\")\n",
    "        print(\"\\n card = 0\\n subs = 1\\n goals = 2\\n background = 3\")\n",
    "\n",
    "        print(\"\\n ********* Distribution and count *********\")\n",
    "        print(f\"\\n N card: {card} \\n N subs: {subs} \\n N goal: {goal} \\n N background: {background} \\n \\n Total : {card+subs+goal+background}\")\n",
    "        \n",
    "        print(\"\\n\\n ********* Configuration *********\")\n",
    "        print(f\"\\n npy_file: {self.npy_file} \\n tshift: {self.tshift} \\n root_dir: {self.root_dir} \\n transform: {self.transform} \\n frame_center: {self.frame_center} \\n nframes: {self.nframes} \\n stride_frames: {self.stride_frames} \\n background: {self.background}\")\n",
    "        print(\"\\n\\n ********* Evalidnd of description *********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 8,\n",
    "         'shuffle': False,\n",
    "         'num_workers':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = SoccerNetDataset(root_dir=root_dir,npy_file=train_file)\n",
    "X_valid = SoccerNetDataset(root_dir=root_dir,npy_file=valid_file)\n",
    "X_test = SoccerNetDataset(root_dir=root_dir,npy_file=test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(X_train,**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 858 ms, sys: 371 ms, total: 1.23 s\n",
      "Wall time: 53min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, data in enumerate(dataloader_train):\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataloader_valid = DataLoader(X_valid,**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 2.\nOriginal Traceback (most recent call last):\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/librosa/core/audio.py\", line 146, in load\n    with sf.SoundFile(path) as sf_desc:\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/soundfile.py\", line 629, in __init__\n    self._file = self._open(file, mode_int, closefd)\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/soundfile.py\", line 1184, in _open\n    \"Error opening {0!r}: \".format(self.name))\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/soundfile.py\", line 1357, in _error_check\n    raise RuntimeError(prefix + _ffi.string(err_str).decode('utf-8', 'replace'))\nRuntimeError: Error opening '/work/oarongve/data/sound_dataset/SoccerNet-code/data/france_ligue-1/2016-2017/2017-05-14 - 22-00 St Etienne 0 - 5 Paris SG/2_audio.wav': System error.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 185, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-93-b8cf6cf15c1b>\", line 120, in __getitem__\n    y, sr = librosa.load(audiopath,sr=SAMPLE_RATE,offset=start_sec,duration=self.wsize+1)\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/librosa/core/audio.py\", line 163, in load\n    y, sr_native = __audioread_load(path, offset, duration, dtype)\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/librosa/core/audio.py\", line 187, in __audioread_load\n    with audioread.audio_open(path) as input_file:\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/audioread/__init__.py\", line 111, in audio_open\n    return BackendClass(path)\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/audioread/rawread.py\", line 62, in __init__\n    self._fh = open(filename, 'rb')\nFileNotFoundError: [Errno 2] No such file or directory: '/work/oarongve/data/sound_dataset/SoccerNet-code/data/france_ligue-1/2016-2017/2017-05-14 - 22-00 St Etienne 0 - 5 Paris SG/2_audio.wav'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 2.\nOriginal Traceback (most recent call last):\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/librosa/core/audio.py\", line 146, in load\n    with sf.SoundFile(path) as sf_desc:\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/soundfile.py\", line 629, in __init__\n    self._file = self._open(file, mode_int, closefd)\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/soundfile.py\", line 1184, in _open\n    \"Error opening {0!r}: \".format(self.name))\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/soundfile.py\", line 1357, in _error_check\n    raise RuntimeError(prefix + _ffi.string(err_str).decode('utf-8', 'replace'))\nRuntimeError: Error opening '/work/oarongve/data/sound_dataset/SoccerNet-code/data/france_ligue-1/2016-2017/2017-05-14 - 22-00 St Etienne 0 - 5 Paris SG/2_audio.wav': System error.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 185, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-93-b8cf6cf15c1b>\", line 120, in __getitem__\n    y, sr = librosa.load(audiopath,sr=SAMPLE_RATE,offset=start_sec,duration=self.wsize+1)\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/librosa/core/audio.py\", line 163, in load\n    y, sr_native = __audioread_load(path, offset, duration, dtype)\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/librosa/core/audio.py\", line 187, in __audioread_load\n    with audioread.audio_open(path) as input_file:\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/audioread/__init__.py\", line 111, in audio_open\n    return BackendClass(path)\n  File \"/home/oarongve/.local/share/virtualenvs/project-daredevil-8eBKzQn6/lib/python3.6/site-packages/audioread/rawread.py\", line 62, in __init__\n    self._fh = open(filename, 'rb')\nFileNotFoundError: [Errno 2] No such file or directory: '/work/oarongve/data/sound_dataset/SoccerNet-code/data/france_ligue-1/2016-2017/2017-05-14 - 22-00 St Etienne 0 - 5 Paris SG/2_audio.wav'\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, data in enumerate(dataloader_valid):\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataloader_test = DataLoader(X_test,**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 300 ms, sys: 142 ms, total: 442 ms\n",
      "Wall time: 17min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, data in enumerate(dataloader_test):\n",
    "    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save training list for dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = SoccerNetDataset(root_dir=root_dir,npy_file=train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(X,**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file=root_dir+\"train_samples.npy\",arr=samples,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.load(root_dir+\"train_samples.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audiopath': '/work/oarongve/data/sound_dataset/SoccerNet-code/data/england_epl/2014-2015/2015-02-21 - 18-00 Chelsea 1 - 1 Burnley/1_audio.wav',\n",
       " 'annotation': {'gameTime': '1 - 40:08',\n",
       "  'label': 'y-card',\n",
       "  'team': 'away',\n",
       "  'duration1': 'Duration: 00:45:00.00',\n",
       "  'duration2': 'Duration: 00:45:00.00'},\n",
       " 'idx': 1,\n",
       " 'one_hot_label': array([1., 0., 0., 0.]),\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3965"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save validation list for dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = SoccerNetDataset(root_dir=root_dir,npy_file=valid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = list()\n",
    "for e in X:\n",
    "    samples.append(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file=root_dir+\"valid_samples.npy\",arr=samples,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.load(root_dir+\"valid_samples.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1314"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save test list for dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = SoccerNetDataset(root_dir=root_dir,npy_file=test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = list()\n",
    "for e in X:\n",
    "    samples.append(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file=root_dir+\"test_samples.npy\",arr=samples,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.load(root_dir+\"test_samples.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1358"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.pool = nn.MaxPool2d(4, 4)\n",
    "        self.fc1 = nn.Linear(2208, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = x.view(-1, 2208)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Note: Can also see warning once\n",
    "# warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/mel_spec_experiment_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(labels == torch.argmax(outputs, dim=1)).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SummaryWriter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-de1982f8cca5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'runs/mel_spec_experiment_5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'SummaryWriter' is not defined"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs/mel_spec_experiment_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device)\n",
    "# Dataloader or dataset faulty(returns batches of 0\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    net.train()\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data['mel_spectogram'].to(device),data['label'].to(device)\n",
    "\n",
    "        #print(inputs.size())\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 0:    # print every 2000 mini-batches\n",
    "            \n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 5,\n",
    "                            epoch * len(dataloader) + i)\n",
    "            \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 5))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # calculate accuracy\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        res = torch.zeros((3,3))\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data['mel_spectogram'].to(device),data['label'].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "            \n",
    "            for p,gt in zip(preds,labels):\n",
    "                res[int(p),int(gt)] += 1\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        N_total = res.sum()\n",
    "        N_correct = res.diag().sum()\n",
    "        \n",
    "        acc = N_total / N_correct\n",
    "        \n",
    "        writer.add_scalar('training acc',\n",
    "                    acc,\n",
    "                    epoch)\n",
    "        print(f\"Epoch : {epoch}, Accuracy : {acc}\")\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate samples to look for cases where y, sr from librosa is inconsistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.fc1.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device)\n",
    "\n",
    "running_loss = 0.0\n",
    "for i, data in enumerate(dataloader, 0):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data['mel_spectogram'].unsqueeze(0).to(device),torch.argmax(data['one_hot_label']).to(device)\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    running_loss += loss.item()\n",
    "    if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "        print('[%d, %5d] loss: %.3f' %\n",
    "              (epoch + 1, i + 1, running_loss / 2000))\n",
    "        running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
